[{"authors":null,"categories":["Infrastructure","Kubernetes"],"content":"When a Kubernetes Operator Makes Sense Beyond YAML: Real-World Lessons from Managing Complex Infrastructure There are plenty of ways to deploy applications onto Kubernetes:\nraw kubectl apply Kustomize overlays Helm charts sidecars and init containers and, at the far end of the spectrum, fully-fledged operators Most teams start at the simple end and stay there. And they should, most applications don’t need anything more complicated than a Deployment, a few ConfigMaps, and a kubectl apply -k.\nBut over the last few years building and operating platforms for distributed systems, secrets management, and internal PaaS primitives, I’ve learned a consistent pattern:\nIf you find yourself orchestrating multi-step lifecycle logic with scripts, sidecars, or tribal knowledge, you’re already halfway to writing an operator — whether you mean to or not.\nIn this post, I outline when an operator genuinely makes sense, using one of the clearest real-world cases I’ve worked with: running and operating Vault inside Kubernetes.\nThe Limits of YAML, Sidecars, and Good Intentions Kubernetes gives you powerful declarative primitives, but those primitives assume your application behaves like a stateless, idempotent component. In practice, many systems don’t.\nTeams often try to bridge the gap with tools like:\ninit containers sidecar containers Helm hooks bash scripts baked into container entrypoints These techniques work when the lifecycle is simple: “run this once, then start the app.” But they fall apart completely when the application behaves like a state machine rather than a simple process.\nVault is the poster child for this.\nCase Study: Vault’s Lifecycle Doesn’t Fit the Pod Lifecycle Vault is incredibly powerful — but it has distinct operational states:\nuninitialised initialised but sealed unsealed leader follower resealed on restart expiring leases privileged configuration requiring root-level access None of that behaviour maps cleanly onto a Deployment or StatefulSet. And for a while, the SRE team supporting our Vault deployments tried to glue the lifecycle together using init scripts and sidecars.\nIt was unreliable. And unavoidably so. While the SRE team heros could keep our SaaS instance working, the problems really started to surface when the product was deployed in dedicated VPC instances for bigger customers.\nInitialisation isn’t idempotent\nvault operator init must run exactly once, on one node, and only when the cluster is uninitialised. If a script guesses wrong, it bricks the cluster.\nOperators excel here because they can read application state, maintain a shared control loop, and encode an idempotent workflow.\nPods don’t share memory — but Vault has shared state\nSidecars run once per pod, but Vault’s state is cluster-wide. Coordinating initialisation, unseal operations, and failover across replicas cannot be expressed through pod-local logic.\nAn operator, running as a single control plane component, can coordinate safely.\nMulti-step workflows don’t belong in bash\nA simplified lifecycle of a Vault cluster:\nDetect initialisation state Initialise (once) if required Store unseal keys safely Unseal nodes one by one Detect restarts Re-unseal automatically Reconcile mounts, roles, and policies Rotate secrets Maintain downstream K8s access tokens Back up and restore data selectively Trying to express this via init scripts and pod startup timing is brittle and unsafe.\nFailures are domain-specific, not pod-specific\n“Sealed” is not “crashed.” Vault failures require domain-aware remediation, not generic liveness probes.\nOperators can interpret domain faults and take domain-correct actions.\nExample A Real-World Example of Why Scripts Fail: The “Replica Index Hack”\nOne of the clearest signs the approach had gone too far was a clever — and unintentionally hilarious — hack I encountered.\nTo prevent every pod from attempting initialisation, the team leaned on this logic:\nVault pods in a StatefulSet get predictable names: vault-0, vault-1, …\nHelm passes replicaCount into the container.\nThe init script would:\nParse its own index Compare it to replicaCount - 1 If it was the “last” pod, assume the others were up Attempt initialisation Have all other pods skip In other words:\n“Use pod index order and hope Kubernetes starts pods in sequence.”\nOf course:\nKubernetes makes no guarantee about pod startup order Restarted pods break assumptions A “last” pod can start first after rescheduling Node drains or autoscaling resets the whole hack This was an accidental reinvention of a distributed coordination protocol using naming conventions and timing.\nAnd it failed exactly when you’d expect it to.\nThis was the moment it became clear: we needed a real controller.\nEvaluating Open-Source Vault Operators Before building anything, we evaluated the existing ecosystem:\nHashiCorp Vault Secrets Operator\nGreat for syncing secrets downstream into Kubernetes Secrets. Not designed for managing Vault itself, nor for initialisation/unseal logic.\nKubeVault …","date":1763467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1763467200,"objectID":"ee6d92c1fdc8e8f724f6b1356a601fb0","permalink":"https://stephenc.github.io/post/2025-11-18-when-a-kubernetes-operator-makes-sense/","publishdate":"2025-11-18T12:00:00Z","relpermalink":"/post/2025-11-18-when-a-kubernetes-operator-makes-sense/","section":"post","summary":"When a Kubernetes Operator Makes Sense Beyond YAML: Real-World Lessons from Managing Complex Infrastructure There are plenty of ways to deploy applications onto Kubernetes:\nraw kubectl apply Kustomize overlays Helm charts sidecars and init containers and, at the far end of the spectrum, fully-fledged operators Most teams start at the simple end and stay there. And they should, most applications don’t need anything more complicated than a Deployment, a few ConfigMaps, and a kubectl apply -k.\n","tags":["kubernetes","operator-pattern","vault","devops","platform-engineering"],"title":"When a Kubernetes Operator Makes Sense","type":"post"},{"authors":null,"categories":null,"content":"About 19 years ago, I set up a blog on Google’s Blogger platform to track my adventures learning Java: https://javaadventure.blogspot.com/\nThe platform has changed a lot since then, and not always for the better. Many posts no longer render the way they used to, and a few images have disappeared entirely.\nOne feature I really loved, which is now broken, was the ability to email a special address and have the message automatically turned into a post. It made publishing effortless… though that was also before I discovered what was then X (née Twitter).\nI’ve tried exploring other hosting platforms, but none give me the level of control over my content that I want. And then this weekend I had a facepalm moment: why not just use the root of my GitHub Pages site?\nSo here we go. I’m giving technical blogging another shot.\nIf it’s fun, I’ll keep going.\nNote: Right now I’m using this GitHub-inspired Hugo theme: https://github.com/MeiK2333/github-style, we’ll see how long it lasts before I get the itch to switch again.\nNote: I may or may not fix the formatting of the older posts and better tag them depending on how much it annoys me. I’ve done some but there’s at least 50 that still need fixing.\n","date":1763424e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1763424e3,"objectID":"cb9736be9ebe10fe18604242b8aa72f5","permalink":"https://stephenc.github.io/post/2025-11-18-migrating-content-to-github-pages/","publishdate":"2025-11-18T00:00:00Z","relpermalink":"/post/2025-11-18-migrating-content-to-github-pages/","section":"post","summary":"About 19 years ago, I set up a blog on Google’s Blogger platform to track my adventures learning Java: https://javaadventure.blogspot.com/\nThe platform has changed a lot since then, and not always for the better. Many posts no longer render the way they used to, and a few images have disappeared entirely.\nOne feature I really loved, which is now broken, was the ability to email a special address and have the message automatically turned into a post. It made publishing effortless… though that was also before I discovered what was then X (née Twitter).\n","tags":["general"],"title":"Migrating my old blog content to GitHub Pages","type":"post"},{"authors":null,"categories":null,"content":"Another interesting tidbit:\n@Benchmark public void debug1Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time)); time++; blackhole.consume(time); } @Benchmark public void guardedDebug1Arg_date(Blackhole blackhole) { if (LOGGER.isDebugEnabled()) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time)); } time++; blackhole.consume(time); } Gives the following benchmark results:\nBenchmark Mode Cnt Score Error Units Log4jBenchmark.debug1Arg_date thrpt 20 179653191.248 ± 2731044.349 ops/s Log4jBenchmark.guardedDebug1Arg_date thrpt 20 207001790.376 ± 2074020.617 ops/s We can also compare guarding with SLF4J over logback\nBenchmark Mode Cnt Score Error Units SLF4JBenchmark.debug1Arg_date thrpt 20 220765608.629 ± 6555782.899 ops/s SLF4JBenchmark.guardedDebug1Arg_date thrpt 20 241286730.504 ± 9532328.812 ops/s So where performance is critical, seems to be about 10% faster if you guard that log statement!\n","date":1480896e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480896e3,"objectID":"53c48bf896255ece34492d46709d93e5","permalink":"https://stephenc.github.io/post/2016-12-05-guarding-logging-log4j/","publishdate":"2016-12-05T00:00:00Z","relpermalink":"/post/2016-12-05-guarding-logging-log4j/","section":"post","summary":"Another interesting tidbit:\n@Benchmark public void debug1Arg_date(Blackhole blackhole) { LOGGER.debug(\"Started at %s\", new Date(time)); time++; blackhole.consume(time); } @Benchmark public void guardedDebug1Arg_date(Blackhole blackhole) { if (LOGGER.isDebugEnabled()) { LOGGER.debug(\"Started at %s\", new Date(time)); } time++; blackhole.consume(time); } Gives the following benchmark results:\nBenchmark Mode Cnt Score Error Units Log4jBenchmark.debug1Arg_date thrpt 20 179653191.248 ± 2731044.349 ops/s Log4jBenchmark.guardedDebug1Arg_date thrpt 20 207001790.376 ± 2074020.617 ops/s We can also compare guarding with SLF4J over logback\n","tags":["Java"],"title":"The costs of guarding logging with Apache Log4J version 2","type":"post"},{"authors":null,"categories":null,"content":"One of my colleagues had a question:\nNow for some context, when the Jenkins project started off, Kohsuke was working for Sun and felt it would be wrong, as a Sun employee, to use a logging framework other than that provided by the JVM as using a different logging framework could be seen as being implication that the built in Java Utils Logging framework was a steaming pile of excrement.\nNow while JUL is not a complete and utter steaming pile of excrement, at times it does indeed throw shades at being one.\nThis post is not a defence of Java Utils Logging. This post is an analysis of how to use Java Utils Logging such that performance does not end up down the toilet.\nWhen you are using Java Utils Logging there are many many ways to actually log something:\n// simple style LOGGER.info(\u0026#34;A message\u0026#34;); // explicit level style LOGGER.log(Level.INFO, \u0026#34;A message\u0026#34;); // explicit level and stack trace LOGGER.log(Level.INFO, \u0026#34;A message with a stack trace\u0026#34;, e); // explicit level and single parameter LOGGER.log(Level.INFO, \u0026#34;A message with a {0} parameter\u0026#34;, param); // explicit level and multiple parameters LOGGER.log(Level.INFO, \u0026#34;A message with parameter {0} and {1}\u0026#34;, new Object[]{param0,param1}); // explicit level, stack trace and parameter(s) LogRecord lr = new LogRecord(Level.INFO, \u0026#34;A message with parameter {0} and {1} and a stack trace\u0026#34;); lr.setThrown(e); lr.setParams(new Object[]{param0,param1}); LOGGER.log(lr); Now each of the above achieves basically the same thing, sending a message to the logs under differing use cases. The LOGGER.info() variant is intended to be used when you have a constant message to report… but invariably somebody starts doing the easy string concatenation with that style, rather than use the parameterised logging as the JUL framework intended, so you will sometimes see:\nLOGGER.info(\u0026#34;Accepted incoming connection #\u0026#34; + connectionNumber + \u0026#34; from \u0026#34; + socket.getAddress() + \u0026#34; and processing with \u0026#34; + handler); Rather than\nLOGGER.log(Level.INFO, \u0026#34;Accepted incoming connection #{0} from {1} and processing with {2}\u0026#34;, new Object[]{connectionNumber,socket.getAddress(),handler}); At the INFO level (which is normally logged by default) this may not be as critical, but once we move the code from development to production and notch the levels down the difference can be an order of magnitude or more.\nThe reason becomes clear when we look at the source code for Logger:\n/** * Log a message, with no arguments. * \u0026lt;p\u0026gt; * If the logger is currently enabled for the given message * level then the given message is forwarded to all the * registered output Handler objects. * \u0026lt;p\u0026gt; * @param level One of the message level identifiers, e.g., SEVERE * @param msg The string message (or a key in the message catalog) */ public void log(Level level, String msg) { if (!isLoggable(level)) { return; } LogRecord lr = new LogRecord(level, msg); doLog(lr); } /** * Log a message, with an array of object arguments. * \u0026lt;p\u0026gt; * If the logger is currently enabled for the given message * level then a corresponding LogRecord is created and forwarded * to all the registered output Handler objects. * \u0026lt;p\u0026gt; * @param level One of the message level identifiers, e.g., SEVERE * @param msg The string message (or a key in the message catalog) * @param params array of parameters to the message */ public void log(Level level, String msg, Object params[]) { if (!isLoggable(level)) { return; } LogRecord lr = new LogRecord(level, msg); lr.setParameters(params); doLog(lr); } /** * Log an INFO message. * \u0026lt;p\u0026gt; * If the logger is currently enabled for the INFO message * level then the given message is forwarded to all the * registered output Handler objects. * \u0026lt;p\u0026gt; * @param msg The string message (or a key in the message catalog) */ public void info(String msg) { log(Level.INFO, msg); } So that LOGGER.info() call requires that we build up the string first, and only after the string has been instantiated do we check if the logger is logging that level whereas the parameterised message just passes the string constant and the object array but doesn’t do much actual work.\nOne would hope, given sufficient time, that the LOGGER.log(level,msg) call would also get inlined and the JVM might be smart enough to re-order the isLoggable check ahead of the string concatenation and everything would be equal in the long run.\nWell, that’s a nice theory, but users would need to wait for that to occur, plus your log statements are likely in the middle of large methods anyway and the Logger methods are not final so the JVM would need to put in some guards just in case somebody loaded a Logger subclass that would invalidate the optimisation.\nSo what is the impact anyway?\nEnter JMH we can run a micro-benchmark to see what the different styles perform like when our logger is not logging.\nFirstly we need to grab a baseline:\npublic class JulBenchmark { private static final Logger LOGGER = Logger.getLogger(JulBenchmark.class.getName()); static long time; @Benchmark public void noLogging(Blackhole …","date":1480896e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480896e3,"objectID":"1a23bdfa2e27cbb28206c5bc2b0044dc","permalink":"https://stephenc.github.io/post/2016-12-05-costs-java-utils-logging/","publishdate":"2016-12-05T00:00:00Z","relpermalink":"/post/2016-12-05-costs-java-utils-logging/","section":"post","summary":"One of my colleagues had a question:\nNow for some context, when the Jenkins project started off, Kohsuke was working for Sun and felt it would be wrong, as a Sun employee, to use a logging framework other than that provided by the JVM as using a different logging framework could be seen as being implication that the built in Java Utils Logging framework was a steaming pile of excrement.\n","tags":["Java"],"title":"The costs of Java Utils Logging","type":"post"},{"authors":null,"categories":null,"content":"You asked for it.\nLogback:\n@Benchmark public void debug1Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at {}\u0026#34;, new Date(time)); time++; blackhole.consume(time); } @Benchmark public void debug2Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at {}\u0026#34;, new Date(time), null); time++; blackhole.consume(time); } @Benchmark public void debugNArg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at {}\u0026#34;, new Date(time), null, null); time++; blackhole.consume(time); } static { ch.qos.logback.classic.Logger root = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(org.slf4j.Logger.ROOT_LOGGER_NAME); root.setLevel(ch.qos.logback.classic.Level.INFO); } And the benchmarks\nBenchmark Mode Cnt Score Error Units LogbackBenchmark.debug1Arg_date thrpt 20 221056534.656 ± 8549233.826 ops/s LogbackBenchmark.debug2Arg_date thrpt 20 220576341.742 ± 3778270.898 ops/s LogbackBenchmark.debugNArg_date thrpt 20 134887126.088 ± 2973182.812 ops/s JUL over SLF4J (same benchmark code but different dependency)\nBenchmark Mode Cnt Score Error Units SLF4JOverJULBenchmark.debug1Arg_date thrpt 20 213779286.286 ± 4819012.495 ops/s SLF4JOverJULBenchmark.debug2Arg_date thrpt 20 213707271.979 ± 2675083.826 ops/s SLF4JOverJULBenchmark.debugNArg_date thrpt 20 152839334.058 ± 2122611.858 ops/s Then if we compare the JUL LogRecord implicitly:\n@Benchmark public void logRecord(Blackhole blackhole) { LogRecord lr = new LogRecord(Level.FINE, \u0026#34;Started at {0}\u0026#34;); lr.setParameters(new Object[]{new Date(time)}); LOGGER.log(lr); time++; blackhole.consume(time); } This has the following Benchmark\nBenchmark Mode Cnt Score Error Units JulBenchmark.logRecord thrpt 20 16422331.419 ± 148428.926 ops/s DO NOT USE AN UNGUARDED LogRecord WHEN IT WILL LIKELY NOT GET LOGGED\nFinally, Apache’s Log4J version 2 (which has overrides to avoid var-args all the way up to 10 parameters):\n@Benchmark public void debug1Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time)); time++; blackhole.consume(time); } @Benchmark public void debug2Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null); time++; blackhole.consume(time); } @Benchmark public void debug3Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null); time++; blackhole.consume(time); } @Benchmark public void debug4Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null); time++; blackhole.consume(time); } @Benchmark public void debug5Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null); time++; blackhole.consume(time); } @Benchmark public void debug6Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null, null); time++; blackhole.consume(time); } @Benchmark public void debug7Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null, null, null); time++; blackhole.consume(time); } @Benchmark public void debug8Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null, null, null, null); time++; blackhole.consume(time); } @Benchmark public void debug9Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null, null, null, null, null); time++; blackhole.consume(time); } @Benchmark public void debug10Arg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null, null, null, null, null, null); time++; blackhole.consume(time); } @Benchmark public void debugNArg_date(Blackhole blackhole) { LOGGER.debug(\u0026#34;Started at %s\u0026#34;, new Date(time), null, null, null, null, null, null, null, null, null, null); time++; blackhole.consume(time); } And the benchmarks:\nBenchmark Mode Cnt Score Error Units Log4j2Benchmark.debug1Arg_date thrpt 20 182786163.176 ± 1894038.335 ops/s Log4j2Benchmark.debug2Arg_date thrpt 20 180716268.151 ± 5295999.398 ops/s Log4j2Benchmark.debug3Arg_date thrpt 20 178064841.181 ± 6987288.015 ops/s Log4j2Benchmark.debug4Arg_date thrpt 20 181537704.811 ± 4472120.312 ops/s Log4j2Benchmark.debug5Arg_date thrpt 20 181803075.728 ± 3963211.935 ops/s Log4j2Benchmark.debug6Arg_date thrpt 20 178229873.962 ± 8092548.001 ops/s Log4j2Benchmark.debug7Arg_date thrpt 20 181018788.479 ± 5438279.737 ops/s Log4j2Benchmark.debug8Arg_date thrpt 20 180443652.287 ± 4965518.359 ops/s Log4j2Benchmark.debug9Arg_date thrpt 20 181456134.533 ± 2014764.085 ops/s Log4j2Benchmark.debug10Arg_date thrpt 20 176706451.426 ± 7911521.599 ops/s Log4j2Benchmark.debugNArg_date thrpt 20 123243343.482 ± 2051852.105 ops/s So for the logs not logged we have the following:\nFastest is JUL with single argument Second fastest is SLF4J with one or two arguments (Logback is ever so slightly ahead but it’s splitting hairs) Third place is Apache Log4J version 2 with up to 10 arguments Forth place is JUL for more than 1 argument Fifth place is SLF4J over JUL with more than 2 arguments Sixth …","date":1480896e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480896e3,"objectID":"841ae08f3c768a126420a7fc1a1f0d24","permalink":"https://stephenc.github.io/post/2016-12-05-costs-other-logging-frameworks/","publishdate":"2016-12-05T00:00:00Z","relpermalink":"/post/2016-12-05-costs-other-logging-frameworks/","section":"post","summary":"You asked for it.\nLogback:\n@Benchmark public void debug1Arg_date(Blackhole blackhole) { LOGGER.debug(\"Started at {}\", new Date(time)); time++; blackhole.consume(time); } @Benchmark public void debug2Arg_date(Blackhole blackhole) { LOGGER.debug(\"Started at {}\", new Date(time), null); time++; blackhole.consume(time); } @Benchmark public void debugNArg_date(Blackhole blackhole) { LOGGER.debug(\"Started at {}\", new Date(time), null, null); time++; blackhole.consume(time); } static { ch.qos.logback.classic.Logger root = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(org.slf4j.Logger.ROOT_LOGGER_NAME); root.setLevel(ch.qos.logback.classic.Level.INFO); } And the benchmarks\nBenchmark Mode Cnt Score Error Units LogbackBenchmark.debug1Arg_date thrpt 20 221056534.656 ± 8549233.826 ops/s LogbackBenchmark.debug2Arg_date thrpt 20 220576341.742 ± 3778270.898 ops/s LogbackBenchmark.debugNArg_date thrpt 20 134887126.088 ± 2973182.812 ops/s JUL over SLF4J (same benchmark code but different dependency)\n","tags":["Java"],"title":"The costs of other logging frameworks","type":"post"},{"authors":null,"categories":null,"content":"If there are two only things guaranteed to cause all out war between developers, my vote is that those two things are:\nCode formatting conventions\nVersion number conventions\nThe first is resolved trivially (just shoot anyone suggesting the use of TABs). Until recently most people thought the second was resolved by semver… at least until the developer of one of the more commonly used JavaScript libraries threw the cat amongst the pigeons.\nThe real issue here is that we are trying to cram far too much into a list of number like things (that we call a “version number” - note it’s not a plural). On top of that we have marketing types putting additional demands on these poor abused version numbers.\nLet’s start with some example schemes:\nEvery time you change something increment the number by 1.\nThis scheme is dead simple to implement if your source repository is Subversion, as the version number is simply the revision number.\nThings get a bit harder if you use a DVCS like Git. You can certainly count commits from the root commit, but you have to worry about squashed commits and history rewriting, so you end up with a canonical repository configured to not allow rewriting of history and the version number is determined by that repository\nFor something like Software as a Service, there is a lot to be said with this model, as there is only ever one version in production, and that distribution model tends to follow upgrade only processes.\nOnce you have to maintain more than one version (i.e. if you need to fix things in older versions… or if there is an emergency fix needed in production while you await the next big release to make it through testing) then that single version number becomes a liability. You need to have some tracking database to know that version 17 was actually a fixed release of version 10.\nWe need some way to track those fixes…\nWell there’s an infinite supply of numbers, so let’s change the scheme\nEvery time you release from the mainline, increment the number by 10. If releasing an update to an old release, increment the number by 1.\nWell that buys us some room, but if we ever have more than 9 fixes we’ll be in trouble.\nNotice now that we have switched from being able to determine the version number from a rule. The version number has now become subjective.\nWe can refine the scheme to give us some more room, e.g. by switching to decimal numbers.\nEvery time you release from the mainline, increment the number by 1. If releasing an update to an old release, increment the number by 0.1\nIf we consistently expect more than 9 updates to old releases then use an increment to 0.01. We can even be lazy about changing the increment and switch to 0.01 once we are at a .9 release\nSo far we have been able to keep some invariants:\nOur version numbers are actual numbers.\nNewer things have bigger numbers than older things\nAnd if we are strict with policy, we can tell some more information from the version numbers. So for example if we say “only changes that backport bug fixes from trunk” are allowed in older releases then you know that upgrading point releases should be safe.\nAt this point we now leave the realm of the actual numbers.\nSemver and OSGi are amongst this class of schemes.\nVersion numbers are [major].[minor].[patch]\nIf you make a release that breaks backwards compatibility, increase the major number and reset the remaining numbers to 0.\nIf you make a release that adds a feature but remains backwards compatible, increase the minor number and reset the patch number to 0.\nIf you make a release that just fixes bugs, increase the patch number by 1.\nThere are usually additional side rules to nail the scheme down somewhat, but the principle is the same. If you write something that depends on 5.0.0 you should be “safe” with any 5.?.? release. We are now relying on even more subjective criteria, namely the question of when we break backwards compatible behaviour.\nWe can fool ourselves with tooling into the belief that there are automated checks of backwards compatibility, but that just captures changes to method signatures. It does not capture the documentation change that says you now need to call the ‘start’ method before using the ‘forward’ method.\nSo yes, tooling can help us catch those cases where we should have updated the major version and forgot to.\nTooling can be more helpful with catching backwards compatible changes (i.e. new methods in an API) but even then there can be backwards compatible enhancements that are missed by tooling (‘You no-longer have to call the ‘start’ method before using the ‘forward’ method as an un-started widget will be started implicitly on the first call to ‘forward’” would be an example)\nBy all means put tooling in place to help you catch those cases where you forgot to change the version number, but do not assume that the tooling absolves you from thinking about the version number.\nWhen a project is developing rapidly it can be very easy to make mistakes in identifying and …","date":1410134400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410134400,"objectID":"313ac52b829adeda272b1b815ddba655","permalink":"https://stephenc.github.io/post/2014-09-08-version-numbers/","publishdate":"2014-09-08T00:00:00Z","relpermalink":"/post/2014-09-08-version-numbers/","section":"post","summary":"If there are two only things guaranteed to cause all out war between developers, my vote is that those two things are:\nCode formatting conventions\nVersion number conventions\nThe first is resolved trivially (just shoot anyone suggesting the use of TABs). Until recently most people thought the second was resolved by semver… at least until the developer of one of the more commonly used JavaScript libraries threw the cat amongst the pigeons.\n","tags":null,"title":"Version numbers","type":"post"},{"authors":null,"categories":null,"content":"One of the headline grabbing things that people seem to be raving about over Log4J 2.0 is async loggers.\nNow do not get me wrong, they are great… as long as you know what you are doing.\nIf you are using async loggers you had better make sure you are only passing immutable objects to your loggers, because otherwise you may end up logging the state of your objects at the time of the log record being written and not the time you called log.\nNow there are many other good reasons why you should use immutable objects for your logging, but async logging is the tipping point.\nA few years ago I was burned by this exact class of problem in a conferencing call bridge, where we had a log message recording the participants that were actively talking (i.e. their volume was greater than the threshold). Spurious line noise would result in messages like:\nBob has started talking, Bob’s volume is 1, threshold is 64 Bob has stopped talking, Bob’s volume is 120, threshold is 64 Which was a result of the mutable object that held the volume for Bob being changed by the media server in between creating the log record and writing the log record to disk.\nConsider the following simple test class:\npackage test; import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger; import java.util.concurrent.atomic.AtomicLong; public class App { private static final AtomicLong value = new AtomicLong(); public String toString() { return Long.toString(value.get()); } public long next() { return value.incrementAndGet(); } public static void main(String[] args) { for (int i = 0; i \u0026lt; 32; i++) { new Thread() { final Logger logger = LogManager.getLogger(App.class); final App instance = new App(); @Override public void run() { for (int i = 0; i \u0026lt; 100000; i++) { logger.warn(\u0026#34;{} == {}\u0026#34;, instance.next(), instance); } } }.start(); } } } Now run this code…\nHere is the first few lines of logging output\n2014-07-28 15:59:45,729 WARN t.App [Thread-13] 13 == 13 2014-07-28 15:59:45,730 WARN t.App [Thread-29] 29 == 29 2014-07-28 15:59:45,729 WARN t.App [Thread-15] 15 == 15 2014-07-28 15:59:45,729 WARN t.App [Thread-6] 6 == 6 2014-07-28 15:59:45,730 WARN t.App [Thread-30] 30 == 30 2014-07-28 15:59:45,729 WARN t.App [Thread-20] 20 == 20 2014-07-28 15:59:45,729 WARN t.App [Thread-8] 8 == 8 2014-07-28 15:59:45,730 WARN t.App [Thread-28] 28 == 28 2014-07-28 15:59:45,729 WARN t.App [Thread-19] 19 == 19 2014-07-28 15:59:45,729 WARN t.App [Thread-18] 18 == 18 2014-07-28 15:59:45,729 WARN t.App [Thread-5] 5 == 6 2014-07-28 15:59:45,731 WARN t.App [Thread-13] 33 == 37 2014-07-28 15:59:45,731 WARN t.App [Thread-8] 39 == 39 2014-07-28 15:59:45,731 WARN t.App [Thread-28] 40 == 41 2014-07-28 15:59:45,731 WARN t.App [Thread-18] 42 == 43 2014-07-28 15:59:45,731 WARN t.App [Thread-5] 43 == 43 Spot anything wrong with that?\nNow of course I have written the class to have mutable state… because I wanted to test if Log4J 2.0 was capturing the `toString()`` at the time of logging… which it isn’t.\nSo if you have an object with a `toString()`` method that depends on mutable state, you will have to:\nCheck that the logger is enabled for the logging level\nCall toString() by hand\nPass the toString() result as the parameter.\nTo make my previous code work with Asynchronous loggers (other than by fixing the mutable state) I would need to log like this:\nif (logger.isWarnEnabled()) { logger.warn(\u0026#34;{} == {}\u0026#34;, instance.next(), instance.toString()); } Yep, we are back to that old pattern.\nTL;DR Unless you know that every parameter object passed to a log statement is using immutable objects, enabling Asynchronous loggers in Log4J may well result in logs with messages you cannot trust.\nUpdate Here is the log4j2.xml configuration file I used\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- Don\u0026#39;t forget to set system property-DLog4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector to make all loggers asynchronous. --\u0026gt; \u0026lt;Configuration status=\u0026#34;WARN\u0026#34;\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;!-- Async Loggers will auto-flush in batches, so switch off immediateFlush. --\u0026gt; \u0026lt;RandomAccessFile name=\u0026#34;RandomAccessFile\u0026#34; fileName=\u0026#34;async.log\u0026#34; immediateFlush=\u0026#34;false\u0026#34; append=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;PatternLayout\u0026gt; \u0026lt;Pattern\u0026gt;%d %p %c{1.} [%t] %m %ex%n\u0026lt;/Pattern\u0026gt; \u0026lt;/PatternLayout\u0026gt; \u0026lt;/RandomAccessFile\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;Root level=\u0026#34;info\u0026#34; includeLocation=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;RandomAccessFile\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; Which is the example on the Log4j Website\n","date":1406505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406505600,"objectID":"ea58a08f263cbf51ce21d855bca5981f","permalink":"https://stephenc.github.io/post/2014-07-28-log4j-20-async-loggers-and-immutability/","publishdate":"2014-07-28T00:00:00Z","relpermalink":"/post/2014-07-28-log4j-20-async-loggers-and-immutability/","section":"post","summary":"One of the headline grabbing things that people seem to be raving about over Log4J 2.0 is async loggers.\nNow do not get me wrong, they are great… as long as you know what you are doing.\nIf you are using async loggers you had better make sure you are only passing immutable objects to your loggers, because otherwise you may end up logging the state of your objects at the time of the log record being written and not the time you called log.\n","tags":["Java"],"title":"Log4j 2.0 Async loggers and immutability","type":"post"},{"authors":null,"categories":null,"content":"We have all had the bad technical managers… the ones who tell you to go and do something… and then micromanage the task they have “delegated” to you.\nThey are a pain to work for.\nOne of the qualities of a good manager is to tailor their delegation to the people they are delegating to.\nSo they task Gillian, a senior engineer, with “writing some smoke tests to verify that the application works when deployed to the app server” and they are happy to let Gillian work within that scope because they trust that Gillian will come back to seek clarification if the description is lacking, or if there are issues down the road.\nKevin, a junior engineer, on the other hand, has proven over many many tasks to need more detail, so they give Kevin a more detailed written description of the task and they check in on Kevin as he is going along… because Kevin has proven that he needs a certain level of micromanagement… the good manager is all the time testing to see if Kevin can survive with less micromanagement.\nNote: one of the biggest cognitive distortions of bad managers is the thinking that in order to treat everyone fairly, you must treat everyone equally. If we did that then either Gillian gets micromanaged which is unfair to Gillian or Kevin gets under-managed which is unfair to Kevin.\nSo, what does all that have to do with liking Maven?\nWell Maven is a build tool. If you need Maven to build a .war file, you should just tell it to build a .war file\n\u0026lt;project\u0026gt; \u0026lt;groupId\u0026gt;…\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;…\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;…\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt; \u0026lt;dependencies\u0026gt; ... \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; Why do you want to micromanage Maven and tell it every little thing it must do to build the .war file. Wait until you see what it did with your instructions, then and only then should you refine your instructions.\nSo… If you don’t like Maven, you would not be a good manager… The corollaries are not necessarily true though…\nLiking Maven does not mean you will be a good manager… there are other qualities that make a good manager… understanding when and how to micromanage is only one of those qualities\nBeing a good manager does not mean you will like Maven… for example if all your developers (who love to micromanage and thankfully are not managers because of their micromanagement adoration) tell you that Maven is a pain… well a good manager will hear what their team is saying and take it on board… after all they are there to manage, not to do… if they were to see a Maven build where it has not been micromanaged by the developers, then a different view they will form.\n","date":139104e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":139104e4,"objectID":"cce24fa46e364be80bed7a85d0f672db","permalink":"https://stephenc.github.io/post/2014-01-30-if-you-dont-like-maven-you-would-not-be-a-good-manager/","publishdate":"2014-01-30T00:00:00Z","relpermalink":"/post/2014-01-30-if-you-dont-like-maven-you-would-not-be-a-good-manager/","section":"post","summary":"We have all had the bad technical managers… the ones who tell you to go and do something… and then micromanage the task they have “delegated” to you.\nThey are a pain to work for.\nOne of the qualities of a good manager is to tailor their delegation to the people they are delegating to.\nSo they task Gillian, a senior engineer, with “writing some smoke tests to verify that the application works when deployed to the app server” and they are happy to let Gillian work within that scope because they trust that Gillian will come back to seek clarification if the description is lacking, or if there are issues down the road.\n","tags":null,"title":"If you don't like Maven, you would not be a good manager...","type":"post"},{"authors":null,"categories":null,"content":"There are two ways to build a Maven project with Jenkins*\nUse a free-style project with a Maven build step\nUse a Maven-style project\nThe first way runs the build as Maven intended. The second way adds a whole lot of hooks and can even modify the build in ways that Maven did not intend.\nThe first way requires that you configure stuff yourself. The second way tries to “guess” what you want and auto-configure it.\nThe first way is initially less user friendly, i.e. you have more UI to click through to get the full set of reports. The second way is initially more user friendly… but when things go wrong… well sorry out of luck.\nIf something goes wrong with the first way, worst case you add a shell build step above the Maven build step that just runs SET, trigger a build, login to the build slave, switch to the user the build is running as, apply the environment your SET build step output and then run the Maven command that the build’s console log captured. That will give you an exact reproduction of the Maven build and you can debug why your build is not working.\nWhen something goes wrong with the second way, well good luck. By all means try to do the same as you would for a free-style project, but at the end of the day, there is no way you can replicate the injected hooks that Jenkins puts into your Maven build. You can get an approximate reproduction, and hey, that may just be enough to let you figure out what is wrong and fix your build… but there are cases where you cannot.\nHence why, since 2007, I have been saying that the Maven job type is considered evil…\nIt has very attractive because is easy to configure (so users use it) and gives nice per-module reports\nWhen it blows up, and it will blow up, it blows up big\n-Stephen\nwell actually three ways1 if you include the literate job type (Update 2017-08-01) well actually four ways if you include pipeline and the withMaven helper ↩︎\n","date":1383696e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383696e3,"objectID":"1af16ce8f6f9740d16b3235197687f09","permalink":"https://stephenc.github.io/post/2013-11-06-jenkins-maven-job-type-considered-evil/","publishdate":"2013-11-06T00:00:00Z","relpermalink":"/post/2013-11-06-jenkins-maven-job-type-considered-evil/","section":"post","summary":"There are two ways to build a Maven project with Jenkins*\nUse a free-style project with a Maven build step\nUse a Maven-style project\nThe first way runs the build as Maven intended. The second way adds a whole lot of hooks and can even modify the build in ways that Maven did not intend.\nThe first way requires that you configure stuff yourself. The second way tries to “guess” what you want and auto-configure it.\n","tags":null,"title":"Jenkins' Maven job type considered evil","type":"post"},{"authors":null,"categories":null,"content":"I was given a link to yet another article preaching about how 100% code coverage is the only goal (the article is preaching, not Tatu BTW)\nThere is an issue I have with how the 100% coverage advocates present their argument, but we’ll get to that later.\nThe case for 100% coverage is put quite simply:\nAnything less than 100% coverage means that there are some lines in your code that are untested, and are you seriously willing to let code be released without being tested?\nNow if your code is 100 lines long, and you have 95% coverage, 5 lines doesn’t seem too bad. In fact looking at the code coverage report you see those 5 lines, and you make a judgement call that they are an acceptable risk. No harm done, right?\nWhen the code grows to 1,000 lines long, 95% coverage is giving you less of that warm and fuzzy feeling, but a quick scan of the coverage report and you can visually check the 50 lines untested, and you make a judgement call that they are an acceptable risk. No harm done, right?\nWith a 10,000+ LOC code base and 95% coverage and your boss wants to know if it is OK to push this code into production now, the 500+ uncovered lines that you need to review are now much more than a headache…\nAre you a convert now? Do you believe in 100% coverage? It’s a nice argument. But there is a flaw… in some cases that is!\nWhen you are dealing with a dynamically typed language, especially some of the more expressive ones, the only tests you can have are the tests you write yourself. In those languages, the 100% coverage zealots have me sold (at least for code that needs to be maintained and is longer than 100 lines or so!)\nBut in different languages we can, and do, have additional tests that are provided by tooling:\nSyntax tests that verify that every line of code is syntactically correct\nScoping tests (in languages that force declaring names before first use within a scope) that verify that each line only accesses those names within the correct scope for the line.\nType tests (in statically typed languages)\nAnd that’s not all… most of the code I write runs on the JVM, there are more tests I can add to the mix when on the JVM\nStatic analysis tools, such as Checkstyle, PMD and Findbugs provide an additional set of tests that I can run automatically on my code looking for common problems and possible mistakes. In fact I’ve found and fixed bugs with Findbugs in code that had 100% coverage already.\nAnnotation’s in code can be used to, not only document the code contracts, but aid and assist Findbugs in catching bugs. Specifically I am referring to the @CheckForNull and @NonNull annotations. I apply these annotations to the production code, and there are tests applied to the code for free by the toolchain I use\nSo when I am writing Java code, every line I write already has at least five tests covering it and I haven’t even started adding unit tests into the mix!\nNow I am not arguing that the above tests are enough for your code on it’s own… but when you look at my unit test coverage at 83.7% and ask am I “happy to ship with 1,630 untested lines of code”, I will answer that those 1,630 lines of code are tested, they may not be our best tests, but we have tests on them.\nShow me a real code base with 100% coverage, and I will show you a good number of crappy tests helping that code base get to 100% coverage…\nOn the other hand, if you ask me am I happy to ship that Ruby on Rails / Node.JS / etc application into production with 99.5% coverage, I’ll say no way are we shipping that code with 50 untested LOC.\n","date":1366329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1366329600,"objectID":"9cdc0f545917074c80948c4d1c9cd264","permalink":"https://stephenc.github.io/post/2013-04-19-about-test-coverage/","publishdate":"2013-04-19T00:00:00Z","relpermalink":"/post/2013-04-19-about-test-coverage/","section":"post","summary":"I was given a link to yet another article preaching about how 100% code coverage is the only goal (the article is preaching, not Tatu BTW)\nThere is an issue I have with how the 100% coverage advocates present their argument, but we’ll get to that later.\nThe case for 100% coverage is put quite simply:\nAnything less than 100% coverage means that there are some lines in your code that are untested, and are you seriously willing to let code be released without being tested?\n","tags":null,"title":"About test coverage","type":"post"},{"authors":null,"categories":null,"content":"For use when you have multiple JVM providers (Apple \u0026amp; Oracle), you want to be able to switch between JDKs for each CLI\nusejava () { local sel=$1.jdk if [ -x \u0026#34;/Library/Java/JavaVirtualMachines/jdk$sel/Contents/Home/bin/java\u0026#34; -a ! -x \u0026#34;/Library/Java/JavaVirtualMachines/$1/Contents/Home/bin/java\u0026#34; ] then sel=jdk$sel fi local base=/Library/Java/JavaVirtualMachines if [ -x \u0026#34;/System/Library/Java/JavaVirtualMachines/$sel/Contents/Home/bin/java\u0026#34; ] then base=/System/Library/Java/JavaVirtualMachines fi if [ -z \u0026#34;$1\u0026#34; -o ! -x \u0026#34;$base/$sel/Contents/Home/bin/java\u0026#34; ] then local prefix=\u0026#34;Syntax: usejava \u0026#34; for i in /Library/Java/JavaVirtualMachines/* /System/Library/Java/JavaVirtualMachines/* do if [ -x \u0026#34;$i/Contents/Home/bin/java\u0026#34; ] then /bin/echo -n \u0026#34;$prefix$(basename $i | sed -e \u0026#34;s/^jdk//;s/\\.jdk$//;\u0026#34;)\u0026#34; prefix=\u0026#34; | \u0026#34; fi done /bin/echo \u0026#34;\u0026#34; else if [ -z \u0026#34;$JAVA_HOME\u0026#34; ] then export PATH=$base/$sel/Contents/Home/bin:$PATH else export PATH=$(echo $PATH|sed -e \u0026#34;s:$JAVA_HOME/bin:$base/$sel/Contents/Home/bin:g\u0026#34;) fi export JAVA_HOME=$base/$sel/Contents/Home echo -n -e \u0026#34;\\033]0;$(java -version 2\u0026gt;\u0026amp;1 | sed -e \u0026#34;s/.*\\\u0026#34;\\(.*\\)\\\u0026#34;.*/Java \\1/;q\u0026#34;)\\007\u0026#34; fi } There is additional fun to be had, given that most Java based launchers that try to fix JAVA_HOME when not set will guess the Apple JVM path… so the following Java program can help\npublic class FixJavaHome { public static void main(String[] args) { String javaHome = System.getProperty(\u0026#34;java.home\u0026#34;); if (javaHome.endsWith(\u0026#34;/jre\u0026#34;)) { javaHome = javaHome.substring(0,javaHome.length() - \u0026#34;/jre\u0026#34;.length()); } System.out.println(\u0026#34;export JAVA_HOME=\\\u0026#34;\u0026#34;+javaHome+\u0026#39;\\\u0026#34;\u0026#39;); } } Install like so\nmkdir -p ~/bin/FixJavaHome \u0026amp;\u0026amp; cd ~/bin/FixJavaHome \u0026amp;\u0026amp; cat \u0026gt; FixJavaHome.java \u0026lt;\u0026lt;EOF public class FixJavaHome { public static void main(String[] args) { String javaHome = System.getProperty(\u0026#34;java.home\u0026#34;); if (javaHome.endsWith(\u0026#34;/jre\u0026#34;)) { javaHome = javaHome.substring(0,javaHome.length() - \u0026#34;/jre\u0026#34;.length()); } System.out.println(\u0026#34;export JAVA_HOME=\\\u0026#34;\u0026#34;+javaHome+\u0026#39;\\\u0026#34;\u0026#39;); } } EOF javac FixJavaHome.java cd - If you add the following to your ~/.bash_profile\neval $(java -cp ~/bin/FixJavaHome/ FixJavaHome) echo -n -e \u0026#34;\\033]0;$(java -version 2\u0026gt;\u0026amp;1 | sed -e \u0026#34;s/.*\\\u0026#34;\\(.*\\)\\\u0026#34;.*/Java \\1/;q\u0026#34;)\\007\u0026#34; Then your JAVA_HOME should be set up from the start, as well as your Terminal window title\n","date":1359936e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1359936e3,"objectID":"537bc1fde611f79e36d7d769f75242f6","permalink":"https://stephenc.github.io/post/2013-02-04-note-to-self-updated-usejava-bash-function-for-macosx/","publishdate":"2013-02-04T00:00:00Z","relpermalink":"/post/2013-02-04-note-to-self-updated-usejava-bash-function-for-macosx/","section":"post","summary":"For use when you have multiple JVM providers (Apple \u0026 Oracle), you want to be able to switch between JDKs for each CLI\nusejava () { local sel=$1.jdk if [ -x \"/Library/Java/JavaVirtualMachines/jdk$sel/Contents/Home/bin/java\" -a ! -x \"/Library/Java/JavaVirtualMachines/$1/Contents/Home/bin/java\" ] then sel=jdk$sel fi local base=/Library/Java/JavaVirtualMachines if [ -x \"/System/Library/Java/JavaVirtualMachines/$sel/Contents/Home/bin/java\" ] then base=/System/Library/Java/JavaVirtualMachines fi if [ -z \"$1\" -o ! -x \"$base/$sel/Contents/Home/bin/java\" ] then local prefix=\"Syntax: usejava \" for i in /Library/Java/JavaVirtualMachines/* /System/Library/Java/JavaVirtualMachines/* do if [ -x \"$i/Contents/Home/bin/java\" ] then /bin/echo -n \"$prefix$(basename $i | sed -e \"s/^jdk//;s/\\.jdk$//;\")\" prefix=\" | \" fi done /bin/echo \"\" else if [ -z \"$JAVA_HOME\" ] then export PATH=$base/$sel/Contents/Home/bin:$PATH else export PATH=$(echo $PATH|sed -e \"s:$JAVA_HOME/bin:$base/$sel/Contents/Home/bin:g\") fi export JAVA_HOME=$base/$sel/Contents/Home echo -n -e \"\\033]0;$(java -version 2\u003e\u00261 | sed -e \"s/.*\\\"\\(.*\\)\\\".*/Java \\1/;q\")\\007\" fi } There is additional fun to be had, given that most Java based launchers that try to fix JAVA_HOME when not set will guess the Apple JVM path… so the following Java program can help\n","tags":["Shell"],"title":"Note to self: Updated usejava BASH function for MacOSX","type":"post"},{"authors":null,"categories":null,"content":"http://j.mp/TfdoxL a link to a free online iOS app development training course that looks worth checking out\n","date":1356220800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356220800,"objectID":"6ef8f4ad43716bdfb620f7d25ce29ffd","permalink":"https://stephenc.github.io/post/2012-12-23-ios-training-course/","publishdate":"2012-12-23T00:00:00Z","relpermalink":"/post/2012-12-23-ios-training-course/","section":"post","summary":"http://j.mp/TfdoxL a link to a free online iOS app development training course that looks worth checking out\n","tags":null,"title":"iOS traing course","type":"post"},{"authors":null,"categories":null,"content":"Special Symbols and Characters on the regular Mac Keyboard\nThese are for the British Keyboard layout\nCurrency Symbols\nSymbol Key combination $ dollar Shift+4 ¢ cents Option+4 £ pound Shift+3 ¥ yen Option+y € euro Option+2 Trademark and Copyright Symbols\nSymbol Key combination © copyright Option+g ® registered Option+r ™ trademark Option+Shift+2 Apple Symbol\nSymbol Key combination  apple Option+Shift+K Math and Greek Character Symbols\nSymbol Key combination ± plus-or-minus Option+Shift+Equals µ micro Option+h π pi Option+l (as in L is for llama) √ square root Option+t ÷ divided by Option+/ (slash is key to the left of right-hand shift key) · middle dot Option+Shift+9 ≈ almost equal Option+x ≠ not equal Option+= ∞ infinity Option+Shift+T ≤ less than or equal Option+, (comma) ≥ greater than or equal Option+. (period) Å Angstrom sign Option+Shift+K, Shift+A ∑ summation sign Option+Shift+F ° degree sign Option+Shift+0 (zero) ∂ partial differential Option+d ∫ integral Option+Shift+D Ω Omega Option+Shift+Z Copyediting, typesetting, and miscellaneous symbols\nSymbol Key combination ‡ double dagger Option+Shift+semicolon ¶ pilcrow sign Option+7 § section sign Option+5 • bullet sign Option+Shift+8 Punctuation marks\nSymbol Key combination ‘ left single quotation mark Option+] ’ right single quotation mark Option+Shift+] “ left double quotation mark Option+[ ” right double quotation mark Option+Shift+[ « left pointing double angle quotation mark Option+\\ (backslash) » right pointing double angle quotation mark Option+Shift+\\ (backslash) ‹ single left pointing angle quotation mark Option+Shift+3 › single right pointing angle quotation mark Option+Shift+4 ¡ inverted exclamation mark Option+1 ¿ inverted question mark Option+Shift+? … ellipsis Option+; (semicolon) ","date":1351123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1351123200,"objectID":"3af3aae45cc81a9d59fc3d7f191937d1","permalink":"https://stephenc.github.io/post/2012-10-25-note-to-self-mac-keyboard-and-fancy-characters/","publishdate":"2012-10-25T00:00:00Z","relpermalink":"/post/2012-10-25-note-to-self-mac-keyboard-and-fancy-characters/","section":"post","summary":"Special Symbols and Characters on the regular Mac Keyboard\nThese are for the British Keyboard layout\nCurrency Symbols\nSymbol Key combination $ dollar Shift+4 ¢ cents Option+4 £ pound Shift+3 ¥ yen Option+y € euro Option+2 Trademark and Copyright Symbols\nSymbol Key combination © copyright Option+g ® registered Option+r ™ trademark Option+Shift+2 Apple Symbol\nSymbol Key combination  apple Option+Shift+K Math and Greek Character Symbols\nSymbol Key combination ± plus-or-minus Option+Shift+Equals µ micro Option+h π pi Option+l (as in L is for llama) √ square root Option+t ÷ divided by Option+/ (slash is key to the left of right-hand shift key) · middle dot Option+Shift+9 ≈ almost equal Option+x ≠ not equal Option+= ∞ infinity Option+Shift+T ≤ less than or equal Option+, (comma) ≥ greater than or equal Option+. (period) Å Angstrom sign Option+Shift+K, Shift+A ∑ summation sign Option+Shift+F ° degree sign Option+Shift+0 (zero) ∂ partial differential Option+d ∫ integral Option+Shift+D Ω Omega Option+Shift+Z Copyediting, typesetting, and miscellaneous symbols\n","tags":null,"title":"Note to self: Mac Keyboard and ‘fancy’ characters","type":"post"},{"authors":null,"categories":null,"content":"This is a repost of my post on the CloudBees Developers blog\nTL;DR Source control injection attacks are a bigger worry than build tool injection attacks, and if you cannot trust your local filesystem, then you cannot trust anything.\nA few exchanges on twitter have prompted me to write a fuller blog post on the subject of Cross-Build Injection (XBI) Attacks.\nThe idea of XBI is that you trick the developer and replace parts of their code with your code, thereby getting your code to be trusted by the developer.\nI do not object to the theory of XBI. But let’s get real for a minute. Ultimately all the XBI attacks rely on a compromised local file system.\nI am not saying that you cannot apply these attacks to remote systems and then have those affect developers with un-compromised local file systems.\nI am saying that when you fix any remote vectors, you still end up victim of the local file system integrity.\nTake for example this attack vector using Maven as an example victim build tool. How does the attack work? Well it replaces a good artifact in the Maven local repository with a bad version… and bad things happen.\nFor this attack to work for real you need to have your local file system compromised. Is that attack specific to Maven? Nope. You can get your $ANT_HOME/lib folder contents compromised just as easily (i.e. if your local file system cannot be trusted to hold your local repository, it cannot be trusted to hold your build tool) Same too applies to Gradle, Make, MSBuild, etc.\nHow do we prevent the attack? Well for quite some time the central repository has only been publishing artifacts with GPG signatures. So we could verify the GPG signature before each and every build… but those signatures are stored on the file system too, so we cannot trust them… and our GPG checking code is stored on the filesystem also… so we cannot trust that! Never mind that such checks would slow every build down - increasing the risk of the developer being knocked out of “the zone”.\nThe reality of “the zone” is often lost on people. Working memory is only able to retain information for a couple of seconds at a time and therefore any interruptions can be fatal to problem solving processes. Software development is one continuous problem solving process after another. If you add 5 seconds to every build, then that is 5 seconds of temptation for the developer to check their email / reddit / stackoverflow / etc. And then they will have to rebuild the context of the problem they were solving. In some cases, this can correspond to up to 45-50 minutes of zero productivity for the developer (I cannot find the link, but I have personal experiences that confirm this).\nGood developers that recognise this problem will therefore seek to reduce build time to the minimum… therefore turning off any GPG or other integrity checks, etc. If you ask them why, they will probably respond with something like:\nWell if I cannot trust the local filesystem, sure I cannot trust the SCM or the signature checks to even run in the first place. I’m reclaiming those 5 seconds on every build and being more productive.\nWhat is the solution? Simple. Don’t do the checks until you are making the release build! Better yet do the release builds from a continuous integration server such as Jenkins. You can lock that down, have it do the checks for you, and have it sign the resultant artifacts… but just be sure that you trust its filesystem and your source control system too!\n","date":1349740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349740800,"objectID":"e6bf7de063dd3c3ce41808ba5a437468","permalink":"https://stephenc.github.io/post/2012-10-09-the-cross-build-injection-attack-fallacy/","publishdate":"2012-10-09T00:00:00Z","relpermalink":"/post/2012-10-09-the-cross-build-injection-attack-fallacy/","section":"post","summary":"This is a repost of my post on the CloudBees Developers blog\nTL;DR Source control injection attacks are a bigger worry than build tool injection attacks, and if you cannot trust your local filesystem, then you cannot trust anything.\nA few exchanges on twitter have prompted me to write a fuller blog post on the subject of Cross-Build Injection (XBI) Attacks.\nThe idea of XBI is that you trick the developer and replace parts of their code with your code, thereby getting your code to be trusted by the developer.\n","tags":["Maven","Jenkins"],"title":"The Cross-Build Injection Attack Fallacy","type":"post"},{"authors":null,"categories":null,"content":" Hamlet: … for there is nothing either good or bad, but thinking makes it so.\n— Hamlet Act 2, scene 2, 239–251, William Shakespeare\nThe Apache Software Foundation is a meritocracy. By this we mean that you gain status based on the merit of your work and actions. In fact the status that you gain is a recognition of the merit of your work and actions.\nMaven is an Apache project, that means that we have to follow the Apache rules and way. One of those rules is that we cannot hand out commit access to anyone who asks for it.\nTo gain commit access you must establish your merit by submitting patches that get picked up by existing committers.\nAfter you have contributed enough patches to establish merit, the project management committee decides whether you can be trusted with commit access.\nQuestion Is this a good way to manage commit access?\nThere was a reason for the Hamlet quote that I opened this post with.\nOther communities can do things differently, for example the Jenkins project which I am also involved with gives out commit access to anyone who cares to ask for it… but commit access to core requires completing some paperwork, and access to infrastructure requires that you establish your merit.\nWhich is better? It all depends on who is asking and what they mean by better.\nThe reality is that “It is what it is”\nTL;DR To become a Maven committer write good patches and get them applied.\nWhat makes a good patch?\nA good patch is a patch that applies cleanly and includes tests that cover both the positive and negative case and has documentation where relevant.\nFor example, if you were implementing a patch to fix MNG-4612 you would first need to write a test case that is failing when trying to encrypt\n{DESede}y+qq...== and a second test case that is passing when trying to encrypt\npassword This is in order to be sure that you have written an effective test case that can pass for good data. Then you implement the fix and all the tests should pass. You then take a Subversion compatible1 diff of the source code and attach that to the issue in question.\nTo understand how your patch gets evaluated, here is how I apply patches:\nI look at the actual diff, if there is a whole lot of formatting changes irrelevant to the issue being fixed =\u0026gt; Patch is no good, ask on JIRA for a clean patch\nI look at the list of files in the diff, if there are no tests =\u0026gt; Patch is no good, ask on JIRA for test cases\nI look at the issue and if the issue requires documentation be updated and there is no documentation changes in the patch =\u0026gt; Patch is no good, ask on JIRA for documentation changes in the patch\nI take a clean checkout of the source that the patch applies to and try to apply the patch… if it does not apply clean =\u0026gt; Patch is no good, ask on JIRA for an updated patch\nI revert the src/main and run the tests. If the tests all pass, then there are no test cases to catch the bug =\u0026gt; Patch is no good, ask on JIRA for proper tests\nI revert src and run the tests. If any tests fail, then there is something wrong with the existing code =\u0026gt; If I have time I might try and fix the issue, otherwise I just move on\nI apply the patch a second time and run the tests. If the tests all pass =\u0026gt; Patch is good, I commit the patch and mark the JIRA as resolved.\nSo there you have it, my guide to writing good patches… now the next step is getting your patches noticed…\nHow to get your patches noticed The simplest way to get your patches noticed is to submit them to the JIRA issue that they fix.\nRemember that the Maven project is run by volunteers in their spare time, so very often we may not notice your patch for a few days.\nIf you are certain that your patch is a good patch, and a week has passed with no comments on JIRA, then you should send one and only one email to the dev@maven.apache.org mailing list to see if your patch can get noticed.\nNote You need to be fairly confident that your patch is a good patch, because if you keep on pestering the Maven developers looking to have non-good patches applied, your merit will become negative and people will be less inclined to help you get your patches applied… also this is why you should send one and only one email about your patch on any specific JIRA issue.\nStephen, Arnaud \u0026amp; Barrie’s school for potential Maven committers To help people who are interested in becoming Maven committers fulfill their goals, myself, Arnaud Heritier and Barrie Treloar (along with any other current Maven committers who decide to help) will be running an assignment based class to help people become committers.\nTo register for the class you need to complete the following steps:\nRead the Apache Individual Contributor License Agreement. When you graduate from the class you will be required to sign this in order to become a committer.\nSubscribe to the dev@maven.apache.org mailing list.\nSend an email to the list with the Subject line:\n[Committer School] I would like to become a committer and the Message body:\nI am interested in the following …","date":1341964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341964800,"objectID":"a204f516c00f41e3d6fd4e0424567575","permalink":"https://stephenc.github.io/post/2012-07-11-do-you-want-to-become-a-maven-committer/","publishdate":"2012-07-11T00:00:00Z","relpermalink":"/post/2012-07-11-do-you-want-to-become-a-maven-committer/","section":"post","summary":" Hamlet: … for there is nothing either good or bad, but thinking makes it so.\n— Hamlet Act 2, scene 2, 239–251, William Shakespeare\nThe Apache Software Foundation is a meritocracy. By this we mean that you gain status based on the merit of your work and actions. In fact the status that you gain is a recognition of the merit of your work and actions.\nMaven is an Apache project, that means that we have to follow the Apache rules and way. One of those rules is that we cannot hand out commit access to anyone who asks for it.\n","tags":["Maven"],"title":"Do you want to become a Maven Committer?","type":"post"},{"authors":null,"categories":null,"content":"With Java Generics, it can be useful to insert wildcards wherever possible, but how do you decide which wildcard is correct? When do you use ? super T, ? extends T and when should you not use a wildcard at all.\nThe Get and Put principle: Use an extends wildcard when you only get values from the structure. Use a super wildcard when you only put values into the structure. Don’t use a wildcard when you both get and put values from/into the structure.\nThe best example of this principle is the following copy method signature:\npublic static \u0026lt;T\u0026gt; void copy( Collection\u0026lt;? super T\u0026gt; destination, Collection\u0026lt;? extends T\u0026gt; source); The method gets values out of the source, so source uses extends, and it puts values into the destination, so that is declared with the super wildcard.\n","date":1319414400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1319414400,"objectID":"c2210258ba0051debf47efb36fcaf827","permalink":"https://stephenc.github.io/post/2011-10-24-note-to-self-java-generics-the-get-and-put-principle/","publishdate":"2011-10-24T00:00:00Z","relpermalink":"/post/2011-10-24-note-to-self-java-generics-the-get-and-put-principle/","section":"post","summary":"With Java Generics, it can be useful to insert wildcards wherever possible, but how do you decide which wildcard is correct? When do you use ? super T, ? extends T and when should you not use a wildcard at all.\nThe Get and Put principle: Use an extends wildcard when you only get values from the structure. Use a super wildcard when you only put values into the structure. Don’t use a wildcard when you both get and put values from/into the structure.\n","tags":null,"title":"Note to self: Java Generics - The Get and Put principle","type":"post"},{"authors":null,"categories":null,"content":"Cmd+Shift+4 followed by Space is a lovely way to get a screen shot of a window on an Apple Mac…\nIn fact here is one such screenshot:\nNotice the nice shadow effect around the screenshot? Ever wanted to add that shadow effect to your non-mac screenshots?\nImageMagick is your friend\nconvert NoShadowScreenshot.png \\( +clone -background black -shadow 80x20+0+15 \\) \\ +swap -background transparent -layers merge +repage WithShadowScreenshot.png There you are, nice equivalent shadow added.\nOh and if you hate the Mac’s shadow:\nTo remove from existing screenshots?\nImageMagick is your friend again\nconvert WithShadowScreenshot.png -crop +40+25 -crop -40-55 WithoutShadowScreenshot.png If you get sick of doing that all the time, you can just disable it.\nHere’s the command. Just paste this line into your Terminal, and press return.\ndefaults write com.apple.screencapture disable-shadow -bool true Then, you’ll need to restart the System’s UI Server, which is the component of the operating system responsible for doing things like taking screenshots and drawing drop shadows. To accomplish this, simply paste this line into the Terminal.\nkillall SystemUIServer ","date":1318982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1318982400,"objectID":"fdfdb3c0137541fbc932426da4619d94","permalink":"https://stephenc.github.io/post/2011-10-19-how-to-add-mac-like-shadow-to-your-screenshots/","publishdate":"2011-10-19T00:00:00Z","relpermalink":"/post/2011-10-19-how-to-add-mac-like-shadow-to-your-screenshots/","section":"post","summary":"Cmd+Shift+4 followed by Space is a lovely way to get a screen shot of a window on an Apple Mac…\nIn fact here is one such screenshot:\nNotice the nice shadow effect around the screenshot? Ever wanted to add that shadow effect to your non-mac screenshots?\nImageMagick is your friend\nconvert NoShadowScreenshot.png \\( +clone -background black -shadow 80x20+0+15 \\) \\ +swap -background transparent -layers merge +repage WithShadowScreenshot.png There you are, nice equivalent shadow added.\n","tags":null,"title":"How to add Mac-like shadow to your screenshots","type":"post"},{"authors":null,"categories":null,"content":"Java has a couple of “nice” features, specifically:\nBuilt-in locks\nBaked in support for object serialization\nNow I don’t want to get into a war about how both of these are flawed (there was a reason that I put “nice” in quotes) but here is a quick note on how to make the two play nice (more as a reference to myself… but if others find this useful, well and good).\nGeneral principal In essence, in each case you implement the readObject and writeObject methods per the Java Object Serialization Specification.\nUsing object’s intrinsic lock In this case you can just make the readObject and writeObject methods synchronized:\nprivate synchronized void readObject(ObjectInputStream stream) throws ClassNotFoundException, IOException { stream.defaultReadObject(); } private synchronized void writeObject(ObjectOutputStream stream) throws IOException { stream.defaultWriteObject(); } Using Java 5 style locks In this case you just wrap the functionality inside a try…finally block\nprivate void readObject(ObjectInputStream stream) throws ClassNotFoundException, IOException { lock.lock(); try { stream.defaultReadObject(); } finally { lock.unlock(); } } private void writeObject(ObjectOutputStream stream) throws IOException { lock.lock(); try { stream.defaultWriteObject(); } finally { lock.unlock(); } } Using multiple locks If your object uses multiple locks to guard the different fields, there are really two techniques you can use:\nGet all the locks in one go, ensuring that you always get multiple locks in the same sequence (high-risk)\nStop relying on stream.default____Object() and get/set each field manually in code as that allows you to hold one lock at a time (may write a partially modified object)\nGotchas Watch out for the fields you are writing being mutable and modified by other threads while you are writing them to the stream. Reads from a stream are less of an issue as the object should not be given to another thread until fully read back in.\n","date":1313366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1313366400,"objectID":"36fa8ab6ec9dd54a180fbaac8b8f731b","permalink":"https://stephenc.github.io/post/2011-08-15-java-serialization-and-locks/","publishdate":"2011-08-15T00:00:00Z","relpermalink":"/post/2011-08-15-java-serialization-and-locks/","section":"post","summary":"Java has a couple of “nice” features, specifically:\nBuilt-in locks\nBaked in support for object serialization\nNow I don’t want to get into a war about how both of these are flawed (there was a reason that I put “nice” in quotes) but here is a quick note on how to make the two play nice (more as a reference to myself… but if others find this useful, well and good).\n","tags":null,"title":"Java Serialization and locks","type":"post"},{"authors":null,"categories":null,"content":"Book review: “EJB 3.1 Cookbook” by Richard M. Reese Review The kind people at Packt gave me a copy of “EJB 3.1 Cookbook” by Richard M. Reese to review. This book should be viewed as a collection of building block recipes, not as a collection of meal plans, and not as a how to cook book that you would read from cover to cover. When I look at the book from this point of view, I think that it is well structured and put together and the content is pitched just about right. This book does not tell you when to use a specific recipe, so it would be a mistake to think that this is the only book you would need for EJB 3.1. However, when you need a “Béchamel sauce”, this is a book that you can go to, quickly find and open up the right section and read the recipe to refresh your mind and get cooking.\nThe book itself is aimed at Java EE and EJB developers, promising to bring them quickly up to speed on how to use EJB 3.1 techniques through the use of step-by-step examples. I think that the back cover of this book could be designed a little better in terms of putting the book into context with regards to skill level and where the book should sit in a learning tree. In my view this book should be aimed for three audiences: the occasional EJB developer who has to work on other things a lot; the intermediate EJB developer who is moving to the EJB 3.1 platform from a previous release; and the beginning EJB 3.1 developer who has just read their first book or two on EJB 3.1 and now is trying to develop EJB 3.1 applications.\nThe cookbook format works well for a reference book when you know that you need to do XYZ, it will have a section that you can find quickly, and that section will be easy to find and contain some of the common tricks and pitfalls that apply to doing XYZ. When reviewing this book it is all too easy to fall into the “as an EJB architect” trap and point out that the book does not tell you when to do XYZ or how to decide between XYZ and ABC. Architects should not be reading cookbooks to find the answers to these kinds of questions.\nThere are some specific criticisms that I have with this book:\nThe book says that it uses Netbeans and Glassfish. To be honest I found very little in the book that is specific to either, and I think that the author would have been better off saying that all the examples were tested on Glassfish (which, as the reference implementation, should guarantee that they will work on all EJB 3.1 containers) and that IDE examples used Netbeans.\nChapter 11 covers packaging the EJBs, yet it does not cover or even hint at how to achieve this using the build tools that most developers use, e.g. ANT, Maven, etc. I think chapter 11 would be significantly enhanced if it included at least “Packaging EJBs using Apache ANT” and “Packaing EJBs using Apache Maven” recipes. Recipes for some of the other newer build tools like Buildr would be a bonus, but one could be forgiven for leaving them out.\nThere is no chapter on testing EJBs. In fact there are no testing recipes at all. No developer should be writing code without tests. At a minimum I would like to see a recipes like “Unit testing EJBs with mocking frameworks”, “Testing EJBs using OpenEJB’s embeddable container”, “Testing EJBs using JBoss’s embeddable container”, “Testing EJBs using Glassfish’s embeddable container”. I’m sure books could be written on the fine arts of each of these recipes but a book like this should at least be sketching out that this kind of thing is possible.\nDespite these criticisms, the recipes that it does provide are clearly written and well set out in a consistent format. I specifically liked the “There’s more” section that each recipe has. If you try to read this book cover to cover you will be annoyed at the repetition, but then cookbooks are not meant to be read that way!\nI would recommend this book for beginner and intermediate level developers who are either occasionally working with EJB 3.1 or who are moving from a previous version of EJB to 3.1. More advanced developers may not find many recipes that interest them, and architects will not find any guides about how to pick which recipes to combine to make the meal.\nOverall: 6 out 10.\nBook details URL: http://www.packtpub.com/ejb-3-1-cookbook/book\nPublisher: Packt Publishing\nLanguage: English\nPaperback: 436 pages [ 235mm x 191mm ]\nRelease Date: June 2011\nISBN: 1849682380\nISBN 13: 978-1-84968-238-1\nAuthor(s): Richard M. Reese\n","date":1313020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1313020800,"objectID":"23e337a03322776872e6e1f2a6d227af","permalink":"https://stephenc.github.io/post/2011-08-11-ejb3.1-cookbook-review/","publishdate":"2011-08-11T00:00:00Z","relpermalink":"/post/2011-08-11-ejb3.1-cookbook-review/","section":"post","summary":"Book review: “EJB 3.1 Cookbook” by Richard M. Reese Review The kind people at Packt gave me a copy of “EJB 3.1 Cookbook” by Richard M. Reese to review. This book should be viewed as a collection of building block recipes, not as a collection of meal plans, and not as a how to cook book that you would read from cover to cover. When I look at the book from this point of view, I think that it is well structured and put together and the content is pitched just about right. This book does not tell you when to use a specific recipe, so it would be a mistake to think that this is the only book you would need for EJB 3.1. However, when you need a “Béchamel sauce”, this is a book that you can go to, quickly find and open up the right section and read the recipe to refresh your mind and get cooking.\n","tags":null,"title":"Book review: “EJB 3.1 Cookbook” by Richard M. Reese","type":"post"},{"authors":null,"categories":null,"content":"There has been this idea running around the back of my head for a while, and it’s only now that it is starting to crystalize into something that I can express.\nWhen we look at Open Source projects, we see that there is a hierarchy of involvement. There are different levels at which you can be involved, and at each higher level, there will be less and less individuals. For now I am going to divide involvement up like this:\nInterested: this group of individuals know that the project exists, and might even be following what it is doing, but have not been able to actually use the project at all yet (for whatever reason)\nConsumers: these are the people who actually use the project. They may not even be following the project, e.g. a lot of people consume log4j or ANT without following the mailing lists, seeing what features are on the roadmap, or even filing issues.\nContributors: if you are filing issues, submitting patches, etc, but you do not have commit access to the project, then you are a Contributor.\nCommitters: you have commit access to the project\nManagement: you get to have a say in some of the following: whether the new release of a project can be released; the architecture/direction of the project going forward; who has commit access; etc.\nDifferent Open Source projects but different barriers at different points. For example:\nContributor road-blocks:\nYou may have to create an account to file issues. [Technical]\nYou may have to sign a CLA and fax it off before you can commit any patches. [Legal]\nYou may have to get a notarized signed CLA sent via snail-mail before you can commit any patches. [Legal]\nYou may have to get your employer to sign-off on you contributing patches. [Legal]\nCommitter road-blocks:\nYou may have to be invited to become a committer.\nYou may have to establish merit before you can be invited to become a committer.\nYou may have to sign a CLA and fax it off before you can get commit access. [Legal]\nYou may have to get a notarized signed CLA sent via snail-mail before you can get commit access. [Legal]\nYou may have to get your employer to sign-off on you committing code to the project. [Legal]\nManagement road-blocks:\nYou may have to be invited to become management.\nYou may have to establish merit before you can be invited to become management.\nNote I’m not going to even try and pretend that the above is a complete list of road-blocks\nDifferent people view success of Open Source projects differently. Some measures of success include: the number of consumers; the number of active contributors; the number of committers; the number of releases; the number of downloads; the number of issues raised and closed; the activity of mailing lists.\nNone of these are correct, and much like psychologists hypothesize a (in reality) unmeasurable “g factor” as a true measure of intelligence against which all real measures (such as IQ) are only partial measures. We could hypothesize an unmeasurable “s factor” which is the true measure of the success of an Open Source project.\nBut I don’t want to go down such an academic road today. Instead lets look at the dependency tree in the measures of success that we know of…\nNumber of downloads depends on number of consumers: as a consumer has to download your project at least once… it is not a perfect dependency, because you could download each release of the project once and every time decide it is a load of rubbish and never actually consume it… and a consumer may have just downloaded version 1.0 once and stayed on that version for ever more, but in general, if you have a large number of consumers, you will have a large number of downloads and the opposite does not necessarily follow.\nActivity of mailing lists depends on the number of active contributors: when you have a lot of active contributors, the mailing lists will be active… however the mailing lists can be active without any active contributors.\nNumber of issues raised depends on the number of active contributors: for similar reasons to the previous.\nNumber of issues closed depends on the number of committers: because you need commit access to close most issues (appart from the “not a bug” type of issues)\nSo a lot of the measures of success can be raised by increasing the number of consumers, active contributors, and committers. However, just because we have a large number of consumers/active contributors/committers does not imply that we have a successful project, it just says that projects that have a large number of consumers/active contributors/committers have a greater likelihood of being successful projects.\nSo how do we increase that number, and thereby increase the probability that our Open Source project is a “success”?\nWell, if you are picking an project to use, i.e. deciding to become a consumer, one of the things you will look at is how active the community is (i.e. number of active contributors and number of committers). It’s not the only thing you will look at, but assuming you have two …","date":1312416e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1312416e3,"objectID":"c0c29f3d2349e412f72d0c9f45c331eb","permalink":"https://stephenc.github.io/post/2011-08-04-open-source-the-meritocracy-vs-the-circle-of-trust/","publishdate":"2011-08-04T00:00:00Z","relpermalink":"/post/2011-08-04-open-source-the-meritocracy-vs-the-circle-of-trust/","section":"post","summary":"There has been this idea running around the back of my head for a while, and it’s only now that it is starting to crystalize into something that I can express.\nWhen we look at Open Source projects, we see that there is a hierarchy of involvement. There are different levels at which you can be involved, and at each higher level, there will be less and less individuals. For now I am going to divide involvement up like this:\n","tags":null,"title":"Open Source: the Meritocracy vs the Circle of Trust","type":"post"},{"authors":null,"categories":null,"content":"In relation to http://dhanji.github.com/#unit-tests-false-idol here is the tail of the worst test case I ever came across…\nIn a former employers, there was an employee who we will call Kevin McCallister in order to protect the guilty. In any case, for various reasons, I ended up having to maintain some of the code that Kevin wrote…\nI ran all the test cases and measured the code coverage, it seemed high and there were lots of test cases… but bugs a plenty kept on hitting me… I finally found the answer in one test class… which looked a little something like this:\n/** * Tests the FooBar class * @author Kevin McCallister */ public void FooBarTest { @Test public void smokes() { try { new FooBar().method1(); } catch (Throwable t) {} try { new FooBar().method2(); } catch (Throwable t) {} try { new FooBar().method3(); } catch (Throwable t) {} // ... try { new FooBar().method15(); } catch (Throwable t) {} // ... try { new FooBar().method30(); } catch (Throwable t) {} } @Test public void method1DoesSomething() { // write later } @Test public void method1DoesSomethingElse() { // write later } @Test public void method1DoesAnotherThing() { // write later } @Test public void method1DoesSomethingWhenFoo() { // write later } @Test public void method1DoesSomethingWhenBar() { // write later } @Test public void method1DoesSomethingWhenBarAfterFoo() { // write later } @Test public void method1DoesSomethingWhenFooAfterBar() { // write later } // ... } To make myself clear, there was one method at the top that called every function and would never fail (gives you the code coverage) and a couple of hundred empty test methods that did nothing but had names that sounded like nice test cases…\nSo there you have it, how not to write unit tests\n","date":1306713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1306713600,"objectID":"54d48ea898a4362d924728ace5190c9b","permalink":"https://stephenc.github.io/post/2011-05-30-the-worst-unit-tests-i-ever-saw/","publishdate":"2011-05-30T00:00:00Z","relpermalink":"/post/2011-05-30-the-worst-unit-tests-i-ever-saw/","section":"post","summary":"In relation to http://dhanji.github.com/#unit-tests-false-idol here is the tail of the worst test case I ever came across…\nIn a former employers, there was an employee who we will call Kevin McCallister in order to protect the guilty. In any case, for various reasons, I ended up having to maintain some of the code that Kevin wrote…\nI ran all the test cases and measured the code coverage, it seemed high and there were lots of test cases… but bugs a plenty kept on hitting me… I finally found the answer in one test class… which looked a little something like this:\n","tags":null,"title":"The worst Unit Tests I ever saw","type":"post"},{"authors":null,"categories":null,"content":"This is a tail about Jenkins (née Hudson) and Kohsuke’s policy of maintaining backwards compatibility…\nBack in 2006 I started working for my previous employer, just a month or two after Peter Reilly started. Initially we were working on the same team. This was a team who’s CI system was a nightly cron job that emailed off a list of failing tests to everyone… obviously Peter and I had many a WTF over that old system… so I convinced our boss that we should put some effort into setting up a proper CI system… Initially this was CruiseControl (as he thought Hudson at version 1.64 was too new and unheard of… go with the old reliable)… but after a couple of pains with the CruiseControl system (monolithic xml config file), we convinced him to switch to Hudson… (I don’t think we ever looked back!)\nWhat we really liked was that Kohsuke had put in place a plugin framework, so I started writing plugins, and shortly afterwards convinced Peter that it was “cool” (even if he did have to use Maven to build the plugins - Peter is on the Apache ANT PMC).\nOne of the earlier plugins that Peter wrote during his spare time was his “Simple Cobertura plugin” which allowed you to get the Cobertura coverage results on the build page[1]. Peter created his plugin against Hudson 1.129. By this stage Peter and I had moved onto separate projects, eventually Peter left the company, but the team he was working on still had the .hpi for his “Simple Cobertura plugin”. As they moved to newer and newer Hudson builds, the plugin kept on working (no recompile needed). I had my own plugins which were built for an earlier version of Hudson (my closed source SilkTest plugin, my original closed source AccuRev plugin [not to be confused with the open source one I subsequently developed and handed on to others to maintain]) which also were still working (with no recompile) in newer versions of Hudson\nRecently, I met up with Peter, and he told me the sad news…. his plugin is now broken… it no longer works in the latest version of Jenkins… this was strange news to me, as before I left my previous employer to join CloudBees I’d upgraded our CI servers to the latest and one of those was using Peter’s “Simple Cobertura plugin” which did not seem broken…\nAfter looking at Peter’s code I finally found the problem… he was using the old javadoc annotation to mark the constructor as one for data binding, with one simple change:\n6,7d5\n\u0026lt; import org.kohsuke.stapler.DataBoundConstructor;\n\u0026lt;\n22a21\n* @stapler-constructor 24d22\n\u0026lt; @DataBoundConstructor\nHis plugin was back in action… Now I was puzzled, as I couldn’t understand how I’d upgraded this old old plugin from Hudson 1.129 and got it running on Jenkins 1.397 without recompiling…\nWell I found out the answer, the version Peter had left in behind, didn’t use the data bound constructor at all… it was doing\npublic Publisher newInstance(StaplerRequest req) throws FormException {\nreturn new C2Publisher(req.getParameter(“c2_coverReportDir”));\n}\nWhile the code Peter had was doing public C2Publisher newInstance(StaplerRequest req, JSONObject obj)\nthrows FormException {\nreturn req.bindParameters(C2Publisher.class, “c2_”);\n}\nIf you change it back to the old way, and you have enough Maven-foo to build against that old a version of Jenkins (née Hudson) you can end up with a plugin that works on both Hudson 1.129 and Jenkins 1.413…\nI am fairly sure that if I had a SilkTest license and a copy of the SilkTest plugin that I wrote against Hudson 1.96, it would also still run unmodified on Jenkins 1.413.\nHow many projects can maintain that level of backwards compatibility.\n[1] Peter wanted to have the coverage results on the main page, and at the time Kohsuke did not want to allow plugins to add columns to the main page… I came up with the compromise of adding a column which would be just one icon wide and have a tooltip to which plugins could contribute information… and that was the birth of the weather (health) icons[2]\n[2] at the time Peter thought it would be cool if he could generate his own weather icon on the fly so that if you had high code coverage that would be a full umbrella while poor code coverage would be a tattered umbrella with no fabric and only the frame remaining… this is actually part of the API, so the technology to implement this has been there since 1.115… just nobody has done it… yet!\n","date":1304208e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1304208e3,"objectID":"5439e1d8e9eef1b8b6d96032e377423d","permalink":"https://stephenc.github.io/post/2011-05-01-backwards-compatibility/","publishdate":"2011-05-01T00:00:00Z","relpermalink":"/post/2011-05-01-backwards-compatibility/","section":"post","summary":"This is a tail about Jenkins (née Hudson) and Kohsuke’s policy of maintaining backwards compatibility…\nBack in 2006 I started working for my previous employer, just a month or two after Peter Reilly started. Initially we were working on the same team. This was a team who’s CI system was a nightly cron job that emailed off a list of failing tests to everyone… obviously Peter and I had many a WTF over that old system… so I convinced our boss that we should put some effort into setting up a proper CI system… Initially this was CruiseControl (as he thought Hudson at version 1.64 was too new and unheard of… go with the old reliable)… but after a couple of pains with the CruiseControl system (monolithic xml config file), we convinced him to switch to Hudson… (I don’t think we ever looked back!)\n","tags":["Jenkins","CloudBees"],"title":"Backwards compatibility","type":"post"},{"authors":null,"categories":null,"content":"In my previous post showed how easy it is to run your java application on CloudBees’ RUN@cloud service. Today I’m going to use the CloudBees Deployer plugin for Jenkins that allows you to deploy your app to the cloud from your CI server. I am using the DEV@cloud Jenkins service for my CI infrastructure, but you can use this plugin from your own Jenkins (or Nectar) server.\nSo first step is to install the CloudBees Deployer plugin…\nGoto Manage Jenkins\nGoto Manage Plugins3. Goto the Available tab4. Scroll down until you find the cloudbees-deployer-plugin. Check the box.5. Scroll down and click the Install button6. Restart Jenkins after it’s installed.7. Goto Manage Jenkins, select Configure and scroll down to the bottom8. Click the Add button beside the CloudBees accounts9. Add in your CloudBees account details (which you can find on your user keys screen on grandcentral)10. Click on Save and then goto the Configure page for your project. Enable CloudBees Deployment and fill in the details: 11. Save and then kick off a build12. When the build is finished, your application has been deployed:There you go. Continuous Deployment on RUN@cloud.\nThere is a whole host of things you can do with this. You can use build promotion to trigger the deployment, you can set up a staging deployment followed by the real thing if a test staging project builds successfully… I could go on… but there is always another day! Speaking of which, my next step will probably be enabling deployment straight from the project build (for those unfortunate enough to not have a CI server) probably using the ship-maven-plugin\n","date":1304208e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1304208e3,"objectID":"5fa786bab679606c8fc8bf002e188abb","permalink":"https://stephenc.github.io/post/2011-05-01-continuously-deploy-your-java-apps-to-the-cloud/","publishdate":"2011-05-01T00:00:00Z","relpermalink":"/post/2011-05-01-continuously-deploy-your-java-apps-to-the-cloud/","section":"post","summary":"In my previous post showed how easy it is to run your java application on CloudBees’ RUN@cloud service. Today I’m going to use the CloudBees Deployer plugin for Jenkins that allows you to deploy your app to the cloud from your CI server. I am using the DEV@cloud Jenkins service for my CI infrastructure, but you can use this plugin from your own Jenkins (or Nectar) server.\nSo first step is to install the CloudBees Deployer plugin…\n","tags":["CloudBees"],"title":"Continuously deploy your java apps to the cloud","type":"post"},{"authors":null,"categories":null,"content":"I work for CloudBees Inc., they are a great company with great products. I have mostly been working on the DEV@ side of the fence which is focused on continuous integration and basically the development side of your application, but we also have the RUN@ side of the fence where we provide a platform as a service (PaaS) for running your java web applications on the cloud. I could give you the sales pitch, but I’ll leave it at: the technologies and people behind RUN@ were one of the key reasons why I decided to join CloudBees.\nWell I’ve been busy on some stuff since joining, so I decided it was time to actually try out the RUN@ stuff for my self. So here is my experience:\nMy test application:\nI’m on the Apache Maven PMC, so I’m going to build it with… shock… horror… Maven.\nI am partial to the odd bit of JSF, so it will be a JSF 2.0 application based off of Apache MyFaces.\nI love Jetty as a servlet container for local testing, so we’ll use that hammer too.\nLet’s get started…\nFirst the pom.xml\n\u0026lt;project xmlns=“http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=“http://www.w3.org/2001/XMLSchema-instance\u0026#34;\nxsi:schemaLocation=“http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt;\n4.0.0\ncom.blogspot.javaadventure.cloudbees.run\njsf2-hello-world\n0.1-SNAPSHOT\nwar\nJSF 2.0 Hello World\nA JSF 2.0 web application that says hello world.\n\u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt;\n\u0026lt;project.build.outputEncoding\u0026gt;UTF-8\u0026lt;/project.build.outputEncoding\u0026gt;\n\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\norg.apache.myfaces.core\nmyfaces-api\n2.0.5\norg.apache.myfaces.core\nmyfaces-impl\n2.0.5\njunit\njunit\n4.8.2\ntest\nmaven-clean-plugin\n2.4.1\nmaven-compiler-plugin\n2.3.2\n1.6\n1.6\nmaven-deploy-plugin\n2.6\nmaven-failsafe-plugin\n2.8.1\nintegration-test\nverify\nmaven-install-plugin\n2.3.1\nmaven-jar-plugin\n2.3.1\nmaven-surefire-plugin\n2.8.1\nmaven-release-plugin\n2.1\nmaven-resources-plugin\n2.5\norg.mortbay.jetty\njetty-maven-plugin\n8.0.0.M2\nmaven-release-plugin\ntrue\ninstall\nThen the src/main/webapp/WEB-INF/web.xml\n\u0026lt;web-app version=“2.5” xmlns=“http://java.sun.com/xml/ns/javaee\u0026#34;\nxmlns:xsi=“http://www.w3.org/2001/XMLSchema-instance\u0026#34;\nxsi:schemaLocation=“http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt;\nJSF 2.0 Hello World\nA JSF 2.0 web application that says hello world.\njavax.faces.STATE_SAVING_METHOD\nserver\njavax.faces.DEFAULT_SUFFIX\n.xhtml\njavax.faces.FACELETS_SKIP_COMMENTS\ntrue\njavax.faces.PROJECT_STAGE\nProduction\norg.apache.myfaces.webapp.StartupServletContextListener\nFaces Servlet\njavax.faces.webapp.FacesServlet\n1\nFaces Servlet\n*.xhtml\n60\nindex.xhtml\nThen the backing bean (src/main/java/com/blogspot/javaadventure/cloudbees/run/GreeterBean.java)\npackage com.blogspot.javaadventure.cloudbees.run;\nimport javax.faces.bean.ManagedBean;\nimport javax.faces.bean.ViewScoped;\nimport java.io.Serializable;\n@ManagedBean(name=“greeter”)\n@ViewScoped\npublic class GreeterBean implements Serializable {\nprivate String name;\npublic String getName() {\nreturn name;\n}\npublic void setName(String name) {\nthis.name = name;\n}\npublic String getResponse() {\nif (name != null \u0026amp;\u0026amp; !name.isEmpty()) {\nreturn “Hello \u0026#34; + name;\n} else {\nreturn null;\n}\n}\n}\nShould always have some tests (src/test/java/com/blogspot/javaadventure/cloudbees/run/GreeterBeanTest.java)\npackage com.blogspot.javaadventure.cloudbees.run;\nimport org.junit.Test;\nimport static org.hamcrest.CoreMatchers.*;\nimport static org.junit.Assert.*;\npublic class GreeterBeanTest {\n@Test\npublic void nullNameMeansNoGreeting() throws Exception {\nGreeterBean instance = new GreeterBean();\ninstance.setName(null);\nassertThat(instance.getResponse(), nullValue());\n}\n@Test\npublic void noNameMeansNoGreeting() throws Exception {\nGreeterBean instance = new GreeterBean();\ninstance.setName(””);\nassertThat(instance.getResponse(), nullValue());\n}\n@Test\npublic void aNameMeansGreeting() throws Exception {\nGreeterBean instance = new GreeterBean();\ninstance.setName(“Fred”);\nassertThat(instance.getResponse(), notNullValue());\n}\n}\nNext the page of our web application (src/main/webapp/index.xhtml), i’m going to use the JSF 2.0 ajax support (because it’s there)\nxmlns:ui=“http://java.sun.com/jsf/facelets\u0026#34;\nxmlns:h=“http://java.sun.com/jsf/html\u0026#34;\nxmlns:f=“http://java.sun.com/jsf/core\u0026#34;\u0026gt;\n\u0026lt;ui:insert name=“metadata”/\u0026gt;\n\u0026lt;h:head\u0026gt;\nJSF 2.0 Hello World\n\u0026lt;/h:head\u0026gt;\n\u0026lt;h:body\u0026gt;\n\u0026lt;f:view\u0026gt;\n\u0026lt;h:form\u0026gt;\n\u0026lt;h:outputLabel for=“greeter” value=“Please tell me your name:”/\u0026gt;\n\u0026lt;h:inputText id=“greeter” value=”#{greeter.name}\u0026#34;\u0026gt;\n\u0026lt;f:ajax event=“keyup” render=“text”/\u0026gt;\n\u0026lt;/h:inputText\u0026gt;\n\u0026lt;/h:form\u0026gt;\n\u0026lt;h:outputText id=“text” value=\u0026#34;${greeter.response}”/\u0026gt;\n\u0026lt;/f:view\u0026gt;\n\u0026lt;/h:body\u0026gt;\nLet’s test it locally\n$ mvn jetty:run[INFO] Scanning for projects…\n[INFO]\n[INFO] ————————————————————————\n[INFO] Building JSF 2.0 Hello World 0.1-SNAPSHOT\n[INFO] ————————————————————————\n[INFO]\n…WARNING:\n*** WARNING: Apache MyFaces-2 is running in DEVELOPMENT mode. ***\n*** ^^^^^^^^^^^ ***\n*** Do NOT deploy to your live server(s) without …","date":1304208e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1304208e3,"objectID":"2867c52a03d3eac50369b85d7baafdfe","permalink":"https://stephenc.github.io/post/2011-05-01-deploy-your-java-apps-to-the-cloud/","publishdate":"2011-05-01T00:00:00Z","relpermalink":"/post/2011-05-01-deploy-your-java-apps-to-the-cloud/","section":"post","summary":"I work for CloudBees Inc., they are a great company with great products. I have mostly been working on the DEV@ side of the fence which is focused on continuous integration and basically the development side of your application, but we also have the RUN@ side of the fence where we provide a platform as a service (PaaS) for running your java web applications on the cloud. I could give you the sales pitch, but I’ll leave it at: the technologies and people behind RUN@ were one of the key reasons why I decided to join CloudBees.\n","tags":["CloudBees"],"title":"Deploy your java apps to the cloud","type":"post"},{"authors":null,"categories":null,"content":"The following quick and dirty bash script will take a pom and a jar and fake a maven build based on the source files for that that can be found in the current directory.\nReally useful when running mvn dependency:analyze on a project you are validating POMs for.\n#!/bin/bash\nif [ “A$3” == “A” ]\nthen\necho “Syntax: $0 pomfile jarfile dir”\nreturn\nfi\nrm -rvf “$3/src”\nmkdir -p “$3/src/main/java”\ncp -f “$1” “$3/pom.xml”\nfor name in $(jar -tf “$2” | sed -n -e “/\\$/d;s/\\.class/.java/p”)\ndo\necho -n “Looking for $name … \u0026#34;\nloc=\u0026#34;$(find . | fgrep $name | head -n 1)”\nif [ “A$loc” == “A” ]\nthen\necho “NOT FOUND”\nelse\necho “$loc”\nmkdir -p “$3/src/main/java/$(dirname $name)”\ncp “$loc” “$3/src/main/java/$name”\nfi\ndone\n","date":1301616e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1301616e3,"objectID":"49b9bfdd612c947e6bc7e5a94709ecf2","permalink":"https://stephenc.github.io/post/2011-04-01-quick-and-very-dirty-mavenizer/","publishdate":"2011-04-01T00:00:00Z","relpermalink":"/post/2011-04-01-quick-and-very-dirty-mavenizer/","section":"post","summary":"The following quick and dirty bash script will take a pom and a jar and fake a maven build based on the source files for that that can be found in the current directory.\nReally useful when running mvn dependency:analyze on a project you are validating POMs for.\n#!/bin/bash\nif [ “A$3” == “A” ]\nthen\necho “Syntax: $0 pomfile jarfile dir”\nreturn\nfi\nrm -rvf “$3/src”\nmkdir -p “$3/src/main/java”\ncp -f “$1” “$3/pom.xml”\n","tags":["Maven"],"title":"Quick and very Dirty Mavenizer","type":"post"},{"authors":null,"categories":null,"content":"#!/bin/bash\nURL=\u0026#34;$(svn info | sed -n -e ‘/^URL:/{s/URL: *//p}’)\u0026#34;\nROOT=\u0026#34;$(svn info | sed -n -e “/^Repository Root:/{s/Repository Root: *//p}”)\u0026#34;\nNEW_PATH=\u0026#34;${URL#$ROOT}\u0026#34;\nOLD_URL=\u0026#34;$(sed -n ‘/\u0026lt; *scm *\u0026gt;/,/\u0026lt; */scm *\u0026gt;/p’ pom.xml | sed -n ‘/\u0026lt; *connection *\u0026gt;/,/\u0026lt; */ *connection *\u0026gt;/{s/.*connection \u0026gt; scm:svn:([^ \u0026lt;])[ \u0026lt;]./\\1/p}’)\u0026#34;\nOLD_PATH=\u0026#34;${OLD_URL#$ROOT}\u0026#34;\necho “OLD URL: $OLD_URL”\necho “NEW URL: $URL”\necho “ROOT: $ROOT”\necho “OLD PATH: $OLD_PATH”\necho “NEW PATH: $NEW_PATH”\nsed -i ‘/\u0026lt; *scm *\u0026gt;/,/\u0026lt; */scm *\u0026gt;/{s/’${OLD_PATH////\\/}’/’${NEW_PATH////\\/}’/}’ pom.xml\n","date":1298937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1298937600,"objectID":"d7f9bac151a2ab8bcef845edfc44944c","permalink":"https://stephenc.github.io/post/2011-03-01-handy-bash-script-to-fix-a-poms-scm-section-to-the-current-subversion-location/","publishdate":"2011-03-01T00:00:00Z","relpermalink":"/post/2011-03-01-handy-bash-script-to-fix-a-poms-scm-section-to-the-current-subversion-location/","section":"post","summary":"#!/bin/bash\nURL=\"$(svn info | sed -n -e ‘/^URL:/{s/URL: *//p}’)\"\nROOT=\"$(svn info | sed -n -e “/^Repository Root:/{s/Repository Root: *//p}”)\"\nNEW_PATH=\"${URL#$ROOT}\"\nOLD_URL=\"$(sed -n ‘/\u003c *scm *\u003e/,/\u003c */scm *\u003e/p’ pom.xml | sed -n ‘/\u003c *connection *\u003e/,/\u003c */ *connection *\u003e/{s/.*connection \u003e scm:svn:([^ \u003c])[ \u003c]./\\1/p}’)\"\nOLD_PATH=\"${OLD_URL#$ROOT}\"\necho “OLD URL: $OLD_URL”\necho “NEW URL: $URL”\necho “ROOT: $ROOT”\necho “OLD PATH: $OLD_PATH”\necho “NEW PATH: $NEW_PATH”\nsed -i ‘/\u003c *scm *\u003e/,/\u003c */scm *\u003e/{s/’${OLD_PATH////\\/}’/’${NEW_PATH////\\/}’/}’ pom.xml\n","tags":["Maven","Shell"],"title":"Handy bash script to fix a pom's SCM section to the current Subversion location","type":"post"},{"authors":null,"categories":null,"content":"OK, so a while back I posted my bash script for selecting the maven version to use for the current session http://s.apache.org/FQ2\nNow that I have a Mac for my full time development machine, I thought I would share my version of these functions for Mac users:\nusemvn ()\n{\nif [ -z “$1” -o ! -x “/usr/share/java/maven-$1/bin/mvn” ]\nthen\nlocal prefix=“Syntax: usemvn \u0026#34;\nfor i in /usr/share/java/maven-*\ndo\nif [ -x “$i/bin/mvn” ]; then\necho -n “$prefix$(basename $i | sed ’s/^maven-//’)”\nprefix=” | \u0026#34;\nfi\ndone\necho \u0026#34;\u0026#34;\nelse\nif [ -z “$MAVEN_HOME” ]\nthen\nexport PATH=/usr/share/java/maven-$1/bin:$PATH\nelse\nexport PATH=$(echo $PATH|sed -e “s:$MAVEN_HOME/bin:/usr/share/java/maven-$1/bin:g”)\nfi\nexport MAVEN_HOME=/usr/share/java/maven-$1\nfi\n}\nuseant ()\n{\nif [ -z “$1” -o ! -x “/usr/share/java/ant-$1/bin/ant” ]\nthen\nlocal prefix=“Syntax: useant \u0026#34;\nfor i in /usr/share/java/ant-*\ndo\nif [ -x “$i/bin/ant” ]; then\necho -n “$prefix$(basename $i | sed ’s/^ant-//’)”\nprefix=” | \u0026#34;\nfi\ndone\necho \u0026#34;\u0026#34;\nelse\nif [ -z “$ANT_HOME” ]\nthen\nexport PATH=/usr/share/java/ant-$1/bin:$PATH\nelse\nexport PATH=$(echo $PATH|sed -e “s:$ANT_HOME/bin:/usr/share/java/ant-$1/bin:g”)\nfi\nexport ANT_HOME=/usr/share/java/ant-$1\nfi\n}\nSimply add the above into your ~/.bash_profile and you can use them from any bash shell.\nFor example:\n[stephenc@stephenc ~]$ mvn -version\nApache Maven 3.0.2 (r1056850; 2011-01-09 00:58:10+0000)\nJava version: 1.6.0_24, vendor: Apple Inc.\nJava home: /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home\nDefault locale: en_US, platform encoding: MacRoman\nOS name: “mac os x”, version: “10.6.6”, arch: “x86_64”, family: “mac”\n[stephenc@stephenc ~]$ usemvn\nSyntax: usemvn 2.2.0 | 2.2.1 | 3.0.2\n[stephenc@stephenc ~]$ usemvn 2.2.1\n[stephenc@stephenc ~]$ mvn -version\nApache Maven 2.2.1 (r801777; 2009-08-06 20:16:01+0100)\nJava version: 1.6.0_24\nJava home: /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home\nDefault locale: en_US, platform encoding: MacRoman\nOS name: “mac os x” version: “10.6.6” arch: “x86_64” Family: “mac”\n[stephenc@stephenc ~]$\nThe joy of these as bash functions is that they only affect the current session. So I can have one Terminal tab running Maven 2.2.1 and another running Maven 3.0.2\nOther tricks that people use by re-pointing the symlink are global and have global effect which makes hopping between tasks or testing different versions of Maven a whole lot harder.\n","date":1298937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1298937600,"objectID":"d3174b3e0bcd5b73eafd3a7d00a361b7","permalink":"https://stephenc.github.io/post/2011-03-01-my-magic-maven-and-ant-version-selection-bash-functions-for-the-mac/","publishdate":"2011-03-01T00:00:00Z","relpermalink":"/post/2011-03-01-my-magic-maven-and-ant-version-selection-bash-functions-for-the-mac/","section":"post","summary":"OK, so a while back I posted my bash script for selecting the maven version to use for the current session http://s.apache.org/FQ2\nNow that I have a Mac for my full time development machine, I thought I would share my version of these functions for Mac users:\nusemvn ()\n{\nif [ -z “$1” -o ! -x “/usr/share/java/maven-$1/bin/mvn” ]\nthen\nlocal prefix=“Syntax: usemvn \"\nfor i in /usr/share/java/maven-*\ndo\nif [ -x “$i/bin/mvn” ]; then\n","tags":["Shell"],"title":"My magic Maven and ANT version selection bash functions (for the Mac)","type":"post"},{"authors":null,"categories":null,"content":"Here’s a handy string for i18n testing:\n用户汉语\nIt can be handy to have a string in a non-english charater set that can be pushed end-to-end.\nThis should be a sad sad joke similar to the writing on the bottom of a leprechaun I saw in a gift shop in Ennis:\nDéanta i dtír eile\nI should point out that it was probably\nDéanta sa tSín\nStill\nMura féidir leat tuiscint a fháil ar an ansin is féidir leat léamh na Gaeilge.\nGoogle seems to suggest that 中国扬声器可以阅读本 would be a better string to go with though!\n","date":1296518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1296518400,"objectID":"2588401ac2b5c39733e365d50e664d8c","permalink":"https://stephenc.github.io/post/2011-02-01-a-handy-string-for-when-testing-i18n/","publishdate":"2011-02-01T00:00:00Z","relpermalink":"/post/2011-02-01-a-handy-string-for-when-testing-i18n/","section":"post","summary":"Here’s a handy string for i18n testing:\n用户汉语\nIt can be handy to have a string in a non-english charater set that can be pushed end-to-end.\nThis should be a sad sad joke similar to the writing on the bottom of a leprechaun I saw in a gift shop in Ennis:\nDéanta i dtír eile\nI should point out that it was probably\nDéanta sa tSín\nStill\nMura féidir leat tuiscint a fháil ar an ansin is féidir leat léamh na Gaeilge.\n","tags":null,"title":"A handy string for when testing i18n","type":"post"},{"authors":null,"categories":null,"content":"An interesting blog on QA and development: The Clean Coder: QA or When do you flip a pancake?\n","date":1280620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1280620800,"objectID":"faf70a1d7450ef56997a1a50aed9358b","permalink":"https://stephenc.github.io/post/2010-08-01-the-clean-coder-qa-or-when-do-you-flip-a-pancake/","publishdate":"2010-08-01T00:00:00Z","relpermalink":"/post/2010-08-01-the-clean-coder-qa-or-when-do-you-flip-a-pancake/","section":"post","summary":"An interesting blog on QA and development: The Clean Coder: QA or When do you flip a pancake?\n","tags":null,"title":"The Clean Coder: QA or When do you flip a pancake?","type":"post"},{"authors":null,"categories":null,"content":"I had my first oportunity to see the new 3D TV’s this weekend. They looked OK to me. There was a 3D effect. All around me were people who were going “wow! this is great! this is absolutely fantastic!”.\nBut then I tilted my head, and low and behold, because the system uses horizontal separation to deliver 3D, it requires that your eyes be horizontally separated in order to deliver the 3D effect… when your eyes are vertical, however, it looks just as shit as when you have not got the glasses on.\nNow I don’t know about you, but one of my favoured ways of watching TV is lying on the couch with my head turned sideways to face rthe TV… which results in my eyes being vertical not horizontal…\nSo I’ll add that to the top of the list of reasons why I’ll not be buying a 1st generation 3D TV\n","date":1277942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277942400,"objectID":"516046722f97600f0a187c097fb59da8","permalink":"https://stephenc.github.io/post/2010-07-01-3d-tv-level-headed-people-will-say-it-looks-fine-looks-bad-lying-down/","publishdate":"2010-07-01T00:00:00Z","relpermalink":"/post/2010-07-01-3d-tv-level-headed-people-will-say-it-looks-fine-looks-bad-lying-down/","section":"post","summary":"I had my first oportunity to see the new 3D TV’s this weekend. They looked OK to me. There was a 3D effect. All around me were people who were going “wow! this is great! this is absolutely fantastic!”.\nBut then I tilted my head, and low and behold, because the system uses horizontal separation to deliver 3D, it requires that your eyes be horizontally separated in order to deliver the 3D effect… when your eyes are vertical, however, it looks just as shit as when you have not got the glasses on.\n","tags":null,"title":"3D TV, level headed people will say it looks fine, looks bad lying  down","type":"post"},{"authors":null,"categories":null,"content":"We recently lost our hudson server due to a multiple disk failure in the RAID array storing our hudson configuration. [5 of the 15 disks died]\nSo I’ve been looking into a backup script that will allow us to keep a backup of the configuration. We use Maven for most of our builds, so the released artifacts are in our Maven Repository (which is hosted on two servers each with RAID arrays and using DRBD to mirror between the pair, with an rsync to a NAS in another cabinet and we are trying to get an rsych to an off-site storage going as well).\nThere seem to be two main options:\nUse the Hudson Backup Plugin.\nBackup your Hudson configuration to Source Control.\nOption 1 is nice, but you still have to copy off the backup files and find some safe place to store them. Option 2 sounds better to me as if we loose our source control system, we’ll there’s nothing to build anyway!\nSo a quick search of the interwebs revealed Mike Rooney has been here before… cool… I have somewhere to start… with a few tweaks I have ended up with the following:\n#!/bin/bash\nif [[ ! -d $HUDSON_HOME ]]\nthen\necho “Hudson home directory ($HUDSON_HOME) is missing or undefined”\nexit 1\nfi\ncd $HUDSON_HOME\nAdd any new conf files, jobs, users, and content. svn add -q –parents .xml jobs//config.xml users//config.xml userContent/\nAdd the names of plugins so that we know what plugins we have ls -l plugins \u0026gt; plugins.list\nsvn add -q -N –parents plugins.list\nIgnore things in the root we don’t care about. echo -e “war\\nlog\\n*.log\\n*.tmp\\n*.old\\n*.bak\\n*.jar\\n*.json\\nsecret.key\\ntools\\nshelvedProjects\\n.owner\\nupdates\\nplugins” \u0026gt; myignores\nsvn ps -q svn:ignore -F myignores . \u0026amp;\u0026amp; rm myignores\nIgnore things in jobs/* we don’t care about. echo -e “builds\\nlast*\\nnext*\\n*.txt\\n*.log\\nworkspace*\\ncobertura\\njavadoc\\nhtmlreports\\nncover\\ndoclinks” \u0026gt; myignores\nsvn ps -q svn:ignore -F myignores jobs/* \u0026amp;\u0026amp; rm myignores\nRemove anything from SVN that no longer exists in Hudson. svn st | sed -n -e “s/^!//p” | xargs -r svn rm\nAnd finally, check in of course, showing status before and after for logging. svn st \u0026amp;\u0026amp; svn ci –non-interactive –username=hudson-build -m “automated commit of Hudson configuration” \u0026amp;\u0026amp; svn st\nThe main changes are that I’ve updated the root level ignores and I capture a listing of the plugins directory so that you can know exactly what plugins you had installed\n","date":1277942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277942400,"objectID":"28f58a318d66bc3885e1abdcee0aa99d","permalink":"https://stephenc.github.io/post/2010-07-01-keeping-hudson-configuration-and-data-in-svn/","publishdate":"2010-07-01T00:00:00Z","relpermalink":"/post/2010-07-01-keeping-hudson-configuration-and-data-in-svn/","section":"post","summary":"We recently lost our hudson server due to a multiple disk failure in the RAID array storing our hudson configuration. [5 of the 15 disks died]\nSo I’ve been looking into a backup script that will allow us to keep a backup of the configuration. We use Maven for most of our builds, so the released artifacts are in our Maven Repository (which is hosted on two servers each with RAID arrays and using DRBD to mirror between the pair, with an rsync to a NAS in another cabinet and we are trying to get an rsych to an off-site storage going as well).\n","tags":["Jenkins"],"title":"Keeping Hudson configuration and data in SVN","type":"post"},{"authors":null,"categories":null,"content":"Works on *nixfind ~/.m2/repository -type d -name *-SNAPSHOT -exec rm -rvf {} ;By searching for the directories we should catch the -YYYYMMDD.HHMMSS format of snapshots also\n","date":1277942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277942400,"objectID":"476f090ce328655728c328ad9db74804","permalink":"https://stephenc.github.io/post/2010-07-01-quick-and-dirty-remove-snapshots-from-your-local-maven-repository/","publishdate":"2010-07-01T00:00:00Z","relpermalink":"/post/2010-07-01-quick-and-dirty-remove-snapshots-from-your-local-maven-repository/","section":"post","summary":"Works on *nixfind ~/.m2/repository -type d -name *-SNAPSHOT -exec rm -rvf {} ;By searching for the directories we should catch the -YYYYMMDD.HHMMSS format of snapshots also\n","tags":["Maven","Shell"],"title":"Quick and dirty remove -SNAPSHOTS from your local maven repository","type":"post"},{"authors":null,"categories":null,"content":"Cool post I just found:http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/7\n","date":1272672e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1272672e3,"objectID":"702d43d7ea4570375f29dc649f542629","permalink":"https://stephenc.github.io/post/2010-05-01-easy-parallelization-with-bash-in-linux/","publishdate":"2010-05-01T00:00:00Z","relpermalink":"/post/2010-05-01-easy-parallelization-with-bash-in-linux/","section":"post","summary":"Cool post I just found:http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/7\n","tags":["Shell"],"title":"Easy parallelization with Bash in Linux","type":"post"},{"authors":null,"categories":null,"content":"I am starting a series of things you should not do:\nSeam has this handy annotation: @Synchronized which ensures that only a single thread may access the methods/fields of the component at the same time.\nOften times it is easy to forget that SESSION scoped Seam components are automatically @Synchronized\nJava has this (formerly) handy modifier synchronized which when applied to a method, ensures that the object’s implicit lock is held whenever the method is invoked.\nHilarity will ensue if you have an @Synchronized component with synchronized methods (which you should not have to apply because the component is @Synchronized), e.g.\n@Name(“donny”)\n@Scope(ScopeType.SESSION)\npublic class DonnyDont {\npublic synchronized String dont() {\n// some stuff\n}\n}\n","date":1267401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1267401600,"objectID":"7b42fbe4079e5b059ccc5b7c484ea2b2","permalink":"https://stephenc.github.io/post/2010-03-01-dont-do-what-donny-dont-does-1-seam-synchronized-and-synchronized-methods/","publishdate":"2010-03-01T00:00:00Z","relpermalink":"/post/2010-03-01-dont-do-what-donny-dont-does-1-seam-synchronized-and-synchronized-methods/","section":"post","summary":"I am starting a series of things you should not do:\nSeam has this handy annotation: @Synchronized which ensures that only a single thread may access the methods/fields of the component at the same time.\nOften times it is easy to forget that SESSION scoped Seam components are automatically @Synchronized\nJava has this (formerly) handy modifier synchronized which when applied to a method, ensures that the object’s implicit lock is held whenever the method is invoked.\n","tags":null,"title":"Don't Do What Donny Don't Does #1 - Seam @Synchronized and  synchronized methods","type":"post"},{"authors":null,"categories":null,"content":"I’ve been meaning to blog about getting transaction management working with OpenEjb and Jetty using jetty:run… it’s still an on-going story… but the following might get you going…First off, in your pom.xml you need to add the configuration for maven-jetty-plugin… we need to dance around the various activemq/activeio versions and ensure that we get the correct version of ant… \u0026lt;project xmlns=“http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=“http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=“http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; 4.0.0 org.apache.openejb.examples jetty-openejb war 1.0-SNAPSHOT jetty-openejb Maven Webapp http://maven.apache.org junit junit 3.8.1 test ${project.artifactId} org.mortbay.jetty maven-jetty-plugin 6.1.22 org.apache.activemq activemq-core 4.1.1 commons-logging commons-logging commons-logging commons-logging-api org.apache.activemq activeio-core org.apache.activemq activemq-ra 4.1.1 commons-logging commons-logging commons-logging commons-logging-api org.apache.activemq activeio-core org.apache.activemq activeio-core 3.1.2 commons-logging commons-logging commons-logging commons-logging-api org.apache.openejb openejb-core 3.1.2 org.apache.activemq activemq-core org.apache.activemq activemq-ra org.apache.activemq activeio-core junit junit org.mortbay.jetty jsp-2.1-jetty 6.1.22 ant ant ${basedir}/src/main/jetty/jetty.xml Next we need to configure a src/main/jetty/jetty.xml to bind the UserTransaction instance into jetty… java.naming.factory.initial org.apache.openejb.client.LocalInitialContextFactory openejb:TransactionManager And presto-chango, now jetty has a transaction manager provided by openejb. (Note: if we don’t mind storing that in a jetty-env in /WEB-INF, you can put the same config in WEB-INF/jetty-env.xml) OK, so here are the issues:Reloading does not work (because org.apache.openejb.core.ivm.naming.IvmContext does not support the destroySubcontext(Context) methodWe are using jetty’s JNDI provider in the web-app and openejb’s JNDI provider for the EJBs… this is because When jetty binds names to JNDI (using org.mortbay.jetty.plus.naming.Resource or org.mortbay.jetty.plus.naming.Transaction) it binds the object to JNDIName and it also binds a NamingEnrtry for the object to __/JNDIName Unfortunately, openejb’s JNDI implementation seems to be somewhat strange in this regard… if we add the SystemProperties to jetty to have it use openejb’s JNDI implementation, e.g. add the following to /project/build/plugins/plugin[maven-jetty-plugin]/configuration/systemProperties java.naming.factory.initial org.apache.openejb.client.LocalInitialContextFactory Then when we bind /UserTransaction it gets bound to openejb:/UserTransaction but when we lookup /UserTransaction openejb looks up openejb:local//UserTransaction And that is just for starters… there seems to be a whole host of other JNDI strangeness between jetty’s side and openejb’s sideThe side effect of all this is that if you want resource refs to work correctly, you need to fish them out of openejb’s JNDI context and push them into jetty’s JNDI context In any case this is at least a start!\n","date":1267401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1267401600,"objectID":"95791636ad8ccf1881973adcb49a81d4","permalink":"https://stephenc.github.io/post/2010-03-01-openejb-jetty-and-maven-transaction-management/","publishdate":"2010-03-01T00:00:00Z","relpermalink":"/post/2010-03-01-openejb-jetty-and-maven-transaction-management/","section":"post","summary":"I’ve been meaning to blog about getting transaction management working with OpenEjb and Jetty using jetty:run… it’s still an on-going story… but the following might get you going…First off, in your pom.xml you need to add the configuration for maven-jetty-plugin… we need to dance around the various activemq/activeio versions and ensure that we get the correct version of ant… \u003cproject xmlns=“http://maven.apache.org/POM/4.0.0\" xmlns:xsi=“http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=“http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"\u003e 4.0.0 org.apache.openejb.examples jetty-openejb war 1.0-SNAPSHOT jetty-openejb Maven Webapp http://maven.apache.org junit junit 3.8.1 test ${project.artifactId} org.mortbay.jetty maven-jetty-plugin 6.1.22 org.apache.activemq activemq-core 4.1.1 commons-logging commons-logging commons-logging commons-logging-api org.apache.activemq activeio-core org.apache.activemq activemq-ra 4.1.1 commons-logging commons-logging commons-logging commons-logging-api org.apache.activemq activeio-core org.apache.activemq activeio-core 3.1.2 commons-logging commons-logging commons-logging commons-logging-api org.apache.openejb openejb-core 3.1.2 org.apache.activemq activemq-core org.apache.activemq activemq-ra org.apache.activemq activeio-core junit junit org.mortbay.jetty jsp-2.1-jetty 6.1.22 ant ant ${basedir}/src/main/jetty/jetty.xml Next we need to configure a src/main/jetty/jetty.xml to bind the UserTransaction instance into jetty… java.naming.factory.initial org.apache.openejb.client.LocalInitialContextFactory openejb:TransactionManager And presto-chango, now jetty has a transaction manager provided by openejb. (Note: if we don’t mind storing that in a jetty-env in /WEB-INF, you can put the same config in WEB-INF/jetty-env.xml) OK, so here are the issues:Reloading does not work (because org.apache.openejb.core.ivm.naming.IvmContext does not support the destroySubcontext(Context) methodWe are using jetty’s JNDI provider in the web-app and openejb’s JNDI provider for the EJBs… this is because When jetty binds names to JNDI (using org.mortbay.jetty.plus.naming.Resource or org.mortbay.jetty.plus.naming.Transaction) it binds the object to JNDIName and it also binds a NamingEnrtry for the object to __/JNDIName Unfortunately, openejb’s JNDI implementation seems to be somewhat strange in this regard… if we add the SystemProperties to jetty to have it use openejb’s JNDI implementation, e.g. add the following to /project/build/plugins/plugin[maven-jetty-plugin]/configuration/systemProperties java.naming.factory.initial org.apache.openejb.client.LocalInitialContextFactory Then when we bind /UserTransaction it gets bound to openejb:/UserTransaction but when we lookup /UserTransaction openejb looks up openejb:local//UserTransaction And that is just for starters… there seems to be a whole host of other JNDI strangeness between jetty’s side and openejb’s sideThe side effect of all this is that if you want resource refs to work correctly, you need to fish them out of openejb’s JNDI context and push them into jetty’s JNDI context In any case this is at least a start!\n","tags":["Java","Maven","JavaEE"],"title":"OpenEjb, Jetty and Maven - Transaction Management","type":"post"},{"authors":null,"categories":null,"content":"Review Board is quite nice… it has a handy program for posting reviews (postreview)… and you can integrate this into your subversion hook scripts quite nicely…\nBut what if you want to automate submitting reviews on only parts of your code base…\nWhat I want is to be able to set a property on a folder and then any time a file is changed in that folder or it’s children, then a review will automatically be scheduled…\nSo I wrote the following C/C++ helper (because we would potentially be forking a lot of svnlook processes) which checks to see if a property is set on any of the changed paths or the changed path parents.\n/*\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements. See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership. The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n“License”); you may not use this file except in compliance\nwith the License. You may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n“AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied. See the License for the\nspecific language governing permissions and limitations\nunder the License.\n*/\n#include \u0026lt;stdio.h\u0026gt;\n#include \u0026lt;string.h\u0026gt;\n#include \u0026lt;stdlib.h\u0026gt;\n#include \u0026lt;unistd.h\u0026gt;\n#include \u0026lt;sys/types.h\u0026gt;\n#include \u0026lt;sys/wait.h\u0026gt;\n/**\nReturns a stream for the output of dirs-changed from svnlook. */\nFILE *svnlook_dirs_changed(char *svnlook, char *repo, char *rev) {\nchar *cmd;\ncmd = (char *) malloc(strlen(svnlook) + strlen(\u0026#34; dirs-changed “) + strlen(repo) + strlen(” -r “) + strlen(rev) + 1);\nstrcpy(cmd, svnlook);\nstrcat(cmd, \u0026#34; dirs-changed “);\nstrcat(cmd, repo);\nstrcat(cmd, \u0026#34; -r “);\nstrcat(cmd, rev);\nreturn (FILE *) popen(cmd, “r”);\n}\n/**\nUses svnlook to check and see if the specified property is set on the specified path in the specified repository. */\nint svnlook_is_prop_set(char *svnlook, char *repopath, char *propname, char *path) {\nint status;\npid_t pid;\npid = fork();\nif (pid == 0) {\nfclose(stdin);\nFILE* fp = fopen(\u0026#34;/dev/null”, “w+”);\nif (fileno(fp) != STDIN_FILENO) {\n_exit(EXIT_FAILURE);\n}\nif (dup2(STDIN_FILENO, STDOUT_FILENO) == -1) {\n_exit(EXIT_FAILURE);\n}\nif (dup2(STDIN_FILENO, STDERR_FILENO) == -1) {\n_exit(EXIT_FAILURE);\n}\nexecl(svnlook, svnlook, “pg”, repopath, propname, path, NULL);\nprintf(“exit failure\\n”);\n_exit(EXIT_FAILURE);\n} else if (pid \u0026lt; 0) {\nstatus = -1;\n} else {\nif (waitpid(pid, \u0026amp;status, 0) != pid) {\nstatus = -1;\n}\n}\nreturn status;\n}\n/**\nChecks to see if any of the directories from the stream have the specified property set. */\nint check_svn_dirs(FILE* fdirschanged, char *svnlook,char *repopath, char *revnum, char *propname, int showallpaths) {\nchar line[1024];\nint rv = 0;;\nwhile (fgets(line, sizeof line, fdirschanged)) {\nfor (unsigned int i = 0; i \u0026lt; sizeof line; i++) {\nif (line[i] == ‘\\n’) {\nline[i] = 0;\nfor (int j = i; j \u0026gt; 0; j–) {\nif (line[j] == ‘/’) {\nline[j] = 0;\nif (0 == svnlook_is_prop_set(svnlook, repopath, propname, line)) {\nprintf(\u0026#34;%s/\\n”, line);\nif (!showallpaths) {\nreturn 1;\n} else {\nrv = 1;\n}\n}\n}\n}\nline[0] = 0;\nif (0 == svnlook_is_prop_set(svnlook, repopath, propname, line)) {\nprintf(”/\\n\u0026#34;);\nif (!showallpaths) {\nreturn 1;\n} else {\nrv = 1;\n}\n}\nbreak;\n} // else it’s a really long path and I’m refusing to check it!\n}\n}\nreturn rv;\n}\nint main(int argc, char **argv) {\nFILE *fpipe;\nchar *svnlook = “/usr/bin/svnlook”;\nchar *repopath = “..”;\nchar *revnum = NULL;\nchar *propname = NULL;\nint showallpaths = 0;\nint index = 1;\nint help = 0;\nwhile (index \u0026lt; argc) {\nif (strcmp(\u0026#34;–svn-look\u0026#34;, argv[index]) == 0) {\nindex++;\nif (index \u0026lt; argc) {\nsvnlook = argv[index];\n} else {\nhelp = 1;\nbreak;\n}\n} else if (strcmp(\u0026#34;-r\u0026#34;, argv[index]) == 0) {\nindex++;\nif (index \u0026lt; argc) {\nrevnum = argv[index];\n} else {\nhelp = 1;\nbreak;\n}\n} else if (strcmp(\u0026#34;–repo\u0026#34;, argv[index]) == 0) {\nindex++;\nif (index \u0026lt; argc) {\nrepopath = argv[index];\n} else {\nhelp = 1;\nbreak;\n}\n} else if (strcmp(\u0026#34;–property\u0026#34;, argv[index]) == 0) {\nindex++;\nif (index \u0026lt; argc) {\npropname = argv[index];\n} else {\nhelp = 1;\nbreak;\n}\n} else if (strcmp(\u0026#34;–show-all-paths\u0026#34;, argv[index]) == 0) {\nshowallpaths = 1;\n} else if (strcmp(\u0026#34;–help\u0026#34;, argv[index]) == 0 || strcmp(\u0026#34;-h\u0026#34;, argv[index]) == 0 || strcmp(\u0026#34;-?\u0026#34;, argv[index]) == 0) {\nhelp = 1;\nbreak;\n} else {\nhelp = 1;\nbreak;\n}\nindex++;\n}\nif (help || svnlook == NULL || repopath == NULL || revnum == NULL || propname == NULL) {\nprintf(“Syntax: %s options\\n”, argv[0]);\nprintf(“Options:\\n”);\nprintf(\u0026#34; –svn-look PATH Specify an alternative svnlook binary location (default /usr/bin/svnlook)\\n\u0026#34;);\nprintf(\u0026#34; –repo PATH Specify the repository to work against (required)\\n\u0026#34;);\nprintf(\u0026#34; -r REVNUM Specify the revision to process (required)\\n\u0026#34;);\nprintf(\u0026#34; -property NAME Specify the property to check (required)\\n\u0026#34;);\nprintf(\u0026#34; –show-all-paths Shows all the changed paths with the property rather than …","date":1264982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1264982400,"objectID":"22aa371ece1ad0567c8620be04cacafe","permalink":"https://stephenc.github.io/post/2010-02-01-review-board-and-subversion-hooks/","publishdate":"2010-02-01T00:00:00Z","relpermalink":"/post/2010-02-01-review-board-and-subversion-hooks/","section":"post","summary":"Review Board is quite nice… it has a handy program for posting reviews (postreview)… and you can integrate this into your subversion hook scripts quite nicely…\nBut what if you want to automate submitting reviews on only parts of your code base…\nWhat I want is to be able to set a property on a folder and then any time a file is changed in that folder or it’s children, then a review will automatically be scheduled…\n","tags":null,"title":"Review Board and Subversion Hooks","type":"post"},{"authors":null,"categories":null,"content":"Here is my version of the holy grail, i.e.Authentication for Apache HTTPD against Active Directory.This is not the only way to skin this cat, for example you could also use Sander Marechal’s technique (which uses mod_authnz_ldap). However, my problem with Sander’s technique is that you need to have an account in Active Directory which you will use to bind to the LDAP server. That means that the accound password has to be stored in a plain-text file on the Apache server, and if the password expires everything breaks until you go fix the password.I want as near to zero maintenance as possible, running on CentOS 5.2 with minimal custom work - so that I don’t have to maintain it when it does break.I have previously configured Kerberos to authenicate against Active Directory, so my first attempt was with mod_auth_kerb. That worked… but very slowly… trying to an empty access Subversion repository took over 2 minutes. The problem being that successful authentication was not being cached.Then I tried using mod_perl and the Authen::Simple::ActiveDirectory reasoning that I could always hack caching once in perl… but getting that lot installed on a CentOS 5.2 from RPMs was an exercise in tears.So, anyway, I found out that Cyrus SASL supports two modes of LDAP authentication:The bind method uses the LDAP bind facility to verify the password. The bind method is not available when ldap_use_sasl is turned on. In that case saslauthd will use fastbind.‘bind’ is the default auth method. When ldap_use_sasl is enabled, ‘fastbind’ is the default.The custom method uses userPassword attribute to verify the password. Suppored hashes: crypt, md5, smd5, sha and ssha. Cleartext is supported as well.The fastbind method (when ’ldap_use_sasl: no’) does away with the search and an extra anonymous bind in auth_bind, but makes two assumptions: 1. Expanding the ldap_filter expression gives the user’s fully-qualified DN 2. There is no cost to staying bound as a named userSo bind is pretty much the same technique as that used by mod_authnz_ldap, and (as ActiveDirectory does not support - at my company at least - anonymous bind) is ruled out of the running.“fastbind” sounds exactly like what I want… ok and saslauthd can be configured to cache authentication, so none of the performance hit of mod_auth_kerb. All we need is a way to tie this into Apache.So, enter mod_authn_sasl which does just that.First, we need to create an RPM, so I did a quicksudo yum install httpd-devel rpmbuild mocksudoecho “%_topdir %(echo $HOME)/rpmbuild” \u0026gt; ~/.rpmmacrosmkdir -p ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}I added my account to the mock group, logged out and in again for the group membership to be recognised and I was ready to go. This was my first experience playing with mock, but it was lovely, especially as CentOS has its own version.I pre-primed my mock environments for i386 and x86_64 as I need RPMs for both of these:mock -r centos-5-i386 initmock -r centos-5-x86_64 initThen I downloaded mod_authn_sasl-1.0.2.tar.bz2 and started writing my spec file.You can download the RPC spec: mod_authn_sasl.spec and the apache config file: mod_authn_sasl.conf.I put mod_authn_sasl-1.0.2.tar.bz2 and mod_authn_sasl.conf in the ~/rpmbuild/SOURCES and then runningrpmbuild -ba mod_authn_sasl.specproduced my source RPM, then I used mock to create the two binary RPMs that I needed:mock -r centos-5-i386 ~/rpmbuild/SRPMS/mod_authn_sasl-1.0.2-4.src.rpmmock -r centos-5-x86_64 ~/rpmbuild/SRPMS/mod_authn_sasl-1.0.2-4.src.rpmThe rpms built from the mock environments end up in /var/lib/mock/centos-5-i386/result and /var/lib/mock/centos-5-x86_64/result. If you want to be lazy and trust my binaries here they are:mod_authn_sasl-1.0.2-4.i386.rpmmod_authn_sasl-1.0.2-4.x86_64.rpmNow all we need to do is configure everything.I’ve written this shell script to simplify configuring saslauthd for most good deployments of Active Directory, i.e. where there are SRV records for the domain in your DNS server. You need to run it as root. It looks up the SRV records for the domain name you provide, and creates /etc/saslauthd.conf from them, assuming that the Active Directory domain name is the first word of your DNS name converted to uppercase. So for example, if your Active Directory is set up correctly, and you can login to windows as either EXAMPLE\\joebloggs or jbloggs@example.foo.com then you would runsh system-saslauthd-active-directory-config.sh example.foo.comAnd that should setup saslauthd for you. You can test this using the testsaslauthd program.Then all you need to do is secure the appropriate locations in apache, e.g. by adding the following to your VirtualHost configuration:\u0026lt;Location /private\u0026gt;AuthSaslPwcheckMethod saslauthdAuthSaslAppname httpdAuthSaslRealm exampleAuthType basicAuthBasicProvider saslAuthBasicAuthoritative OnAuthName “sasl@example.com\u0026#34;require valid-userAnd define the SASL application provider for the AuthSaslAppname you specified, e.g. for the above configuration you …","date":1225497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225497600,"objectID":"6eff3e5921219627badfda16c4c0d3d3","permalink":"https://stephenc.github.io/post/2008-11-01-apache-22-authentication-with-active-directory-via-cyrus-sasl/","publishdate":"2008-11-01T00:00:00Z","relpermalink":"/post/2008-11-01-apache-22-authentication-with-active-directory-via-cyrus-sasl/","section":"post","summary":"Here is my version of the holy grail, i.e.Authentication for Apache HTTPD against Active Directory.This is not the only way to skin this cat, for example you could also use Sander Marechal’s technique (which uses mod_authnz_ldap). However, my problem with Sander’s technique is that you need to have an account in Active Directory which you will use to bind to the LDAP server. That means that the accound password has to be stored in a plain-text file on the Apache server, and if the password expires everything breaks until you go fix the password.I want as near to zero maintenance as possible, running on CentOS 5.2 with minimal custom work - so that I don’t have to maintain it when it does break.I have previously configured Kerberos to authenicate against Active Directory, so my first attempt was with mod_auth_kerb. That worked… but very slowly… trying to an empty access Subversion repository took over 2 minutes. The problem being that successful authentication was not being cached.Then I tried using mod_perl and the Authen::Simple::ActiveDirectory reasoning that I could always hack caching once in perl… but getting that lot installed on a CentOS 5.2 from RPMs was an exercise in tears.So, anyway, I found out that Cyrus SASL supports two modes of LDAP authentication:The bind method uses the LDAP bind facility to verify the password. The bind method is not available when ldap_use_sasl is turned on. In that case saslauthd will use fastbind.‘bind’ is the default auth method. When ldap_use_sasl is enabled, ‘fastbind’ is the default.The custom method uses userPassword attribute to verify the password. Suppored hashes: crypt, md5, smd5, sha and ssha. Cleartext is supported as well.The fastbind method (when ’ldap_use_sasl: no’) does away with the search and an extra anonymous bind in auth_bind, but makes two assumptions: 1. Expanding the ldap_filter expression gives the user’s fully-qualified DN 2. There is no cost to staying bound as a named userSo bind is pretty much the same technique as that used by mod_authnz_ldap, and (as ActiveDirectory does not support - at my company at least - anonymous bind) is ruled out of the running.“fastbind” sounds exactly like what I want… ok and saslauthd can be configured to cache authentication, so none of the performance hit of mod_auth_kerb. All we need is a way to tie this into Apache.So, enter mod_authn_sasl which does just that.First, we need to create an RPM, so I did a quicksudo yum install httpd-devel rpmbuild mocksudoecho “%_topdir %(echo $HOME)/rpmbuild” \u003e ~/.rpmmacrosmkdir -p ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}I added my account to the mock group, logged out and in again for the group membership to be recognised and I was ready to go. This was my first experience playing with mock, but it was lovely, especially as CentOS has its own version.I pre-primed my mock environments for i386 and x86_64 as I need RPMs for both of these:mock -r centos-5-i386 initmock -r centos-5-x86_64 initThen I downloaded mod_authn_sasl-1.0.2.tar.bz2 and started writing my spec file.You can download the RPC spec: mod_authn_sasl.spec and the apache config file: mod_authn_sasl.conf.I put mod_authn_sasl-1.0.2.tar.bz2 and mod_authn_sasl.conf in the ~/rpmbuild/SOURCES and then runningrpmbuild -ba mod_authn_sasl.specproduced my source RPM, then I used mock to create the two binary RPMs that I needed:mock -r centos-5-i386 ~/rpmbuild/SRPMS/mod_authn_sasl-1.0.2-4.src.rpmmock -r centos-5-x86_64 ~/rpmbuild/SRPMS/mod_authn_sasl-1.0.2-4.src.rpmThe rpms built from the mock environments end up in /var/lib/mock/centos-5-i386/result and /var/lib/mock/centos-5-x86_64/result. If you want to be lazy and trust my binaries here they are:mod_authn_sasl-1.0.2-4.i386.rpmmod_authn_sasl-1.0.2-4.x86_64.rpmNow all we need to do is configure everything.I’ve written this shell script to simplify configuring saslauthd for most good deployments of Active Directory, i.e. where there are SRV records for the domain in your DNS server. You need to run it as root. It looks up the SRV records for the domain name you provide, and creates /etc/saslauthd.conf from them, assuming that the Active Directory domain name is the first word of your DNS name converted to uppercase. So for example, if your Active Directory is set up correctly, and you can login to windows as either EXAMPLE\\joebloggs or jbloggs@example.foo.com then you would runsh system-saslauthd-active-directory-config.sh example.foo.comAnd that should setup saslauthd for you. You can test this using the testsaslauthd program.Then all you need to do is secure the appropriate locations in apache, e.g. by adding the following to your VirtualHost configuration:\u003cLocation /private\u003eAuthSaslPwcheckMethod saslauthdAuthSaslAppname httpdAuthSaslRealm exampleAuthType basicAuthBasicProvider saslAuthBasicAuthoritative OnAuthName “sasl@example.com\"require valid-userAnd define the SASL application provider for the AuthSaslAppname you specified, e.g. for the above configuration you need to create /usr/lib/sasl2/httpd.conf with the contents:pwcheck_method:saslauthdThat’s it. You should be done.Updated Friday 28th November 2008: I noticed that the spec file I had provided did not have the correct Requires and BuildRequires. I have fixed this and now I have posted updated rpms (these are 1.0.2-4) with the correct requires to help with a minimal install\n","tags":null,"title":"Apache 2.2 Authentication with Active Directory via Cyrus SASL","type":"post"},{"authors":null,"categories":null,"content":"Here’s my step by step:Install CentOS 5.2Configure Network and Proxies as neededI usually create a login script: /etc/profile.d/login.sh as follows:function set_proxies() { local s PROXY_ADDR=“http://proxy.example.com:8000/\u0026#34; for s in HTTP HTTPS FTP GOPHER NEWSPOST NEWSREPLY\\ NEWS NNTP SNEWSPOST SNEWSREPLY SNEWS\\ WAIS FINGER CSO; do export ${s}_PROXY=${PROXY_ADDR} done for s in http https ftp; do export ${s}_proxy=${PROXY_ADDR} done}set_proxiesI installed from the DVD, so yum update to ensure everything is up-to-date.Get my mod_authn_sasl rpm:wget http://www.one-dash.com/blog/mod_authn_sasl-1.0.2-3.i386.rpmInstall it (this should pull down the):yum –nogpgcheck localinstall mod_authn_sasl-1.0.2-3.i386.rpmGet my sasl-magic-config script:wget http://www.one-dash.com/blog/system-saslauthd-active-directory-config.shdos2unix system-saslauthd-active-directory-config.shRun the script:sh system-saslauthd-active-directory-config.sh example.comChange the security level:system-config-securitylevel-tuiSet SELinux to Permissive, Customize and enable WWW and Secure WWW on the firewallCreate the sasl2 configuration for apache:echo “pwcheck_method:saslauthd” \u0026gt; /usr/lib/sasl2/apache-httpd.confNow we need to install Subversion 1.5.2:wget http://summersoft.fay.ar.us/pub/subversion/1.5.2/rhel-5/i386/subversion-1.5.2-1.i386.rpmwget http://summersoft.fay.ar.us/pub/subversion/1.5.2/rhel-5/i386/neon-0.27.2-1.i386.rpmwget http://summersoft.fay.ar.us/pub/subversion/1.5.2/rhel-5/i386/mod_dav_svn-1.5.2-1.i386.rpmyum install perl-URIrpm -i neon-0.27.2-1.i386.rpm rpm -i subversion-1.5.2-1.i386.rpmrpm -i mod_dav_svn-1.5.2-1.i386.rpmNext modify the apache conf file for our subversion repositories: /etc/httpd/conf.d/subversion.conf# Needed to do Subversion Apache server.LoadModule dav_svn_module modules/mod_dav_svn.so# Only needed if you decide to do “per-directory” access control.#LoadModule authz_svn_module modules/mod_authz_svn.so\u0026lt;Location /svn\u0026gt; DAV svn SVNParentPath /var/www/svn # Limit write permission to list of valid users. # Require SSL connection for password protection. # SSLRequireSSL AuthType Basic AuthName “EXAMPLE” AuthBasicProvider sasl AuthSaslPwcheckMethod saslauthd auxprop AuthSaslAppname apache-httpd AuthSaslRealm example Require valid-user Next, create the subversion projects root and restart Apache:mkdir /var/www/svnchown -R apache.apache /var/www/svnservice httpd restartAt this point you can now create a test repository:svnadmin create /var/www/svn/testchown -R apache.apache /var/www/svn/testLet’s test if subversion is working:svn info http://localhost/svn/testsvn mkdir –username myWindowsUsername –message “a test commit” http://localhost/svn/test/trunkAt this point we should have subversion up and running.\n","date":1225497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225497600,"objectID":"571f5376a4abf283c7030e89d8e3f91d","permalink":"https://stephenc.github.io/post/2008-11-01-howto-centos-5-apache-22-subversion-15-with-activedirectory-authentication/","publishdate":"2008-11-01T00:00:00Z","relpermalink":"/post/2008-11-01-howto-centos-5-apache-22-subversion-15-with-activedirectory-authentication/","section":"post","summary":"Here’s my step by step:Install CentOS 5.2Configure Network and Proxies as neededI usually create a login script: /etc/profile.d/login.sh as follows:function set_proxies() { local s PROXY_ADDR=“http://proxy.example.com:8000/\" for s in HTTP HTTPS FTP GOPHER NEWSPOST NEWSREPLY\\ NEWS NNTP SNEWSPOST SNEWSREPLY SNEWS\\ WAIS FINGER CSO; do export ${s}_PROXY=${PROXY_ADDR} done for s in http https ftp; do export ${s}_proxy=${PROXY_ADDR} done}set_proxiesI installed from the DVD, so yum update to ensure everything is up-to-date.Get my mod_authn_sasl rpm:wget http://www.one-dash.com/blog/mod_authn_sasl-1.0.2-3.i386.rpmInstall it (this should pull down the):yum –nogpgcheck localinstall mod_authn_sasl-1.0.2-3.i386.rpmGet my sasl-magic-config script:wget http://www.one-dash.com/blog/system-saslauthd-active-directory-config.shdos2unix system-saslauthd-active-directory-config.shRun the script:sh system-saslauthd-active-directory-config.sh example.comChange the security level:system-config-securitylevel-tuiSet SELinux to Permissive, Customize and enable WWW and Secure WWW on the firewallCreate the sasl2 configuration for apache:echo “pwcheck_method:saslauthd” \u003e /usr/lib/sasl2/apache-httpd.confNow we need to install Subversion 1.5.2:wget http://summersoft.fay.ar.us/pub/subversion/1.5.2/rhel-5/i386/subversion-1.5.2-1.i386.rpmwget http://summersoft.fay.ar.us/pub/subversion/1.5.2/rhel-5/i386/neon-0.27.2-1.i386.rpmwget http://summersoft.fay.ar.us/pub/subversion/1.5.2/rhel-5/i386/mod_dav_svn-1.5.2-1.i386.rpmyum install perl-URIrpm -i neon-0.27.2-1.i386.rpm rpm -i subversion-1.5.2-1.i386.rpmrpm -i mod_dav_svn-1.5.2-1.i386.rpmNext modify the apache conf file for our subversion repositories: /etc/httpd/conf.d/subversion.conf# Needed to do Subversion Apache server.LoadModule dav_svn_module modules/mod_dav_svn.so# Only needed if you decide to do “per-directory” access control.#LoadModule authz_svn_module modules/mod_authz_svn.so\u003cLocation /svn\u003e DAV svn SVNParentPath /var/www/svn # Limit write permission to list of valid users. # Require SSL connection for password protection. # SSLRequireSSL AuthType Basic AuthName “EXAMPLE” AuthBasicProvider sasl AuthSaslPwcheckMethod saslauthd auxprop AuthSaslAppname apache-httpd AuthSaslRealm example Require valid-user Next, create the subversion projects root and restart Apache:mkdir /var/www/svnchown -R apache.apache /var/www/svnservice httpd restartAt this point you can now create a test repository:svnadmin create /var/www/svn/testchown -R apache.apache /var/www/svn/testLet’s test if subversion is working:svn info http://localhost/svn/testsvn mkdir –username myWindowsUsername –message “a test commit” http://localhost/svn/test/trunkAt this point we should have subversion up and running.\n","tags":null,"title":"HowTo: CentOS 5, Apache 2.2, Subversion 1.5 with ActiveDirectory Authentication","type":"post"},{"authors":null,"categories":null,"content":"One of my co-workers has asked me to post this up. It’s rough and ready, so make of it what you want.First off, Acer recently pushed an update for better performance with the Huawei USB modems… I’m assuming that you have this update… check if the file /etc/udev/rules.d/10-Huawei-Datacard.rules exists.If that file exists then when you plug in a E169g it will be correctly autodetected without requiring poking about with usbmodeswitch… it will bind the three serial ports of the E169G to /dev/HuaweiMobile-0, /dev/HuaweiMobile-1 and /dev/HuaweiMobile-2.OK, so assuming you see these device nodes after plugging in the E169G, the next problem is getting wvdial to connect. Here’s the wvdial.conf file I use[Dialer Defaults]Init2 = ATZInit3 = ATHInit4 = ATQ0 V1 E1 S0=0 \u0026amp;C1 \u0026amp;D2 +FCLASS=0Stupid Mode = 1Modem Type = USB ModemISDN = 0Phone = *99#Modem = /dev/HuaweiMobile-0Username = usernamePassword = passwordDial Command = ATDTBaud = 460800Init5 = AT+CGDCONT=1,“IP”,“3ireland.ie\u0026#34;By the way, the username is actually “username”, and the password is actually “password”.That should be enough to get any self-respecting linux freak 90% of the way there. There was some stuff I had to tweak to get DHCP to populate resolve.conf from the pppd connection… and I added the following udev rule as 70-huawei-e169g-dial.rulesSUBSYSTEM==“usb” SYSFS{idProduct}==“1001”,SYSFS{idVendor}==“12d1”,RUN+=\u0026#34;/usr/sbin/e169g_dial\u0026#34;And, /usr/sbin/e169g_dial is just#!/bin/shsleep 5/usr/bin/wvdial 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/wvdial \u0026amp;You might be able to tune down from 5 seconds if you can be bothered… but you need at least some delay\n","date":1222819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1222819200,"objectID":"b3eb024732d77a4f87925052817b9471","permalink":"https://stephenc.github.io/post/2008-10-01-acer-aspire-one-huawei-e169g-and-three-ir/","publishdate":"2008-10-01T00:00:00Z","relpermalink":"/post/2008-10-01-acer-aspire-one-huawei-e169g-and-three-ir/","section":"post","summary":"One of my co-workers has asked me to post this up. It’s rough and ready, so make of it what you want.First off, Acer recently pushed an update for better performance with the Huawei USB modems… I’m assuming that you have this update… check if the file /etc/udev/rules.d/10-Huawei-Datacard.rules exists.If that file exists then when you plug in a E169g it will be correctly autodetected without requiring poking about with usbmodeswitch… it will bind the three serial ports of the E169G to /dev/HuaweiMobile-0, /dev/HuaweiMobile-1 and /dev/HuaweiMobile-2.OK, so assuming you see these device nodes after plugging in the E169G, the next problem is getting wvdial to connect. Here’s the wvdial.conf file I use[Dialer Defaults]Init2 = ATZInit3 = ATHInit4 = ATQ0 V1 E1 S0=0 \u0026C1 \u0026D2 +FCLASS=0Stupid Mode = 1Modem Type = USB ModemISDN = 0Phone = *99#Modem = /dev/HuaweiMobile-0Username = usernamePassword = passwordDial Command = ATDTBaud = 460800Init5 = AT+CGDCONT=1,“IP”,“3ireland.ie\"By the way, the username is actually “username”, and the password is actually “password”.That should be enough to get any self-respecting linux freak 90% of the way there. There was some stuff I had to tweak to get DHCP to populate resolve.conf from the pppd connection… and I added the following udev rule as 70-huawei-e169g-dial.rulesSUBSYSTEM==“usb” SYSFS{idProduct}==“1001”,SYSFS{idVendor}==“12d1”,RUN+=\"/usr/sbin/e169g_dial\"And, /usr/sbin/e169g_dial is just#!/bin/shsleep 5/usr/bin/wvdial 2\u003e\u00261 \u003e /var/log/wvdial \u0026You might be able to tune down from 5 seconds if you can be bothered… but you need at least some delay\n","tags":["Java","JavaEE"],"title":"Acer Aspire One, Huawei E169G and Three IR","type":"post"},{"authors":null,"categories":null,"content":"Life gets in the way… but we’re back with our final installment! So where to start, let’s start with a publisher for freestyle builds, then we’ll add a publisher for Maven 2 builds… These will both require some reports to display results, and then finally we’ll need the plugin entry point. But before we get into all that, perhaps I should briefly explain structured form submission supportDataBoundConstructorsHudson uses Stapler as it’s web framework. One of the things that Stapler provides is support for constructing objects from a JSON data model. Basically, if you have a class with a public constructor annotated with @DataBoundConstructor, Stapler will bind fields from a JSON object by matching the field name to the constructor parameter name. If a parameter also has a @DataBoundConstructor, then Stapler will recurse to construct this child object from the child JSON object.Note: The only hole in this (at the moment) is if you want to inject a variable class, i.e. it does not support the case where there are three ChildImpl classes all implementing Child, and all with @DataBoundConstructor and Parent’s constructor has a parameter which takes Child… However, plans are afoot to fix this!JavaNCSSPublisherPublishers in Hudson must have a Descriptor, this will be registered with Hudson and allows Hudson to create Publisher instances which have the details for the project they are publishing. Descriptors are normally implemented as an inner class called DescriptorImpl and there is normally a static field of the publisher DESCRIPTOR that holds the Descriptor singleton. 99.995% of the time, you will want your publisher to have a @DataBoundConstructor, so without further delay, here is the publisher:package hudson.plugins.javancss;import hudson.maven.MavenModule;import hudson.maven.MavenModuleSet;import hudson.model.AbstractProject;import hudson.model.Action; import hudson.model.Descriptor;import hudson.plugins.helpers.AbstractPublisherImpl;import hudson.plugins.helpers.Ghostwriter;import hudson.tasks.BuildStepDescriptor;import hudson.tasks.Publisher;import net.sf.json.JSONObject;import org.kohsuke.stapler.DataBoundConstructor;import org.kohsuke.stapler.StaplerRequest;public class JavaNCSSPublisher extends AbstractPublisherImpl { private String reportFilenamePattern; @DataBoundConstructor public JavaNCSSPublisher(String reportFilenamePattern) { reportFilenamePattern.getClass(); this.reportFilenamePattern = reportFilenamePattern; } public String getReportFilenamePattern() { return reportFilenamePattern; } public boolean needsToRunAfterFinalized() { return false; } public static final DescriptorImpl DESCRIPTOR = new DescriptorImpl(); public Descriptor getDescriptor() { return DESCRIPTOR; } public Action getProjectAction(AbstractProject project) { return new JavaNCSSProjectIndividualReport(project); } protected Ghostwriter newGhostwriter() { return new JavaNCSSGhostwriter(reportFilenamePattern); } public static final class DescriptorImpl extends BuildStepDescriptor { private DescriptorImpl() { super(JavaNCSSPublisher.class); } public String getDisplayName() { return “Publish \u0026#34; + PluginImpl.DISPLAY_NAME; } public boolean isApplicable(Class\u0026gt; extends AbstractBuildAction { private final Collection results; private final Statistic totals; public AbstractBuildReport(Collection results) { this.results = results; this.totals = Statistic.total(results); } public Collection getResults() { return results; } public Statistic getTotals() { return totals; } public String getSummary() { AbstractBuild prevBuild = getBuild().getPreviousBuild(); while (prevBuild != null \u0026amp;\u0026amp; prevBuild.getAction(getClass()) == null) { prevBuild = prevBuild.getPreviousBuild(); } if (prevBuild == null) { return totals.toSummary(); } else { AbstractBuildReport action = prevBuild.getAction(getClass()); return totals.toSummary(action.getTotals()); } } public String getIconFileName() { return PluginImpl.ICON_FILE_NAME; } public String getDisplayName() { return PluginImpl.DISPLAY_NAME; } public String getUrlName() { return PluginImpl.URL; } public boolean isGraphActive() { return false; }}Similarly, we have AbstractProjectReport which will be used for project reports:package hudson.plugins.javancss;import java.io.IOException;import java.util.Collection;import java.util.Collections;import hudson.model.AbstractBuild;import hudson.model.AbstractProject;import hudson.model.ProminentProjectAction;import hudson.plugins.helpers.AbstractProjectAction;import hudson.plugins.javancss.parser.Statistic;import org.kohsuke.stapler.StaplerRequest;import org.kohsuke.stapler.StaplerResponse;public abstract class AbstractProjectReport\u0026lt;T extends AbstractProject\u0026gt; extends AbstractProjectAction implements ProminentProjectAction { public AbstractProjectReport(T project) { super(project); } public String getIconFileName() { for (AbstractBuild build = getProject().getLastBuild(); build != null; build = build.getPreviousBuild()) { final AbstractBuildReport action = …","date":1212278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1212278400,"objectID":"53c6f31855756b990d0d287c10fe0fde","permalink":"https://stephenc.github.io/post/2008-06-01-writing-a-hudson-plugin-part-7-putting-it-all-together/","publishdate":"2008-06-01T00:00:00Z","relpermalink":"/post/2008-06-01-writing-a-hudson-plugin-part-7-putting-it-all-together/","section":"post","summary":"Life gets in the way… but we’re back with our final installment! So where to start, let’s start with a publisher for freestyle builds, then we’ll add a publisher for Maven 2 builds… These will both require some reports to display results, and then finally we’ll need the plugin entry point. But before we get into all that, perhaps I should briefly explain structured form submission supportDataBoundConstructorsHudson uses Stapler as it’s web framework. One of the things that Stapler provides is support for constructing objects from a JSON data model. Basically, if you have a class with a public constructor annotated with @DataBoundConstructor, Stapler will bind fields from a JSON object by matching the field name to the constructor parameter name. If a parameter also has a @DataBoundConstructor, then Stapler will recurse to construct this child object from the child JSON object.Note: The only hole in this (at the moment) is if you want to inject a variable class, i.e. it does not support the case where there are three ChildImpl classes all implementing Child, and all with @DataBoundConstructor and Parent’s constructor has a parameter which takes Child… However, plans are afoot to fix this!JavaNCSSPublisherPublishers in Hudson must have a Descriptor, this will be registered with Hudson and allows Hudson to create Publisher instances which have the details for the project they are publishing. Descriptors are normally implemented as an inner class called DescriptorImpl and there is normally a static field of the publisher DESCRIPTOR that holds the Descriptor singleton. 99.995% of the time, you will want your publisher to have a @DataBoundConstructor, so without further delay, here is the publisher:package hudson.plugins.javancss;import hudson.maven.MavenModule;import hudson.maven.MavenModuleSet;import hudson.model.AbstractProject;import hudson.model.Action; import hudson.model.Descriptor;import hudson.plugins.helpers.AbstractPublisherImpl;import hudson.plugins.helpers.Ghostwriter;import hudson.tasks.BuildStepDescriptor;import hudson.tasks.Publisher;import net.sf.json.JSONObject;import org.kohsuke.stapler.DataBoundConstructor;import org.kohsuke.stapler.StaplerRequest;public class JavaNCSSPublisher extends AbstractPublisherImpl { private String reportFilenamePattern; @DataBoundConstructor public JavaNCSSPublisher(String reportFilenamePattern) { reportFilenamePattern.getClass(); this.reportFilenamePattern = reportFilenamePattern; } public String getReportFilenamePattern() { return reportFilenamePattern; } public boolean needsToRunAfterFinalized() { return false; } public static final DescriptorImpl DESCRIPTOR = new DescriptorImpl(); public Descriptor getDescriptor() { return DESCRIPTOR; } public Action getProjectAction(AbstractProject project) { return new JavaNCSSProjectIndividualReport(project); } protected Ghostwriter newGhostwriter() { return new JavaNCSSGhostwriter(reportFilenamePattern); } public static final class DescriptorImpl extends BuildStepDescriptor { private DescriptorImpl() { super(JavaNCSSPublisher.class); } public String getDisplayName() { return “Publish \" + PluginImpl.DISPLAY_NAME; } public boolean isApplicable(Class\u003e extends AbstractBuildAction { private final Collection results; private final Statistic totals; public AbstractBuildReport(Collection results) { this.results = results; this.totals = Statistic.total(results); } public Collection getResults() { return results; } public Statistic getTotals() { return totals; } public String getSummary() { AbstractBuild prevBuild = getBuild().getPreviousBuild(); while (prevBuild != null \u0026\u0026 prevBuild.getAction(getClass()) == null) { prevBuild = prevBuild.getPreviousBuild(); } if (prevBuild == null) { return totals.toSummary(); } else { AbstractBuildReport action = prevBuild.getAction(getClass()); return totals.toSummary(action.getTotals()); } } public String getIconFileName() { return PluginImpl.ICON_FILE_NAME; } public String getDisplayName() { return PluginImpl.DISPLAY_NAME; } public String getUrlName() { return PluginImpl.URL; } public boolean isGraphActive() { return false; }}Similarly, we have AbstractProjectReport which will be used for project reports:package hudson.plugins.javancss;import java.io.IOException;import java.util.Collection;import java.util.Collections;import hudson.model.AbstractBuild;import hudson.model.AbstractProject;import hudson.model.ProminentProjectAction;import hudson.plugins.helpers.AbstractProjectAction;import hudson.plugins.javancss.parser.Statistic;import org.kohsuke.stapler.StaplerRequest;import org.kohsuke.stapler.StaplerResponse;public abstract class AbstractProjectReport\u003cT extends AbstractProject\u003e extends AbstractProjectAction implements ProminentProjectAction { public AbstractProjectReport(T project) { super(project); } public String getIconFileName() { for (AbstractBuild build = getProject().getLastBuild(); build != null; build = build.getPreviousBuild()) { final AbstractBuildReport action = build.getAction(getBuildActionClass()); if (action != null) { return PluginImpl.ICON_FILE_NAME; } } return null; } public String getDisplayName() { for (AbstractBuild build = getProject().getLastBuild(); build != null; build = build.getPreviousBuild()) { final AbstractBuildReport action = build.getAction(getBuildActionClass()); if (action != null) { return PluginImpl.DISPLAY_NAME; } } return null; } public String getUrlName() { for (AbstractBuild build = getProject().getLastBuild(); build != null; build = build.getPreviousBuild()) { final AbstractBuildReport action = build.getAction(getBuildActionClass()); if (action != null) { return PluginImpl.URL; } } return null; } public String getSearchUrl() { return PluginImpl.URL; } public boolean isGraphActive() { return false; } public Collection getResults() { for (AbstractBuild build = getProject().getLastBuild(); build != null; build = build.getPreviousBuild()) { final AbstractBuildReport action = build.getAction(getBuildActionClass()); if (action != null) { return action.getResults(); } } return Collections.emptySet(); } public Statistic getTotals() { for (AbstractBuild build = getProject().getLastBuild(); build != null; build = build.getPreviousBuild()) { final AbstractBuildReport action = build.getAction(getBuildActionClass()); if (action != null) { return action.getTotals(); } } return null; } protected abstract Class\u003e implements AggregatableAction { public JavaNCSSBuildIndividualReport(Collection results) { super(results); } @Override public synchronized void setBuild(AbstractBuild build) { super.setBuild(build); if (this.getBuild() != null) { for (Statistic r : getResults()) { r.setOwner(this.getBuild()); } } } public MavenAggregatedReport createAggregatedAction(MavenModuleSetBuild build, Map\u003cMavenModule, List\u003e moduleBuilds) { return new JavaNCSSBuildAggregatedReport(build, moduleBuilds); }}That was fairly painless… Note that we interfaces for both the freestyle and maven2 project types, this is OK as the freestyle projects will ignore the Maven2 stuff and vice-versa while the common code is shared by both. Next we need the aggregated build report:package hudson.plugins.javancss;import hudson.maven.*;import hudson.model.Action;import hudson.plugins.javancss.parser.Statistic;import java.util.ArrayList;import java.util.Collection;import java.util.List;import java.util.Map;public class JavaNCSSBuildAggregatedReport extends AbstractBuildReport implements MavenAggregatedReport { public JavaNCSSBuildAggregatedReport(MavenModuleSetBuild build, Map\u003cMavenModule, List\u003e moduleBuilds) { super(new ArrayList()); setBuild(build); } public synchronized void update(Map\u003cMavenModule, List\u003e moduleBuilds, MavenBuild newBuild) { JavaNCSSBuildIndividualReport report = newBuild.getAction(JavaNCSSBuildIndividualReport.class); if (report != null) { Collection u = Statistic.merge(report.getResults(), getResults()); getResults().clear(); getResults().addAll(u); getTotals().add(report.getTotals()); } } public Class\u003e implements ProminentProjectAction { public JavaNCSSProjectIndividualReport(AbstractProject project) { super(project); } protected Class\u003c? extends AbstractBuildReport\u003e getBuildActionClass() { return JavaNCSSBuildIndividualReport.class; }}Don’t repeat ourselves comes in handy here as essentially all the work has been done for us!. The project aggregated report:package hudson.plugins.javancss;import hudson.model.Actionable;import hudson.model.ProminentProjectAction;import hudson.model.AbstractBuild;import hudson.model.Action;import hudson.maven.MavenModuleSet;import hudson.maven.MavenModuleSetBuild;import hudson.plugins.javancss.parser.Statistic;public class JavaNCSSProjectAggregatedReport extends AbstractProjectReport implements ProminentProjectAction { public JavaNCSSProjectAggregatedReport(MavenModuleSet project) { super(project); } protected Class\u003c? extends AbstractBuildReport\u003e getBuildActionClass() { return JavaNCSSBuildAggregatedReport.class; }}Again DRY to the rescue… At this point all that remains is to present the reports from these backing objects… so on with the jelly views. The helper classes and our inheritance makes this easy… all we need is two jelly files: hudson/plugins/javancss/AbstractBuildReport/reportDetail.jelly and hudson/plugins/javancss/AbstractProjectReport/reportDetail.jelly. Here they are:\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout” xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e Results Package Classes Functions Javadocs NCSS JLC SLCLC MLCLC Totals ${it.totals.classes} ${it.totals.functions} ${it.totals.javadocs} ${it.totals.ncss} ${it.totals.javadocLines} ${it.totals.singleCommentLines} ${it.totals.multiCommentLines} \u003cj:forEach var=“r” items=\"${it.results}\"\u003e ${r.name} ${r.classes} ${r.functions} ${r.javadocs} ${r.ncss} ${r.javadocLines} ${r.singleCommentLines} ${r.multiCommentLines} \u003c/j:forEach\u003e \u003c/j:jelly\u003eYep, the two files are identical! Other plugins may not be quite so lucky… but in general the project level report should be the same as the report for the latest buildMaking a pluginNow we are ready to make our plugin…. for this we need a class that extends hudson.Plugin and registers our publisher’s descriptors with the appropriate lists… here it is:package hudson.plugins.javancss;import hudson.Plugin;import hudson.maven.MavenReporters;import hudson.tasks.BuildStep;public class PluginImpl extends Plugin { public void start() throws Exception { BuildStep.PUBLISHERS.add(JavaNCSSPublisher.DESCRIPTOR); MavenReporters.LIST.add(JavaNCSSMavenPublisher.DESCRIPTOR); } public static String DISPLAY_NAME = “Java NCSS Report”; public static String GRAPH_NAME = “Java NCSS Trend”; public static String URL = “javancss”; public static String ICON_FILE_NAME = “graph.gif”;}And that’s pretty much it… we should have a working pluginFinishing touchesOK, so the plugin does not have health reports (i.e. the weather icons) and it does not show a trend graph… I think I’m going to need a part 8 :-(\n","tags":["Jenkins"],"title":"Writing a Hudson plugin (Part 7 - Putting it all together)","type":"post"},{"authors":null,"categories":null,"content":"Over on the Maven2 Users list a recent poster asked what CI server was best, and Hudson was the only answer.Then Jason van Zyl posted this praise for Hudson:I know from my vantage point Hudson is the only system I will provide commercial support for at Sonatype because the battle is over. Hudson won by making developers lives’ easier. Kohsuke will go to no end to make things easier for users. …At any rate I guarantee you that inside 3 months Hudson will have the best Maven integration of any CI/Build Server there is.I’m personally biased towards Hudson, but I have to agree that it has won the war of the CI servers. I don’t see anything coming close in ease of use or speed of startup.\n","date":1207008e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1207008e3,"objectID":"3970f7d45c65da9ebb68811cb028096b","permalink":"https://stephenc.github.io/post/2008-04-01-more-praise-for-hudson/","publishdate":"2008-04-01T00:00:00Z","relpermalink":"/post/2008-04-01-more-praise-for-hudson/","section":"post","summary":"Over on the Maven2 Users list a recent poster asked what CI server was best, and Hudson was the only answer.Then Jason van Zyl posted this praise for Hudson:I know from my vantage point Hudson is the only system I will provide commercial support for at Sonatype because the battle is over. Hudson won by making developers lives’ easier. Kohsuke will go to no end to make things easier for users. …At any rate I guarantee you that inside 3 months Hudson will have the best Maven integration of any CI/Build Server there is.I’m personally biased towards Hudson, but I have to agree that it has won the war of the CI servers. I don’t see anything coming close in ease of use or speed of startup.\n","tags":["Jenkins"],"title":"More praise for Hudson","type":"post"},{"authors":null,"categories":null,"content":"In some ways parsing the JavaNCSS results is the least interesting part of developing a Hudson plugin, as once I have implemented the parser, it is available for everyone. For that reason I will focus more on:best practice techniques for parsing resultscommon gotchasdesigning for extensionGetting startedFirst off, we need to analyse the results file format. In the case of JavaNCSS there are multiple ways that the results file can be generated: from the JavaNCSS program directly, from ANT or from Maven. This leads us onto gotcha #1Gotcha #1:Never assume that a build tool generates the same format of output when run from the command line, ANT or Maven.A case in point for Gotcha #1 is Findbugs which generates one XML format from the command line and ANT, and generates a different format that appears similar at first glance when run from Maven (mail thread). In this case it turns out that Maven 1 used the different format output, and it is feared that some people came to depend on this Maven 1 format, so when the plugin for Maven 2 was developed, they kept the Maven 1 format. In any case, the moral is don’t assume, check!So we use the sample projects from Part 1 and generate an ANT and a Maven 2 XML report. First off, here is the report from ANT:2008-04-1211:22:30 com.onedash.common 1 3 10 3 \u0026lt;javadoc_lines\u0026gt;12\u0026lt;/javadoc_lines\u0026gt; \u0026lt;single_comment_lines\u0026gt;0\u0026lt;/single_comment_lines\u0026gt; \u0026lt;multi_comment_lines\u0026gt;0\u0026lt;/multi_comment_lines\u0026gt; … … 5 8 46 9 \u0026lt;javadoc_lines\u0026gt;37\u0026lt;/javadoc_lines\u0026gt; \u0026lt;single_comment_lines\u0026gt;0\u0026lt;/single_comment_lines\u0026gt; \u0026lt;multi_comment_lines\u0026gt;0\u0026lt;/multi_comment_lines\u0026gt; PackagesClassesFunctionsNCSSJavadocsper 4.005.008.0046.009.00Project 1.252.0011.502.25Package 1.609.201.80Class 5.751.13Function com.onedash.common.Factory 7 3 0 3 … … 6.60 1.60 0.00 1.80 46.00 com.onedash.common.Factory.Factory() 1 1 1 … … 46.00OK, first off, for those following the tutorial exactly, I have cheated a little. I added some more source files into the project to make sure that I have multiple classes is different packages. You can see the source code I built from here. Additionally, I have trimmed the output somewhat to highlight the interesting bits, removing the duplicate entries.From this report file we can see a basic XML structure:The root element is and has child elements: , , , , and The and elements are the timestamp when the report was generated with the date in YYYY-MM-DD format and the time in HH:MM:SS formatThe element has child elements: , , and . There are multiple ; elements, but only one and element.The elements have child elements: , , , , , \u0026lt;javadoc_lines\u0026gt;, \u0026lt;single_comment_lines\u0026gt; and \u0026lt;multi_comment_lines\u0026gt;. The element contains the name of the package as a String and the other elements contain totals as Integers.The element has child elements: , , , , \u0026lt;javadoc_lines\u0026gt;, \u0026lt;single_comment_lines\u0026gt; and \u0026lt;multi_comment_lines\u0026gt;. These elements are the sum of all the corresponding children inside the parentThe element seems to be a HTML table.The element has child elements: , and . There are multiple elements, the element contains the average results for all the elements and the element providing some form of total or average.The element has child elements: and . Again there are multiple elements with the element providing some form of total or average (interestingly the result appears to be the same as from ).Now, let’s take a look at what Maven 2 gives us:2008-04-1211:43:06 com.onedash.common 1 3 10 3 \u0026lt;javadoc_lines\u0026gt;12\u0026lt;/javadoc_lines\u0026gt; \u0026lt;single_comment_lines\u0026gt;0\u0026lt;/single_comment_lines\u0026gt; \u0026lt;multi_comment_lines\u0026gt;0\u0026lt;/multi_comment_lines\u0026gt; … … 5 8 46 10 \u0026lt;javadoc_lines\u0026gt;42\u0026lt;/javadoc_lines\u0026gt; \u0026lt;single_comment_lines\u0026gt;3\u0026lt;/single_comment_lines\u0026gt; \u0026lt;multi_comment_lines\u0026gt;3\u0026lt;/multi_comment_lines\u0026gt; PackagesClassesFunctionsNCSSJava 4.005.008.0046.0010.00P 1.252.0011.502.50Packag 1.609.202.00Class\u0026lt; 5.751.25Function\u0026lt;/ com.onedash.common.api.Namer 2 1 0 1 … … 6.60 1.60 0.00 2.00 46.00 com.onedash.common.api.Namer.newName() 1 1 0 … 46.00Thankfully, this is the same format as for ANT. You will also be relieved to know that this is the format generated by the JavaNCSS program directly. Thus we only have to write one parser, and we do not have to detect what format we are parsing. But before I forget:Best Practice #1:When there are multiple formats of a report generated by different tools, make sure that your Hudson plugin can detect the different formats and can handle them appropriately (by either delegating to a different parser implementation, or by handling the differences on the fly).One of the goals of Hudson is to minimise configuration. So when a plugin can detect an configuration option automatically, it should detect it automatically (possibly providing an “Advanced” option button to let users override the detection if Hudson gets it wrong)Start smallLooking at the JavaNCSS output, I see that there is a lot of information… and I only have one more Part left in this series! So I am not going to parse everything. I am sure that in the future I will extend the Hudson plugin to …","date":1207008e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1207008e3,"objectID":"76278b05713d75292b831647d33feef0","permalink":"https://stephenc.github.io/post/2008-04-01-writing-a-hudson-plugin-part-6-parsing-the-results/","publishdate":"2008-04-01T00:00:00Z","relpermalink":"/post/2008-04-01-writing-a-hudson-plugin-part-6-parsing-the-results/","section":"post","summary":"In some ways parsing the JavaNCSS results is the least interesting part of developing a Hudson plugin, as once I have implemented the parser, it is available for everyone. For that reason I will focus more on:best practice techniques for parsing resultscommon gotchasdesigning for extensionGetting startedFirst off, we need to analyse the results file format. In the case of JavaNCSS there are multiple ways that the results file can be generated: from the JavaNCSS program directly, from ANT or from Maven. This leads us onto gotcha #1Gotcha #1:Never assume that a build tool generates the same format of output when run from the command line, ANT or Maven.A case in point for Gotcha #1 is Findbugs which generates one XML format from the command line and ANT, and generates a different format that appears similar at first glance when run from Maven (mail thread). In this case it turns out that Maven 1 used the different format output, and it is feared that some people came to depend on this Maven 1 format, so when the plugin for Maven 2 was developed, they kept the Maven 1 format. In any case, the moral is don’t assume, check!So we use the sample projects from Part 1 and generate an ANT and a Maven 2 XML report. First off, here is the report from ANT:2008-04-1211:22:30 com.onedash.common 1 3 10 3 \u003cjavadoc_lines\u003e12\u003c/javadoc_lines\u003e \u003csingle_comment_lines\u003e0\u003c/single_comment_lines\u003e \u003cmulti_comment_lines\u003e0\u003c/multi_comment_lines\u003e … … 5 8 46 9 \u003cjavadoc_lines\u003e37\u003c/javadoc_lines\u003e \u003csingle_comment_lines\u003e0\u003c/single_comment_lines\u003e \u003cmulti_comment_lines\u003e0\u003c/multi_comment_lines\u003e PackagesClassesFunctionsNCSSJavadocsper 4.005.008.0046.009.00Project 1.252.0011.502.25Package 1.609.201.80Class 5.751.13Function com.onedash.common.Factory 7 3 0 3 … … 6.60 1.60 0.00 1.80 46.00 com.onedash.common.Factory.Factory() 1 1 1 … … 46.00OK, first off, for those following the tutorial exactly, I have cheated a little. I added some more source files into the project to make sure that I have multiple classes is different packages. You can see the source code I built from here. Additionally, I have trimmed the output somewhat to highlight the interesting bits, removing the duplicate entries.From this report file we can see a basic XML structure:The root element is and has child elements: , , , , and The and elements are the timestamp when the report was generated with the date in YYYY-MM-DD format and the time in HH:MM:SS formatThe element has child elements: , , and . There are multiple ; elements, but only one and element.The elements have child elements: , , , , , \u003cjavadoc_lines\u003e, \u003csingle_comment_lines\u003e and \u003cmulti_comment_lines\u003e. The element contains the name of the package as a String and the other elements contain totals as Integers.The element has child elements: , , , , \u003cjavadoc_lines\u003e, \u003csingle_comment_lines\u003e and \u003cmulti_comment_lines\u003e. These elements are the sum of all the corresponding children inside the parentThe element seems to be a HTML table.The element has child elements: , and . There are multiple elements, the element contains the average results for all the elements and the element providing some form of total or average.The element has child elements: and . Again there are multiple elements with the element providing some form of total or average (interestingly the result appears to be the same as from ).Now, let’s take a look at what Maven 2 gives us:2008-04-1211:43:06 com.onedash.common 1 3 10 3 \u003cjavadoc_lines\u003e12\u003c/javadoc_lines\u003e \u003csingle_comment_lines\u003e0\u003c/single_comment_lines\u003e \u003cmulti_comment_lines\u003e0\u003c/multi_comment_lines\u003e … … 5 8 46 10 \u003cjavadoc_lines\u003e42\u003c/javadoc_lines\u003e \u003csingle_comment_lines\u003e3\u003c/single_comment_lines\u003e \u003cmulti_comment_lines\u003e3\u003c/multi_comment_lines\u003e PackagesClassesFunctionsNCSSJava 4.005.008.0046.0010.00P 1.252.0011.502.50Packag 1.609.202.00Class\u003c 5.751.25Function\u003c/ com.onedash.common.api.Namer 2 1 0 1 … … 6.60 1.60 0.00 2.00 46.00 com.onedash.common.api.Namer.newName() 1 1 0 … 46.00Thankfully, this is the same format as for ANT. You will also be relieved to know that this is the format generated by the JavaNCSS program directly. Thus we only have to write one parser, and we do not have to detect what format we are parsing. But before I forget:Best Practice #1:When there are multiple formats of a report generated by different tools, make sure that your Hudson plugin can detect the different formats and can handle them appropriately (by either delegating to a different parser implementation, or by handling the differences on the fly).One of the goals of Hudson is to minimise configuration. So when a plugin can detect an configuration option automatically, it should detect it automatically (possibly providing an “Advanced” option button to let users override the detection if Hudson gets it wrong)Start smallLooking at the JavaNCSS output, I see that there is a lot of information… and I only have one more Part left in this series! So I am not going to parse everything. I am sure that in the future I will extend the Hudson plugin to parse all of the file, but for now I am just going to concentrate on the element. This gives users something useful and it’s better than nothing.But what happens when I do get around to parsing the and elements? People may have lots of old builds and they will want to see the trends of the and results. I have two choices:Tell them “Sorry, out of luck”Save the results with the build, and then the newer parser can extract the results when people want the trend.Choosing between these two options can be difficult. My preference is to go with option two, as long as the results are not a really big file.Best Practice #2:If you are not parsing everything in the results file, and the results file is not too big, and it can be parsed without reference to the source code, copy the results file to Hudson so that future versions of your plugin can read the information you are not currently parsing.Don’t over parseThe results that we parse are going to be placed into an Action object. This Action object will be serialized. When Hudson starts up, it reads all the results of all the builds. If we place too much information in our Action object, this can have a detrimental effect on Hudson’s performance. When users have 50+ projects each with a couple of hundred builds, they will thank you for keeping your Action objects small.Gotcha #2:Don’t store too much in your Action objects.Don’t under parseOK, so I have just given out about storing too much in your Action objects. There is a second problem… not storing enough! Most reporting plugins try to present a trend graph to show progress over a number of builds. If we don’t store the information required to generate this trend graph inside our Action objects, then displaying the trend graph will require parsing all the result files for all builds of a project. This can have a detrimental effect on Hudson’s performance. When users have projects with a couple of hundred builds, they will thank you for keeping the information to generate the main trend graph inside your Action objects.Gotcha #3:Store the information for generating the Project level trend graph in your Action objects.A case in point for Gotach #3 is the cobertura plugin, which at the time of writing, does not store the information for the main trend graph in the Action object. I fully intend to fix this situation once I have finished this series!How to parseMost of the result files that you will encounter are XML based. We are writing our plugins in Java, so that gives us a range of parsers to choose from, e.g.SAXDOMStAXRoll your ownEtc.Given that report files can end up very big for very big projects, we need to be careful how we parse the results:Gotcha #4:Don’t parse XML results using DOM, as this will require reading the entire report file into memory.I am going to stick my neck out and make a recommendation:Best Practice #3:Use an XML pull parser to parse XML report files.They are generally faster, use less memory, and are better suited to a “hit-and-run” style of result extraction.Be able to aggregate parsing resultsYou may think that there will only ever be one result file that you need to parse. Maven 2 usually throws a spanner into that model, and everyone has their own ANT build script, so:Gotcha #5:Don’t assume you only have to parse one report file for each project.This gotcha arrives from the code coverage plugins (emma, clover, cobertura). Initially, you would think that people are only interested in one code coverage result, i.e. the coverage for the project… so they will only have one result file that we need to parse, right? Wrong! Some tools/build scripts generate a report for each module but only generate a summary report in non-conforming HTML. Some tools / build scripts generate a report for unit tests and integration tests separately. It’s a mess, and don’t get me started on using different tools for different test types…The parsing engineOk, so here is the parsing engine:package hudson.plugins.javancss.parser;import hudson.model.AbstractBuild;import hudson.util.IOException2;import org.xmlpull.v1.XmlPullParser;import org.xmlpull.v1.XmlPullParserException;import org.xmlpull.v1.XmlPullParserFactory;import java.io.;import java.util.;public class Statistic implements Serializable { private AbstractBuild owner; private String name; private long classes; private long functions; private long ncss; private long javadocs; private long javadocLines; private long singleCommentLines; private long multiCommentLines; public static Collection parse(File inFile) throws IOException, XmlPullParserException { Collection results = new ArrayList(); FileInputStream fis = null; BufferedInputStream bis = null; try { fis = new FileInputStream(inFile); bis = new BufferedInputStream(fis); XmlPullParserFactory factory = XmlPullParserFactory.newInstance(); factory.setNamespaceAware(true); factory.setValidating(false); XmlPullParser parser = factory.newPullParser(); parser.setInput(bis, null); // check that the first tag is expectNextTag(parser, “javancss”); // skip until we get to the tag while (parser.getDepth() \u003e 0 \u0026\u0026 (parser.getEventType() != XmlPullParser.START_TAG || !“packages”.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() \u003e 0 \u0026\u0026 (parser.getEventType() != XmlPullParser.START_TAG || !“package”.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() \u003e= 2 \u0026\u0026 parser.getEventType() == XmlPullParser.START_TAG \u0026\u0026 “package”.equals(parser.getName())) { Map\u003cString, String\u003e data = new HashMap\u003cString, String\u003e(); String lastTag = null; String lastText = null; int depth = parser.getDepth(); while (parser.getDepth() \u003e= depth) { parser.next(); switch (parser.getEventType()) { case XmlPullParser.START_TAG: lastTag = parser.getName(); break; case XmlPullParser.TEXT: lastText = parser.getText(); break; case XmlPullParser.END_TAG: if (parser.getDepth() == 4 \u0026\u0026 lastTag != null \u0026\u0026 lastText != null) { data.put(lastTag, lastText); } lastTag = null; lastText = null; break; } } if (data.containsKey(“name”)) { Statistic s = new Statistic(data.get(“name”)); s.setClasses(Long.valueOf(data.get(“classes”))); s.setFunctions(Long.valueOf(data.get(“functions”))); s.setNcss(Long.valueOf(data.get(“ncss”))); s.setJavadocs(Long.valueOf(data.get(“javadocs”))); s.setJavadocLines(Long.valueOf(data.get(“javadoc_lines”))); s.setSingleCommentLines(Long.valueOf(data.get(“single_comment_lines”))); s.setMultiCommentLines(Long.valueOf(data.get(“multi_comment_lines”))); results.add(s); } parser.next(); } } catch (XmlPullParserException e) { throw new IOException2(e); } finally { if (bis != null) { bis.close(); } if (fis != null) { fis.close(); } } return results; } private static void skipTag(XmlPullParser parser) throws IOException, XmlPullParserException { parser.next(); endElement(parser); } private static void expectNextTag(XmlPullParser parser, String tag) throws IOException, XmlPullParserException { while (true) { if (parser.getEventType() != XmlPullParser.START_TAG) { parser.next(); continue; } if (parser.getName().equals(tag)) { return; } throw new IOException(“Expecting tag \" + tag); } } private static void endElement(XmlPullParser parser) throws IOException, XmlPullParserException { int depth = parser.getDepth(); while (parser.getDepth() \u003e= depth) { parser.next(); } } public Statistic(String name) { this.name = name; } … // Simple getters and setters for all the private fields … // equals based on all private fields, hashCode based on // name and owner. … // toString …}Essentially the main work is done in the static parse method. It takes a File and tries to parse it. We get an XML Pull Parser for the stream and ensure that it is neither namespace aware nor validating as the file format does not use namespaces and we will be forgiving on the XML format.The first tag should be and after that we skip until we get a tag. Once we have found the tag we skip until we hit the first tag.We are reverse engineering the JavaNCSS file format, so we will not make any assumptions about the order of the child elements in the element. We put all the child elements into a Map keyed by the element name, and then when we reach the end of the element we pull out the information we were after from the Map and put it into a Statistic object and add that to the collection of results that we will return.As soon as we hit the end of the element, we stop parsing.Supporting aggregationIn order to support aggregation of multiple results, we’ll add some utility methods to the Statistic class, first we need methods that allow us to calculate totals:package hudson.plugins.javancss.parser;…public class Statistic implements Serializable { … public static Statistic total(Collection… results) { Collection merged = merge(results); Statistic total = new Statistic(”\"); for (Statistic individual : merged) { total.add(individual); } return total; } public void add(Statistic r) { classes += r.classes; functions += r.functions; ncss += r.ncss; javadocs += r.javadocs; javadocLines += r.javadocLines; singleCommentLines += r.singleCommentLines; multiCommentLines += r.multiCommentLines; } …}The total method just calculates the total of all the statistics in a collection of statistics. We will also need to be able to merge different result sets. This should aggregate totals for each package separately and return a collection with one total statistic for each package:package hudson.plugins.javancss.parser;…public class Statistic implements Serializable { … public static Collection merge( Collection… results) { if (results.length == 0) { return Collections.emptySet(); } else if (results.length == 1) { return results[0]; } else { Map\u003cString, Statistic\u003e merged = new HashMap\u003cString, Statistic\u003e(); for (Collection result : results) { for (Statistic individual : result) { if (!merged.containsKey(individual.name)) { merged.put(individual.name, new Statistic(individual.name)); } merged.get(individual.name).add(individual); } } return merged.values(); } } …}That is pretty much it for the parser engine.The GhostwriterNow we need to hook the engine into our publisher. We will need to configure the UI elements and the Actions… all tasks for the final part, but for now, we’ll just hook it up. We want to run the parsing on the slave side so we implement Ghostwriter.SlaveGhostwriter.package hudson.plugins.javancss;import hudson.FilePath;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.helpers.Ghostwriter;import hudson.plugins.javancss.parser.Statistic;import org.xmlpull.v1.XmlPullParserException;import java.io.File;import java.io.IOException;import java.util.Collection;import java.util.HashSet;import java.util.Set;public class JavaNCSSGhostwriter implements Ghostwriter, Ghostwriter.SlaveGhostwriter { private final String reportFilenamePattern; public JavaNCSSGhostwriter(String reportFilenamePattern) { this.reportFilenamePattern = reportFilenamePattern; } public boolean performFromSlave( BuildProxy build, BuildListener listener) throws InterruptedException, IOException { FilePath[] paths = build.getExecutionRootDir() .list(reportFilenamePattern); Collection results = null; Set parsedFiles = new HashSet(); for (FilePath path : paths) { final String pathStr = path.getRemote(); if (!parsedFiles.contains(pathStr)) { parsedFiles.add(pathStr); try { Collection result = Statistic.parse(new File(pathStr)); if (results == null) { results = result; } else { results = Statistic.merge(results, result); } // TODO copy the parsed file to the master } catch (XmlPullParserException e) { e.printStackTrace(listener.getLogger()); } } } // TODO add the results into an Action an attach it to the // build. return true; }}Basically, we search the supplied wildcard-path for report files and merge all the results together into a collection of results. In the final part of this series we will create our Action to hold the results and wire everything together.\n","tags":["Jenkins"],"title":"Writing a Hudson plugin (Part 6 - Parsing the results)","type":"post"},{"authors":null,"categories":null,"content":"Ok, life has got in the way and I have not been able to update this series as quickly as I originally intended. In any case, there were a number of bugs in Hudson that I discovered and are now fixed, and there was a good deal of tidy-up needed in order for me to figure out what to do for parts 6 and 7. The good news is that I am getting closer to finishing writing these final two parts. The bad news is that there are a number of corrections to the previous posts (I have put some corrections in-line for parts 4 and 5). This post aims to ensure that, for parts 6 and 7, everyone is able to follow from the same code!pom.xmlThis needs to be updated to reference a Hudson version of at least 1.200 in order to have the bugs I identified fixed.src/main/java/hudson/plugins/helpers/AbstractBuildAction.javaAFAIK I escaped all the HTML entities and this file is the same as constructed from the previous posts.package hudson.plugins.helpers;import hudson.model.AbstractBuild;import hudson.model.HealthReportingAction;public abstract class AbstractBuildAction\u0026lt;BUILD extends AbstractBuild\u0026gt; implements HealthReportingAction { private BUILD build = null; protected AbstractBuildAction() { } public synchronized BUILD getBuild() { return build; } public synchronized void setBuild(BUILD build) { if (this.build == null \u0026amp;\u0026amp; this.build != build) { this.build = build; } } public boolean isFloatingBoxActive() { return false; } public boolean isGraphActive() { return false; } public String getGraphName() { return getDisplayName(); } public String getSummary() { return “”; }}src/main/java/hudson/plugins/helpers/AbstractMavenReporterImpl.javaAFAIK I escaped all the HTML entities and this file is the same as constructed from the previous posts.package hudson.plugins.helpers;import hudson.maven.MavenBuildProxy;import hudson.maven.MavenReporter;import hudson.maven.MojoInfo;import hudson.model.BuildListener;import hudson.model.Result;import org.apache.maven.project.MavenProject;import java.io.IOException;public abstract class AbstractMavenReporterImpl extends MavenReporter { protected MojoExecutionReportingMode getExecutionMode() { return MojoExecutionReportingMode.ONLY_REPORT_ON_SUCCESS; } public boolean postExecute(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener, Throwable error) throws InterruptedException, IOException { if (!isExecutingMojo(mojo)) { // not a mojo who’s result we are interested in return true; } final Boolean okToContinue = getExecutionMode().isOkToContinue(this, build, listener, error); if (okToContinue != null) { return okToContinue; } build.registerAsProjectAction(this); return BuildProxy.doPerform(newGhostwriter(pom, mojo), build, pom, listener); } protected abstract boolean isExecutingMojo(MojoInfo mojo); protected abstract Ghostwriter newGhostwriter(MavenProject pom, MojoInfo mojo); public boolean preExecute(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) throws InterruptedException, IOException { return !isAutoconfMojo(mojo) || autoconfPom(build, pom, mojo, listener); } protected boolean autoconfPom(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) { return true; } protected boolean isAutoconfMojo(MojoInfo mojo) { return false; } protected enum MojoExecutionReportingMode { ONLY_REPORT_ON_SUCCESS { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return error == null ? null : Boolean.TRUE; } }, ALWAYS_REPORT_STABLE { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return null; }}, REPORT_UNSTABLE_ON_ERROR { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { if (error != null) { listener.getLogger().println(\u0026#34;[HUDSON] \u0026#34; + reporter.getDescriptor().getDisplayName() + \u0026#34; setting build to UNSTABLE\u0026#34;); build.setResult(Result.UNSTABLE); } return null; } }; abstract Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error); }}src/main/java/hudson/plugins/helpers/AbstractProjectAction.javaAFAIK I escaped all the HTML entities and this file is the same as constructed from the previous posts.package hudson.plugins.helpers;import hudson.model.AbstractProject;import hudson.model.Actionable;abstract public class AbstractProjectAction\u0026lt;PROJECT extends AbstractProject\u0026gt; extends Actionable { private final PROJECT project; protected AbstractProjectAction(PROJECT project) { this.project = project; } public PROJECT getProject() { return project; } public boolean isFloatingBoxActive() { return true; } public boolean isGraphActive() { return false; } public String getGraphName() { return getDisplayName(); }}src/main/java/hudson/plugins/helpers/AbstractPublisherImpl.javaSome of the HTML entities were not properly escaped.package hudson.plugins.helpers;import hudson.tasks.Publisher;import …","date":1204329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1204329600,"objectID":"2b2c7c0e13a4c11e741574e8cd33a532","permalink":"https://stephenc.github.io/post/2008-03-01-writing-a-hudson-plugin-part-5-typos-corrected/","publishdate":"2008-03-01T00:00:00Z","relpermalink":"/post/2008-03-01-writing-a-hudson-plugin-part-5-typos-corrected/","section":"post","summary":"Ok, life has got in the way and I have not been able to update this series as quickly as I originally intended. In any case, there were a number of bugs in Hudson that I discovered and are now fixed, and there was a good deal of tidy-up needed in order for me to figure out what to do for parts 6 and 7. The good news is that I am getting closer to finishing writing these final two parts. The bad news is that there are a number of corrections to the previous posts (I have put some corrections in-line for parts 4 and 5). This post aims to ensure that, for parts 6 and 7, everyone is able to follow from the same code!pom.xmlThis needs to be updated to reference a Hudson version of at least 1.200 in order to have the bugs I identified fixed.src/main/java/hudson/plugins/helpers/AbstractBuildAction.javaAFAIK I escaped all the HTML entities and this file is the same as constructed from the previous posts.package hudson.plugins.helpers;import hudson.model.AbstractBuild;import hudson.model.HealthReportingAction;public abstract class AbstractBuildAction\u003cBUILD extends AbstractBuild\u003e implements HealthReportingAction { private BUILD build = null; protected AbstractBuildAction() { } public synchronized BUILD getBuild() { return build; } public synchronized void setBuild(BUILD build) { if (this.build == null \u0026\u0026 this.build != build) { this.build = build; } } public boolean isFloatingBoxActive() { return false; } public boolean isGraphActive() { return false; } public String getGraphName() { return getDisplayName(); } public String getSummary() { return “”; }}src/main/java/hudson/plugins/helpers/AbstractMavenReporterImpl.javaAFAIK I escaped all the HTML entities and this file is the same as constructed from the previous posts.package hudson.plugins.helpers;import hudson.maven.MavenBuildProxy;import hudson.maven.MavenReporter;import hudson.maven.MojoInfo;import hudson.model.BuildListener;import hudson.model.Result;import org.apache.maven.project.MavenProject;import java.io.IOException;public abstract class AbstractMavenReporterImpl extends MavenReporter { protected MojoExecutionReportingMode getExecutionMode() { return MojoExecutionReportingMode.ONLY_REPORT_ON_SUCCESS; } public boolean postExecute(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener, Throwable error) throws InterruptedException, IOException { if (!isExecutingMojo(mojo)) { // not a mojo who’s result we are interested in return true; } final Boolean okToContinue = getExecutionMode().isOkToContinue(this, build, listener, error); if (okToContinue != null) { return okToContinue; } build.registerAsProjectAction(this); return BuildProxy.doPerform(newGhostwriter(pom, mojo), build, pom, listener); } protected abstract boolean isExecutingMojo(MojoInfo mojo); protected abstract Ghostwriter newGhostwriter(MavenProject pom, MojoInfo mojo); public boolean preExecute(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) throws InterruptedException, IOException { return !isAutoconfMojo(mojo) || autoconfPom(build, pom, mojo, listener); } protected boolean autoconfPom(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) { return true; } protected boolean isAutoconfMojo(MojoInfo mojo) { return false; } protected enum MojoExecutionReportingMode { ONLY_REPORT_ON_SUCCESS { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return error == null ? null : Boolean.TRUE; } }, ALWAYS_REPORT_STABLE { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return null; }}, REPORT_UNSTABLE_ON_ERROR { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { if (error != null) { listener.getLogger().println(\"[HUDSON] \" + reporter.getDescriptor().getDisplayName() + \" setting build to UNSTABLE\"); build.setResult(Result.UNSTABLE); } return null; } }; abstract Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error); }}src/main/java/hudson/plugins/helpers/AbstractProjectAction.javaAFAIK I escaped all the HTML entities and this file is the same as constructed from the previous posts.package hudson.plugins.helpers;import hudson.model.AbstractProject;import hudson.model.Actionable;abstract public class AbstractProjectAction\u003cPROJECT extends AbstractProject\u003e extends Actionable { private final PROJECT project; protected AbstractProjectAction(PROJECT project) { this.project = project; } public PROJECT getProject() { return project; } public boolean isFloatingBoxActive() { return true; } public boolean isGraphActive() { return false; } public String getGraphName() { return getDisplayName(); }}src/main/java/hudson/plugins/helpers/AbstractPublisherImpl.javaSome of the HTML entities were not properly escaped.package hudson.plugins.helpers;import hudson.tasks.Publisher;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.Launcher;import java.io.IOException;public abstract class AbstractPublisherImpl extends Publisher { protected abstract Ghostwriter newGhostwriter(); public boolean perform(AbstractBuild build, Launcher launcher, final BuildListener listener) throws InterruptedException, IOException { return BuildProxy.doPerform(newGhostwriter(), build, listener); } public boolean prebuild(AbstractBuild build, BuildListener listener) { return true; }}src/main/java/hudson/plugins/helpers/BuildProxy.javaAgain, some of the HTML entities were not properly escaped. Additionally, this is the file that has had the most updates during this tutorial, so here it is in full:package hudson.plugins.helpers;import hudson.FilePath;import hudson.maven.MavenBuildProxy;import hudson.util.IOException2;import hudson.model.Action;import hudson.model.Result;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import java.util.Calendar;import java.util.List;import java.util.ArrayList;import java.io.IOException;import java.io.Serializable;import org.apache.maven.project.MavenProject;public final class BuildProxy implements Serializable { private final FilePath artifactsDir; private final FilePath projectRootDir; private final FilePath buildRootDir; private final FilePath executionRootDir; private final Calendar timestamp; private final List\u003cAbstractBuildAction\u003cAbstractBuild» actions = new ArrayList\u003cAbstractBuildAction\u003cAbstractBuild»(); private Result result = null; private boolean continueBuild = true; public static boolean doPerform(Ghostwriter ghostwriter, AbstractBuild build, BuildListener listener) throws IOException, InterruptedException { // first, do we need to do anything on the slave if (ghostwriter instanceof Ghostwriter.SlaveGhostwriter) { // construct the BuildProxy instance that we will use BuildProxy buildProxy = new BuildProxy( new FilePath(build.getArtifactsDir()), new FilePath(build.getProject().getRootDir()), new FilePath(build.getRootDir()), build.getProject().getModuleRoot(), build.getTimestamp()); BuildProxyCallableHelper callableHelper = new BuildProxyCallableHelper( buildProxy, ghostwriter, listener); try { buildProxy = buildProxy.getExecutionRootDir().act(callableHelper); buildProxy.updateBuild(build); // terminate the build if necessary if (!buildProxy.isContinueBuild()) { return false; } } catch (Exception e) { throw unwrapException(e, listener); } } // finally, on to the master final Ghostwriter.MasterGhostwriter masterGhostwriter = Ghostwriter.MasterGhostwriter.class.cast(ghostwriter); return masterGhostwriter == null || masterGhostwriter.performFromMaster(build, build.getProject().getModuleRoot(), listener); } private static RuntimeException unwrapException(Exception e, BuildListener listener) throws IOException, InterruptedException { if (e.getCause() instanceof IOException) { throw new IOException2(e.getCause().getMessage(), e); } if (e.getCause() instanceof InterruptedException) { e.getCause().printStackTrace(listener.getLogger()); throw new InterruptedException(e.getCause().getMessage()); } if (e.getCause() instanceof RuntimeException) { throw new RuntimeException(e.getCause()); } // How on earth do we get this far down the branch e.printStackTrace(listener.getLogger()); throw new RuntimeException(“Unexpected exception”, e); } public void updateBuild(AbstractBuild build) { for (AbstractBuildAction\u003cAbstractBuild\u003e action : actions) { if (!build.getActions().contains(action)) { action.setBuild(build); build.getActions().add(action); } } if (result != null \u0026\u0026 result.isWorseThan(build.getResult())) { build.setResult(result); } } public static boolean doPerform(Ghostwriter ghostwriter, MavenBuildProxy mavenBuildProxy, MavenProject pom, final BuildListener listener) throws InterruptedException, IOException { // first, construct the BuildProxy instance that we will use BuildProxy buildProxy = new BuildProxy( mavenBuildProxy.getArtifactsDir(), mavenBuildProxy.getProjectRootDir(), mavenBuildProxy.getRootDir(), new FilePath(pom.getBasedir()), mavenBuildProxy.getTimestamp()); // do we need to do anything on the slave if (ghostwriter instanceof Ghostwriter.SlaveGhostwriter) { final Ghostwriter.SlaveGhostwriter slaveGhostwriter = (Ghostwriter.SlaveGhostwriter) ghostwriter; // terminate the build if necessary if (!slaveGhostwriter.performFromSlave(buildProxy, listener)) { return false; } } // finally, on to the master try { return mavenBuildProxy.execute(new BuildProxyCallableHelper( buildProxy, ghostwriter, listener)); } catch (Exception e) { throw unwrapException(e, listener); } } private BuildProxy(FilePath artifactsDir, FilePath projectRootDir, FilePath buildRootDir, FilePath executionRootDir, Calendar timestamp) { this.artifactsDir = artifactsDir; this.projectRootDir = projectRootDir; this.buildRootDir = buildRootDir; this.executionRootDir = executionRootDir; this.timestamp = timestamp; } public List\u003cAbstractBuildAction\u003cAbstractBuild» getActions() { return actions; } public FilePath getArtifactsDir() { return artifactsDir; } public FilePath getBuildRootDir() { return buildRootDir; } public FilePath getExecutionRootDir() { return executionRootDir; } public FilePath getProjectRootDir() { return projectRootDir; } public Calendar getTimestamp() { return timestamp; } public Result getResult() { return result; } public void setResult(Result result) { this.result = result; } public boolean isContinueBuild() { return continueBuild; } public void setContinueBuild(boolean continueBuild) { this.continueBuild = continueBuild; }}src/main/java/hudson/plugins/helpers/BuildProxyCallableHelper.javaLost some HTML entities (again!)package hudson.plugins.helpers;import hudson.remoting.Callable;import hudson.maven.MavenBuildProxy;import hudson.maven.MavenBuild;import hudson.model.BuildListener;import java.io.IOException;class BuildProxyCallableHelper implements Callable\u003cBuildProxy, Exception\u003e, MavenBuildProxy.BuildCallable\u003cBoolean, Exception\u003e { private final BuildProxy buildProxy; private final Ghostwriter ghostwriter; private final BuildListener listener; BuildProxyCallableHelper(BuildProxy buildProxy, Ghostwriter ghostwriter, BuildListener listener) { this.buildProxy = buildProxy; this.ghostwriter = ghostwriter; this.listener = listener; } public Boolean call(MavenBuild mavenBuild) throws Exception { buildProxy.updateBuild(mavenBuild); if (ghostwriter instanceof Ghostwriter.MasterGhostwriter) { final Ghostwriter.MasterGhostwriter masterBuildStep = (Ghostwriter.MasterGhostwriter) ghostwriter; return masterBuildStep.performFromMaster(mavenBuild, buildProxy.getExecutionRootDir(), listener); } return true; } public BuildProxy call() throws Exception { if (ghostwriter instanceof Ghostwriter.SlaveGhostwriter) { final Ghostwriter.SlaveGhostwriter slaveBuildStep = (Ghostwriter.SlaveGhostwriter) ghostwriter; try { buildProxy.setContinueBuild( slaveBuildStep.performFromSlave(buildProxy, listener)); return buildProxy; } catch (IOException e) { throw new Exception(e); } catch (InterruptedException e) { throw new Exception(e); } } return buildProxy; }}src/main/java/hudson/plugins/helpers/Ghostwriter.javaJava Generics are a real gotcha for HTML entitiespackage hudson.plugins.helpers;import hudson.model.BuildListener;import hudson.model.AbstractBuild;import hudson.FilePath;import java.io.Serializable;import java.io.IOException;public interface Ghostwriter extends Serializable { public static interface SlaveGhostwriter extends Ghostwriter { boolean performFromSlave(BuildProxy build, BuildListener listener) throws InterruptedException, IOException; } public static interface MasterGhostwriter extends Ghostwriter { boolean performFromMaster(AbstractBuild build, FilePath executionRoot, BuildListener listener) throws InterruptedException, IOException; }}src/main/resources/hudson/plugins/helpers/AbstractBuildAction/enlargedGraph.jellyI left a “css” attribute in the \u003cl:layout\u003e tag.\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\"\u003e \u003cst:include it=\"${it.build}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“largeGraph.jelly”/\u003e \u003c/j:if\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractBuildAction/floatingBox.jellyThe \u003cj:if\u003e should be based on the from variable and not it\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cj:if test=\"${from.graphActive}\"\u003e ${from.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e enlarge \u003c/j:if\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractBuildAction/index.jellyI left a “css” attribute in the \u003cl:layout\u003e tag.\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\"\u003e \u003cst:include it=\"${it.build}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e ${it.displayName} \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e \u003c/j:if\u003e \u003cst:include page=“reportDetail.jelly”/\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractBuildAction/largeGraph.jelly, src/main/resources/hudson/plugins/helpers/AbstractBuildAction/normalGraph.jelly, and src/main/resources/hudson/plugins/helpers/AbstractBuildAction/reportDetail.jellyThese are all the same content, and are basically empty placeholders to be overrided in classes that extend AbstractBuildAction. I do not think there are any corrections.\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractBuildAction/summary.jellyThe \u003cj:if\u003e had an extra } in the expression\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\" xmlns:i=“jelly:fmt”\u003e \u003ct:summary icon=\"${it.iconFileName}\"\u003e ${it.displayName} ${it.summary} \u003c/t:summary\u003e \u003cj:if test=\"${it.floatingBoxActive}\"\u003e \u003cst:include page=“floatingBox.jelly”/\u003e \u003c/j:if\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractProjectAction/enlargedGraph.jellyI left a “css” attribute in the \u003cl:layout\u003e tag.\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\"\u003e \u003cst:include it=\"${it.project}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“largeGraph.jelly”/\u003e \u003c/j:if\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractProjectAction/floatingBox.jellyThe \u003cj:if\u003e should be based on the from variable and not it\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\" xmlns:i=“jelly:fmt” xmlns:local=“local”\u003e \u003cj:if test=\"${from.graphActive}\"\u003e ${from.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e enlarge \u003c/j:if\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractProjectAction/index.jellyI left a “css” attribute in the \u003cl:layout\u003e tag.\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\"\u003e \u003cst:include it=\"${it.project}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e ${it.displayName} \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e \u003c/j:if\u003e \u003cst:include page=“reportDetail.jelly”/\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003esrc/main/resources/hudson/plugins/helpers/AbstractProjectAction/largeGraph.jelly, src/main/resources/hudson/plugins/helpers/AbstractProjectAction/normalGraph.jelly, and src/main/resources/hudson/plugins/helpers/AbstractProjectAction/reportDetail.jellyThese are all the same content, and are basically empty placeholders to be overrided in classes that extend AbstractProjectAction. I do not think there are any corrections.\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003e\n","tags":["Jenkins"],"title":"Writing a Hudson plugin (Part 5½ - Typos corrected)","type":"post"},{"authors":null,"categories":null,"content":"This is the fourth installment, which covers the two abstract classes that call the Ghostwriter for us. When we implement our plugin we will extend from these two classes. These classes perform the work of calling the Ghostwriter at the appropriate points in the build, the concrete classes that we will develop in Part 5, however have the responsibility of creating a configured Ghostwriter and providing it to the superclass for execution.AbstractPublisherImplIn a way, this is the simplest of the two classes:package hudson.plugins.helpers;import hudson.tasks.Publisher;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.Launcher;import java.io.IOException;public abstract class AbstractPublisherImpl extends Publisher { protected abstract Ghostwriter newGhostwriter(); public boolean perform(AbstractBuild build, Launcher launcher, final BuildListener listener) throws InterruptedException, IOException { return BuildProxy.doPerform(newGhostwriter(), build, listener); } public boolean prebuild(AbstractBuild build, BuildListener listener) { return true; }}Fairly simple, we just ask the BuildProxy to invoke the new Ghostwriter created by the concrete class.AbstractMavenReporterImplThis class needs to do a bit more work. First I’ll present the abstract methods and protected methods that can be overrided by implementing classes:package hudson.plugins.helpers;import hudson.maven.MavenReporter;import hudson.maven.MojoInfo;import hudson.maven.MavenBuildProxy;import hudson.model.BuildListener;import hudson.model.Result;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.javancss.PluginImpl;import org.apache.maven.project.MavenProject;import java.io.IOException;public abstract class AbstractMavenReporterImpl extends MavenReporter { protected abstract boolean isExecutingMojo(MojoInfo mojo); protected abstract Ghostwriter newGhostwriter(MavenProject pom, MojoInfo mojo); protected boolean autoconfPom(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) { return true; } protected boolean isAutoconfMojo(MojoInfo mojo) { return false; }}Maven project execution consists of invocations of various golas of the different mojos that are bound to the Maven lifecycle. Hudson inserts hooks that allow us to intercept mojos before they execute and after they have executed. Intercepting prior to execution can be useful to ensure that the plugin has been configured with the options we require (e.g. XML output enabled). Post execution is usually when we want to invoke our Ghostwriter. If the implementing class wants to be able to tweak the mojo configuration prior to execution it needs to override isAutoconfMojo in order to identify the mojo executions that need to be tweaked, and override autoconfPom to do the actual configuration.The implementing class needs to provide:a isExecutingMojo method to identify execution of the mojo that this publisher reports on.a newGhostwriter method that constructs the Ghostwriter which will do the work for us. The new Ghostwriter can either be configured manually on the build page, and/or can be configured based on information in the pom.The final thing that we need to decide is when to execute the publisher:package hudson.plugins.helpers;…public abstract class AbstractMavenReporterImpl extends MavenReporter { … protected MojoExecutionReportingMode getExecutionMode() { return MojoExecutionReportingMode.ONLY_REPORT_ON_SUCCESS; } … protected enum MojoExecutionReportingMode { ONLY_REPORT_ON_SUCCESS { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return error == null ? null : Boolean.TRUE; } }, ALWAYS_REPORT_STABLE { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return null; }}, REPORT_UNSTABLE_ON_ERROR { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { if (error != null) { listener.getLogger().println(\u0026#34;[HUDSON] \u0026#34; + reporter.getDescriptor().getDisplayName() + \u0026#34; setting build to UNSTABLE\u0026#34;); build.setResult(Result.UNSTABLE); } return null; } }; abstract Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error); }}We define three different execution modes:ONLY_REPORT_ON_SUCCESS - this ensures that we only run the publisher if the mojo executed without error.ALWAYS_REPORT_STABLE - runs the publisher even if the mojo had an execution error, never marks the build as failed or unstable (note that Maven will most likely mark the build as failed or unstable)REPORT_UNSTABLE_ON_ERROR - runs the publisher even if the mojo had an execution error. In the event of a mojo execution error the build will be marked UNSTABLEAll that’s left is are the methods to tie these all together:package hudson.plugins.helpers;…public abstract class AbstractMavenReporterImpl extends MavenReporter { …. public boolean …","date":1201824e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1201824e3,"objectID":"f132315e7b5aaf843c915c3e1a5a24b4","permalink":"https://stephenc.github.io/post/2008-02-01-writing-a-hudson-plug-in-part-4-abstract-publishers-and-mavenreporters/","publishdate":"2008-02-01T00:00:00Z","relpermalink":"/post/2008-02-01-writing-a-hudson-plug-in-part-4-abstract-publishers-and-mavenreporters/","section":"post","summary":"This is the fourth installment, which covers the two abstract classes that call the Ghostwriter for us. When we implement our plugin we will extend from these two classes. These classes perform the work of calling the Ghostwriter at the appropriate points in the build, the concrete classes that we will develop in Part 5, however have the responsibility of creating a configured Ghostwriter and providing it to the superclass for execution.AbstractPublisherImplIn a way, this is the simplest of the two classes:package hudson.plugins.helpers;import hudson.tasks.Publisher;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.Launcher;import java.io.IOException;public abstract class AbstractPublisherImpl extends Publisher { protected abstract Ghostwriter newGhostwriter(); public boolean perform(AbstractBuild build, Launcher launcher, final BuildListener listener) throws InterruptedException, IOException { return BuildProxy.doPerform(newGhostwriter(), build, listener); } public boolean prebuild(AbstractBuild build, BuildListener listener) { return true; }}Fairly simple, we just ask the BuildProxy to invoke the new Ghostwriter created by the concrete class.AbstractMavenReporterImplThis class needs to do a bit more work. First I’ll present the abstract methods and protected methods that can be overrided by implementing classes:package hudson.plugins.helpers;import hudson.maven.MavenReporter;import hudson.maven.MojoInfo;import hudson.maven.MavenBuildProxy;import hudson.model.BuildListener;import hudson.model.Result;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.javancss.PluginImpl;import org.apache.maven.project.MavenProject;import java.io.IOException;public abstract class AbstractMavenReporterImpl extends MavenReporter { protected abstract boolean isExecutingMojo(MojoInfo mojo); protected abstract Ghostwriter newGhostwriter(MavenProject pom, MojoInfo mojo); protected boolean autoconfPom(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) { return true; } protected boolean isAutoconfMojo(MojoInfo mojo) { return false; }}Maven project execution consists of invocations of various golas of the different mojos that are bound to the Maven lifecycle. Hudson inserts hooks that allow us to intercept mojos before they execute and after they have executed. Intercepting prior to execution can be useful to ensure that the plugin has been configured with the options we require (e.g. XML output enabled). Post execution is usually when we want to invoke our Ghostwriter. If the implementing class wants to be able to tweak the mojo configuration prior to execution it needs to override isAutoconfMojo in order to identify the mojo executions that need to be tweaked, and override autoconfPom to do the actual configuration.The implementing class needs to provide:a isExecutingMojo method to identify execution of the mojo that this publisher reports on.a newGhostwriter method that constructs the Ghostwriter which will do the work for us. The new Ghostwriter can either be configured manually on the build page, and/or can be configured based on information in the pom.The final thing that we need to decide is when to execute the publisher:package hudson.plugins.helpers;…public abstract class AbstractMavenReporterImpl extends MavenReporter { … protected MojoExecutionReportingMode getExecutionMode() { return MojoExecutionReportingMode.ONLY_REPORT_ON_SUCCESS; } … protected enum MojoExecutionReportingMode { ONLY_REPORT_ON_SUCCESS { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return error == null ? null : Boolean.TRUE; } }, ALWAYS_REPORT_STABLE { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { return null; }}, REPORT_UNSTABLE_ON_ERROR { Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error) { if (error != null) { listener.getLogger().println(\"[HUDSON] \" + reporter.getDescriptor().getDisplayName() + \" setting build to UNSTABLE\"); build.setResult(Result.UNSTABLE); } return null; } }; abstract Boolean isOkToContinue(MavenReporter reporter, MavenBuildProxy build, BuildListener listener, Throwable error); }}We define three different execution modes:ONLY_REPORT_ON_SUCCESS - this ensures that we only run the publisher if the mojo executed without error.ALWAYS_REPORT_STABLE - runs the publisher even if the mojo had an execution error, never marks the build as failed or unstable (note that Maven will most likely mark the build as failed or unstable)REPORT_UNSTABLE_ON_ERROR - runs the publisher even if the mojo had an execution error. In the event of a mojo execution error the build will be marked UNSTABLEAll that’s left is are the methods to tie these all together:package hudson.plugins.helpers;…public abstract class AbstractMavenReporterImpl extends MavenReporter { …. public boolean preExecute(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener) throws InterruptedException, IOException { return !isAutoconfMojo(mojo) || autoconfPom(build, pom, mojo, listener); } public boolean postExecute(MavenBuildProxy build, MavenProject pom, MojoInfo mojo, BuildListener listener, Throwable error) throws InterruptedException, IOException { if (!isExecutingMojo(mojo)) { // not a mojo who’s result we are interested in return true; } final Boolean okToContinue = getExecutionMode() .isOkToContinue(this, build, listener, error); if (okToContinue != null) { return okToContinue; } build.registerAsProjectAction(this); return BuildProxy.doPerform(newGhostwriter(pom, mojo), build, pom, listener); }}The preExecute method checks if this is an mojo execution that we want to tweak, executing the tweaks if necessary. The postExecute method checks if this the the mojo we want to report on. Then it checks if there were execution errors, following the execution mode reported by getExecutionMode. We register this MavenReporter as a project action (thus signalling Hudson that it should call the getProjectAction() method of our reporter. We will have this method return null if we actually don’t want a project action. This is safer than trying to be smart and only calling register if we want a project action!). Finally we invoke the Ghostwriter!SummaryWell that’s it for Part 4. In the next installment, I will introduce a DRY set of classes for the reports that the publisher will generate\n","tags":["Jenkins"],"title":"Writing a Hudson plug-in (Part 4 – Abstract Publishers and MavenReporters)","type":"post"},{"authors":null,"categories":null,"content":"Until now we have been generating classes that collect the results we want to display. We have not hooked into Hudson’s methods of displaying reports. There are essentially four places that we could want to generate reports:In each individual build (we’ll call this a Single Build Report),In the project (we’ll call this a Single Project Report),In the summary of all the Maven 2 module builds associated with a multi-module Maven 2 build (we’ll call this an Aggregate Build Report), and finallyIn the Maven 2 project itself (we’ll call this an Aggregate Project Report).To make matters more confusing, each of these reports usually to implement different classes and need to implement different interfaces:Project Reports usually inherit from ActionableBuild Reports usually inherit from HealthReportingActionSingle Build Reports in Maven 2 projects need to implement AggregatableActionWhat we need is to put some common framework around these reports to ensure that we are not repeating ourselves all the time. In general, each of these four reports will be doing mostly the same things.The Build Reports will be displaying the results for a specific buildThe Project Reports will be displaying the results for the latest build (and possibly a trend chart if that makes sense)The Aggregate Reports will be displaying the aggregate of all the Single ReportsSound’s like a job for multiple inheritance! Fortune would have it that Java does not support multiple inheritance, so we will have to use some form of composition to get the same effect, and generics can help reduce the repetition too. But enough! On to the solution.AbstractBuildActionWe’ll start with a parent class for all our Build Reports. We’ll make this class generic, parameterised by the Build class that it operates on, so that we can use the same core code for all the Build Reports:package hudson.plugins.helpers;import hudson.model.AbstractBuild;import hudson.model.HealthReportingAction;public abstract class AbstractBuildAction\u0026lt;BUILD extends AbstractBuild\u0026gt; implements HealthReportingAction { private BUILD build = null; protected AbstractBuildAction() { } public synchronized BUILD getBuild() { return build; } public synchronized void setBuild(BUILD build) { if (this.build == null \u0026amp;\u0026amp; this.build != build) { this.build = build; } }}We store a reference to the build in a local variable and provide a getter for the build. Ideally we would like to the build variable to be final and initialize it in the constructor. However, Hudson’s remoting interface will get in the way of this for any actions created on the slave. The solution is to use a setter to set the build. Additionally, we have some logic that makes this setter write-once. This is just a safety net to stop us from accidentally confusing Hudson. Strictly speaking, if you are careful the setter can be justa a simple setter and not write once.[Correction] We also need to modify BuildProxy so that it calls our setter for us for actions added from slave side executions:package hudson.plugsin.helpers;…public final class BuildProxy implements Serializable { … private final List\u0026lt;AbstractBuildAction\u0026lt;AbstractBuild» actions = new ArrayList\u0026lt;AbstractBuildAction»(); … public void updateBuild(AbstractBuild\u0026lt;,?\u0026gt; build) { for (AbstractBuildAction\u0026lt;AbstractBuild\u0026gt; action: actions) { if (!build.getActions().contains(action)) { action.setBuild(build); build.getActions().add(action); } } if (result != null \u0026amp;\u0026amp; result.isWorseThan(build.getResult())) { build.setResult(result); } } … public List\u0026lt;AbstractBuildAction\u0026lt;AbstractBuild» getActions() { return actions; } …}[/Correction]In addition to these simple getters and setters, we want to provide a framework for displaying the report detail. Each different type of report has different ways of fitting into the Hudson UI. We are going to attempt to standardise these by using wrapper .jelly files to call a standard set which implementing classes can override. Jelly files are stored as resources in the hudson plugin, so with the Maven2 project structure for a Hudson plugin, the java source is /src/main/java/hudson/plugins/helpers/AbstractBuildAction.java and the jelly files for this java class are in /src/main/resources/hudson/plugins/helpers/AbstractBuildAction/. The basic things that all build reports want to do are as follows:A main report detail page (e.g. package level summary of the number of lines of code)A graph of some sort, with the option to enlarge it. (e.g. trend graph of the number of lines of code)A simple summary of the report for the main page (i.e. “17,345 lines of code (+1,534)\u0026#34;)We will implement this functionality with some properties of the AbstractBuildAction, and some default .jelly files. First the additional properties:…public abstract class AbstractBuildAction\u0026lt;BUILD extends AbstractBuild\u0026gt; implements HealthReportingAction { … public boolean isFloatingBoxActive() { return false; } public boolean isGraphActive() { return false; } public String getGraphName() { return …","date":1201824e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1201824e3,"objectID":"1cbfc8abf7ff2609bc5f562ea00e8156","permalink":"https://stephenc.github.io/post/2008-02-01-writing-a-hudson-plug-in-part-5-reporting/","publishdate":"2008-02-01T00:00:00Z","relpermalink":"/post/2008-02-01-writing-a-hudson-plug-in-part-5-reporting/","section":"post","summary":"Until now we have been generating classes that collect the results we want to display. We have not hooked into Hudson’s methods of displaying reports. There are essentially four places that we could want to generate reports:In each individual build (we’ll call this a Single Build Report),In the project (we’ll call this a Single Project Report),In the summary of all the Maven 2 module builds associated with a multi-module Maven 2 build (we’ll call this an Aggregate Build Report), and finallyIn the Maven 2 project itself (we’ll call this an Aggregate Project Report).To make matters more confusing, each of these reports usually to implement different classes and need to implement different interfaces:Project Reports usually inherit from ActionableBuild Reports usually inherit from HealthReportingActionSingle Build Reports in Maven 2 projects need to implement AggregatableActionWhat we need is to put some common framework around these reports to ensure that we are not repeating ourselves all the time. In general, each of these four reports will be doing mostly the same things.The Build Reports will be displaying the results for a specific buildThe Project Reports will be displaying the results for the latest build (and possibly a trend chart if that makes sense)The Aggregate Reports will be displaying the aggregate of all the Single ReportsSound’s like a job for multiple inheritance! Fortune would have it that Java does not support multiple inheritance, so we will have to use some form of composition to get the same effect, and generics can help reduce the repetition too. But enough! On to the solution.AbstractBuildActionWe’ll start with a parent class for all our Build Reports. We’ll make this class generic, parameterised by the Build class that it operates on, so that we can use the same core code for all the Build Reports:package hudson.plugins.helpers;import hudson.model.AbstractBuild;import hudson.model.HealthReportingAction;public abstract class AbstractBuildAction\u003cBUILD extends AbstractBuild\u003e implements HealthReportingAction { private BUILD build = null; protected AbstractBuildAction() { } public synchronized BUILD getBuild() { return build; } public synchronized void setBuild(BUILD build) { if (this.build == null \u0026\u0026 this.build != build) { this.build = build; } }}We store a reference to the build in a local variable and provide a getter for the build. Ideally we would like to the build variable to be final and initialize it in the constructor. However, Hudson’s remoting interface will get in the way of this for any actions created on the slave. The solution is to use a setter to set the build. Additionally, we have some logic that makes this setter write-once. This is just a safety net to stop us from accidentally confusing Hudson. Strictly speaking, if you are careful the setter can be justa a simple setter and not write once.[Correction] We also need to modify BuildProxy so that it calls our setter for us for actions added from slave side executions:package hudson.plugsin.helpers;…public final class BuildProxy implements Serializable { … private final List\u003cAbstractBuildAction\u003cAbstractBuild» actions = new ArrayList\u003cAbstractBuildAction»(); … public void updateBuild(AbstractBuild\u003c,?\u003e build) { for (AbstractBuildAction\u003cAbstractBuild\u003e action: actions) { if (!build.getActions().contains(action)) { action.setBuild(build); build.getActions().add(action); } } if (result != null \u0026\u0026 result.isWorseThan(build.getResult())) { build.setResult(result); } } … public List\u003cAbstractBuildAction\u003cAbstractBuild» getActions() { return actions; } …}[/Correction]In addition to these simple getters and setters, we want to provide a framework for displaying the report detail. Each different type of report has different ways of fitting into the Hudson UI. We are going to attempt to standardise these by using wrapper .jelly files to call a standard set which implementing classes can override. Jelly files are stored as resources in the hudson plugin, so with the Maven2 project structure for a Hudson plugin, the java source is /src/main/java/hudson/plugins/helpers/AbstractBuildAction.java and the jelly files for this java class are in /src/main/resources/hudson/plugins/helpers/AbstractBuildAction/. The basic things that all build reports want to do are as follows:A main report detail page (e.g. package level summary of the number of lines of code)A graph of some sort, with the option to enlarge it. (e.g. trend graph of the number of lines of code)A simple summary of the report for the main page (i.e. “17,345 lines of code (+1,534)\")We will implement this functionality with some properties of the AbstractBuildAction, and some default .jelly files. First the additional properties:…public abstract class AbstractBuildAction\u003cBUILD extends AbstractBuild\u003e implements HealthReportingAction { … public boolean isFloatingBoxActive() { return false; } public boolean isGraphActive() { return false; } public String getGraphName() { return getDisplayName(); } public String getSummary() { return “”; }}These four properties will be used to control how the action appears. isFloatingBoxActive allows us to enable the floating box on the build summary page. isGraphActive allows us to activate the graph inside the floating box. getGraphName should return the title that will be displayed above the graph. And finally, getSummary will control the summary text to display beside the build report icon on the build summary page.Next we have some empty default place-holder jelly files. These will be the jelly files that we can override in our actual reports:reportDetail.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout” xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003enormalGraph.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003elargeGraph.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003eThe reportDetail.jelly page will be used for the main report detail page, the normalGraph.jelly page will be used for the floating trend graph, while the largeGraph.jelly page will be used for the enlarged graph. To hook these pages into the Hudson framework, we need the following jelly pages:index.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\" css=\"/plugin/javancss/css/style.css\"\u003e \u003cst:include it=\"${it.build}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e ${it.displayName} \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e \u003c/j:if\u003e \u003cst:include page=“reportDetail.jelly”/\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003eThis page will also include the trend graph if it is activefloatingBox.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cj:if test=\"${it.graphActive}\"\u003e ${from.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e enlarge \u003c/j:if\u003e\u003c/j:jelly\u003esummary.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\" xmlns:i=“jelly:fmt”\u003e \u003ct:summary icon=\"${it.iconFileName}\"\u003e ${it.displayName} ${it.summary} \u003c/t:summary\u003e \u003cj:if test=\"${it.floatingBoxVisible}}\"\u003e \u003cst:include page=“floatingBox.jelly”/\u003e \u003c/j:if\u003e\u003c/j:jelly\u003eNote that the build main page does not support floating boxes, so we have to hack it in via the summary.jelly pageenlargedGraph.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\" css=\"/plugin/javancss/css/style.css\"\u003e \u003cst:include it=\"${it.build}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“largeGraph.jelly”/\u003e \u003c/j:if\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003eAbstractProjectActionThis is similar to AbstractBuildAction, however, we don’t have to deal with the write-once setter problem.package hudson.plugins.helpers;import hudson.model.AbstractProject;import hudson.model.Actionable;abstract public class AbstractProjectAction\u003cPROJECT extends AbstractProject\u003e extends Actionable { private final PROJECT project; protected AbstractProjectAction(PROJECT project) { this.project = project; } public PROJECT getProject() { return project; } public boolean isFloatingBoxActive() { return true; } public boolean isGraphActive() { return false; } public String getGraphName() { return getDisplayName(); }}Again we have a set of jelly files, we’ll repeat the same placeholders:reportDetail.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003enormalGraph.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003elargeGraph.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e\u003c/j:jelly\u003eThe other link in pages are similar, only changing from a reference for ${it.build} to ${it.project}index.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\" css=\"/plugin/javancss/css/style.css\"\u003e \u003cst:include it=\"${it.project}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e ${it.displayName} \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e \u003c/j:if\u003e \u003cst:include page=“reportDetail.jelly”/\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003efloatingBox.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\" xmlns:i=“jelly:fmt” xmlns:local=“local”\u003e \u003cj:if test=\"${it.graphActive}\"\u003e ${from.graphName} \u003cst:include page=“normalGraph.jelly”/\u003e enlarge \u003c/j:if\u003e\u003c/j:jelly\u003eThe project page automatically includes the floating box, so we don;t require the summary hackenlargedGraph.jelly\u003cj:jelly xmlns:j=“jelly:core” xmlns:st=“jelly:stapler” xmlns:d=“jelly:define” xmlns:l=\"/lib/layout\" xmlns:t=\"/lib/hudson\" xmlns:f=\"/lib/form\"\u003e \u003cl:layout xmlns:plugin=\"/hudson/plugins/javancss/tags\" css=\"/plugin/javancss/css/style.css\"\u003e \u003cst:include it=\"${it.project}\" page=“sidepanel.jelly”/\u003e \u003cl:main-panel\u003e \u003cj:if test=\"${it.graphActive}\"\u003e ${it.graphName} \u003cst:include page=“largeGraph.jelly”/\u003e \u003c/j:if\u003e \u003c/l:main-panel\u003e \u003c/l:layout\u003e\u003c/j:jelly\u003eSummaryThat’s it for part 5, next time we will implement the javancss parser and get the results for a build. Part 7 will finish off the plugin with the reports based on these two base classes.\n","tags":["Jenkins"],"title":"Writing a Hudson plug-in (Part 5 – Reporting)","type":"post"},{"authors":null,"categories":null,"content":"Writing a Hudson plug-in (Part 1 – Preparation)This is the first part of a tutorial on writing a Hudson plug-in. The aim of this tutorial is to develop a Publisher for JavaNCSS. This publisher will work with both Hudson Freestyle projects and Hudson Maven2 projects. The publisher will also include a trend graph.Before we can start plug-in development, we need to have a set of working projects to throw at our plugin. Ideally these projects should be simple and quick to build, but the most essential thing is that they build and run the tool that we want to publish the results of! We need a minimum of three projects:Ant-based projectMaven2-based single module projectMaven2-based multiple module projectSo we will develop these three basic projects, get them running the JavaNCSS tool, and then ensure they build in Hudson.The Ant-based projectWe’ll start with the Ant based project. First we’ll need a directory structure:project/ src/ main/ test/ lib/ tools/ javancss/Next we need to download the library dependencies to the lib folder (for example junit.jar) and the custom ant tasks to the appropriate sub-folder of tools.You can get JUnit.jar from http://www.junit.org.The JavaNCSS jars are available at http://www.kclee.de/clemens/java/javancss/ (Note this is the .de domain, not the .com domain). JavaNCSS comes as a zip file, so we’ll just extract the three jar files that we need: ccl.jar, javancss.jar and jhbasic.jarAt this point we should have the followingproject/ src/ main/ test/ lib/ junit.jar tools/ javancss/ ccl.jar javancss.jar jhbasic.jarNext we need a build file, and some sample java files to build. Here is a sample build.xml that will do most of what we want: \u0026lt;pathelement location=\u0026#34;${basedir}/tools/javancss/jhbasic.jar\u0026#34; We can then write some simple java classes and test our build. We’ll start with a simple HelloWorld.javapackage com.onedash.hello;/*** A basic hello world application.** @author Stephen Connolly*/public class Hello { public String sayHello(String name) { return “Hello \u0026#34; + name; } public static void main(String[] args) { Hello instance = new Hello(); if (args.length == 1) { System.out.println(instance.sayHello(args[0])); } else { System.out.println(instance.sayHello(“world”)); } }}At this point we should have the following project structure:project/ build.xml src/ main/ com/ onedash/ hello/ Hello.java test/ lib/ junit.jar tools/ javancss/ ccl.jar javancss.jar jhbasic.jarAnd running ANT should give output like:C:\\local\\project\u0026gt;ant clean distBuildfile: build.xmlclean:[delete] Deleting directory C:\\local\\project\\build[delete] Deleting directory C:\\local\\project\\distcompile: [mkdir] Created dir: C:\\local\\project\\build\\classes [javac] Compiling 5 source files to C:\\local\\project\\build\\classescompile-tests: [mkdir] Created dir: C:\\local\\project\\build\\testcases [javac] Compiling 1 source file to C:\\local\\project\\build\\testcasestest: [mkdir] Created dir: C:\\local\\project\\build\\testcases\\reportsjavancss:[javancss] Generating reportdist: [mkdir] Created dir: C:\\local\\project\\dist [jar] Building jar: C:\\local\\project\\dist\\SimpleAntProject.jarBUILD SUCCESSFULTotal time: 3 secondsAnd there should be a javancss-report.xml file in the build directory. That should be enough for an ANT project. Some extra finesse would be to add some more source code so we can examine the structure of the xml report.The Maven2 based single module projectFirst we’ll need a directory structure:project/ src/ main/ java/ test/ java/Next we need a pom.xml to describe the project for Maven2. Here is a simple pom.xml: xsi:schemaLocation=“http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; 4.0.0 com.onedash.hudson SimpleM2Project SimpleM2Project 1.0-SNAPSHOT jar junit junit 4.4 test package org.codehaus.mojo javancss-maven-plugin process-sources report We can reuse the Hello.java from the Ant project, so at this point we should have the following directory structure:project/ pom.xml src/ main/ java/ com/ onedash/ hello/ Hello.java test/ java/And running maven should give the following output:C:\\local\\project\u0026gt;mvn clean package[INFO] Scanning for projects…[INFO] —————————————————————————-[INFO] Building SimpleM2Project[INFO] task-segment: [clean, package][INFO] —————————————————————————-[INFO] [clean:clean][INFO] Deleting directory C:\\local\\project\\target[INFO] Deleting directory C:\\local\\project\\target\\classes[INFO] Deleting directory C:\\local\\project\\target\\test-classes[INFO] Deleting directory C:\\local\\project\\target\\site[INFO] [javancss:report {execution: default}][WARNING] Unable to locate Source XRef to link to - DISABLED[INFO] [resources:resources][INFO] Using default encoding to copy filtered resources.[INFO] [compiler:compile][INFO] Compiling 1 source files to C:\\local\\project\\target\\classes[INFO] [resources:testResources][INFO] Using default encoding to copy filtered resources.[INFO] [compiler:testCompile][INFO] Nothing to compile - all classes are up to date[INFO] [surefire:test][INFO] No tests to …","date":1200182400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1200182400,"objectID":"c50924ea355b535ea4c658e0ba70a1eb","permalink":"https://stephenc.github.io/post/2008-01-13-writing-a-hudson-plug-in-part-1-preparation/","publishdate":"2008-01-13T00:00:00Z","relpermalink":"/post/2008-01-13-writing-a-hudson-plug-in-part-1-preparation/","section":"post","summary":"Writing a Hudson plug-in (Part 1 – Preparation)This is the first part of a tutorial on writing a Hudson plug-in. The aim of this tutorial is to develop a Publisher for JavaNCSS. This publisher will work with both Hudson Freestyle projects and Hudson Maven2 projects. The publisher will also include a trend graph.Before we can start plug-in development, we need to have a set of working projects to throw at our plugin. Ideally these projects should be simple and quick to build, but the most essential thing is that they build and run the tool that we want to publish the results of! We need a minimum of three projects:Ant-based projectMaven2-based single module projectMaven2-based multiple module projectSo we will develop these three basic projects, get them running the JavaNCSS tool, and then ensure they build in Hudson.The Ant-based projectWe’ll start with the Ant based project. First we’ll need a directory structure:project/ src/ main/ test/ lib/ tools/ javancss/Next we need to download the library dependencies to the lib folder (for example junit.jar) and the custom ant tasks to the appropriate sub-folder of tools.You can get JUnit.jar from http://www.junit.org.The JavaNCSS jars are available at http://www.kclee.de/clemens/java/javancss/ (Note this is the .de domain, not the .com domain). JavaNCSS comes as a zip file, so we’ll just extract the three jar files that we need: ccl.jar, javancss.jar and jhbasic.jarAt this point we should have the followingproject/ src/ main/ test/ lib/ junit.jar tools/ javancss/ ccl.jar javancss.jar jhbasic.jarNext we need a build file, and some sample java files to build. Here is a sample build.xml that will do most of what we want: \u003cpathelement location=\"${basedir}/tools/javancss/jhbasic.jar\" We can then write some simple java classes and test our build. We’ll start with a simple HelloWorld.javapackage com.onedash.hello;/*** A basic hello world application.** @author Stephen Connolly*/public class Hello { public String sayHello(String name) { return “Hello \" + name; } public static void main(String[] args) { Hello instance = new Hello(); if (args.length == 1) { System.out.println(instance.sayHello(args[0])); } else { System.out.println(instance.sayHello(“world”)); } }}At this point we should have the following project structure:project/ build.xml src/ main/ com/ onedash/ hello/ Hello.java test/ lib/ junit.jar tools/ javancss/ ccl.jar javancss.jar jhbasic.jarAnd running ANT should give output like:C:\\local\\project\u003eant clean distBuildfile: build.xmlclean:[delete] Deleting directory C:\\local\\project\\build[delete] Deleting directory C:\\local\\project\\distcompile: [mkdir] Created dir: C:\\local\\project\\build\\classes [javac] Compiling 5 source files to C:\\local\\project\\build\\classescompile-tests: [mkdir] Created dir: C:\\local\\project\\build\\testcases [javac] Compiling 1 source file to C:\\local\\project\\build\\testcasestest: [mkdir] Created dir: C:\\local\\project\\build\\testcases\\reportsjavancss:[javancss] Generating reportdist: [mkdir] Created dir: C:\\local\\project\\dist [jar] Building jar: C:\\local\\project\\dist\\SimpleAntProject.jarBUILD SUCCESSFULTotal time: 3 secondsAnd there should be a javancss-report.xml file in the build directory. That should be enough for an ANT project. Some extra finesse would be to add some more source code so we can examine the structure of the xml report.The Maven2 based single module projectFirst we’ll need a directory structure:project/ src/ main/ java/ test/ java/Next we need a pom.xml to describe the project for Maven2. Here is a simple pom.xml: xsi:schemaLocation=“http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"\u003e 4.0.0 com.onedash.hudson SimpleM2Project SimpleM2Project 1.0-SNAPSHOT jar junit junit 4.4 test package org.codehaus.mojo javancss-maven-plugin process-sources report We can reuse the Hello.java from the Ant project, so at this point we should have the following directory structure:project/ pom.xml src/ main/ java/ com/ onedash/ hello/ Hello.java test/ java/And running maven should give the following output:C:\\local\\project\u003emvn clean package[INFO] Scanning for projects…[INFO] —————————————————————————-[INFO] Building SimpleM2Project[INFO] task-segment: [clean, package][INFO] —————————————————————————-[INFO] [clean:clean][INFO] Deleting directory C:\\local\\project\\target[INFO] Deleting directory C:\\local\\project\\target\\classes[INFO] Deleting directory C:\\local\\project\\target\\test-classes[INFO] Deleting directory C:\\local\\project\\target\\site[INFO] [javancss:report {execution: default}][WARNING] Unable to locate Source XRef to link to - DISABLED[INFO] [resources:resources][INFO] Using default encoding to copy filtered resources.[INFO] [compiler:compile][INFO] Compiling 1 source files to C:\\local\\project\\target\\classes[INFO] [resources:testResources][INFO] Using default encoding to copy filtered resources.[INFO] [compiler:testCompile][INFO] Nothing to compile - all classes are up to date[INFO] [surefire:test][INFO] No tests to run.[INFO] [jar:jar][INFO] Building jar: C:\\local\\project\\target\\SimpleM2Project-1.0-SNAPSHOT.jar[INFO] ————————————————————————[INFO] BUILD SUCCESSFUL[INFO] ————————————————————————[INFO] Total time: 5 seconds[INFO] Finished at: Sun Jan 13 22:06:20 GMT 2008[INFO] Final Memory: 5M/10M[INFO] ————————————————————————And there should be a javancss-raw-report.xml file in the target directory.The Maven2 based multi-module projectWe can generate this project in its simplest form just by adding the simple project as a child of a project with pom. We’ll start off with the following directory structure:project/ SimpleM2Project pom.xml src/ main/ java/ com/ onedash/ hello/ Hello.java test/ java/Where the SimpleM2Project subtree is a copy of the previous project. All we now need is a pom.xml to nest this project in: 4.0.0 com.onedash.mvn.hudson MultiM2Project MultiM2Project 1.0-SNAPSHOT pom SimpleM2Project And running maven should give the following output:C:\\local\\project\u003emvn clean package[INFO] Scanning for projects…[INFO] Reactor build order:[INFO] SimpleM2Project[INFO] MultiM2Project[INFO] —————————————————————————-[INFO] Building SimpleM2Project[INFO] task-segment: [clean, package][INFO] —————————————————————————-[INFO] [clean:clean][INFO] Deleting directory C:\\local\\project\\SimpleM2Project\\target[INFO] Deleting directory C:\\local\\project\\SimpleM2Project\\target\\classes[INFO] Deleting directory C:\\local\\project\\SimpleM2Project\\target\\test-classes[INFO] Deleting directory C:\\local\\project\\SimpleM2Project\\target\\site[INFO] [javancss:report {execution: default}][WARNING] Unable to locate Source XRef to link to - DISABLED[INFO] [resources:resources][INFO] Using default encoding to copy filtered resources.[INFO] [compiler:compile][INFO] Compiling 1 source files to C:\\local\\project\\SimpleM2Project\\target\\classes[INFO] [resources:testResources][INFO] Using default encoding to copy filtered resources.[INFO] [compiler:testCompile][INFO] No sources to compile[INFO] [surefire:test][INFO] No tests to run.[INFO] [jar:jar][INFO] Building jar: C:\\local\\project\\SimpleM2Project\\target\\SimpleM2Project-1.0-SNAPSHOT.jar[INFO] —————————————————————————-[INFO] Building MultiM2Project[INFO] task-segment: [clean, package][INFO] —————————————————————————-[INFO] [clean:clean][INFO] Deleting directory C:\\local\\project\\target[INFO] Deleting directory C:\\local\\project\\target\\classes[INFO] Deleting directory C:\\local\\project\\target\\test-classes[INFO] Deleting directory C:\\local\\project\\target\\site[INFO] [site:attach-descriptor][INFO][INFO][INFO] ————————————————————————[INFO] Reactor Summary:[INFO] ————————————————————————[INFO] SimpleM2Project ………………………………… SUCCESS [7.240s][INFO] MultiM2Project …………………………………. SUCCESS [2.754s][INFO] ————————————————————————[INFO] ————————————————————————[INFO] BUILD SUCCESSFUL[INFO] ————————————————————————[INFO] Total time: 10 seconds[INFO] Finished at: Sun Jan 13 22:16:37 GMT 2008[INFO] Final Memory: 7M/15M[INFO] ————————————————————————And there should be a javancss-raw-report.xml file in the SimpleM2Project/target directory.The Hudson setupWe’ll start by running mvn hpi:create to create a base to work from:C:\\local\u003emvn hpi:create[INFO] Scanning for projects…[INFO] Searching repository for plugin with prefix: ‘hpi’.[INFO] —————————————————————————-[INFO] Building Maven Default Project[INFO] task-segment: [hpi:create] (aggregator-style)[INFO] —————————————————————————-…[INFO] [hpi:create]Enter the groupId of your plugin: org.jvnet.hudson.plugins[INFO] Defaulting package to group ID: org.jvnet.hudson.pluginsEnter the artifactId of your plugin: javancss…[INFO] ————————————————————————[INFO] BUILD SUCCESSFUL[INFO] ————————————————————————[INFO] Total time: 2 minutes 44 seconds[INFO] Finished at: Sun Jan 13 22:34:58 GMT 2008[INFO] Final Memory: 8M/15M[INFO] ————————————————————————The result should be a sub-directory called javancss with a pom.xml file and a basic Hudson plugin starting point. We’ll edit the pom.xml to update the version of Hudson to the latest (at the time of writing 1.170) and launch a live development instance to set our projects up in.Open up the pom.xml file, and change the 1.153 tags for the hudson-core and hudson-war dependencies to 1.170.The dependency section should now look like this: org.jvnet.hudson.main hudson-core 1.170 provided org.jvnet.hudson.main hudson-war war 1.170 testNext launch a copy of Hudson by running mvn hpi:runC:\\local\\javancss\u003emvn hpi:run[INFO] Scanning for projects…[INFO] Searching repository for plugin with prefix: ‘hpi’.[INFO] —————————————————————————-[INFO] Building Unnamed - org.jvnet.hudson.plugins:javancss:hpi:1.0-SNAPSHOT[INFO] task-segment: [hpi:run][INFO] —————————————————————————-[INFO] Preparing hpi:run…[INFO] Started Jetty Server[INFO] Starting scanner at interval of 1 seconds.Now fire up a web browser for http://localhost:8080/We want to create five projects: Freestyle project for the Simple Ant projectFreestyle project for the Single module Maven2 projectFreestyle project for the Multi-module Maven2 projectMaven2 project for the Single module Maven2 projectMaven2 project for the Multi-module Maven2 projectFor extra finesse, we can add a slave executor, and create a second set of these projects tied to the slave. An final extra project that does nothing other than trigger all the other projects to build is the icing on the cake.\n","tags":["Jenkins"],"title":"Writing a Hudson plug-in (Part 1 – Preparation)","type":"post"},{"authors":null,"categories":null,"content":"Before we proceed with developing the plugin, there is an important concept to understand: How the different project types invoke their plugins.Currently, one of the biggest source of confusion for end users of Hudson is that most of the plugins do not work with the “m2 project type”. This is because there are essentially two completely different implementations of plugins.“Normal” Plugins\u0026#34;Normal\u0026#34; plugins work with all project types except the “m2 project type”. Typically they will extend Publisher. The model of execution is that the Publisher is invoked on the Hudson Master and can invoke actions remotely on the slave.The plugin author must be mindfull that they do not overload the master with excessive work, either by minimising the amount of work to be performed, or by sending work to the slave for execution. Best performance will be achieved if the heavy lifting is performed on the slave and then finally the results are sent to the master. Multiple trips back and forth between the master and the slave will not be performant.“Maven” Plugins\u0026#34;Maven\u0026#34; plugins only work with the “m2 project type”. They must extend MavenReporter. Contrary to the “Normal” plugins, they are executed on the Slave. This is because they are invoked as call-backs from the Maven Embedded that is running on the slave. If the MavenReporter is able to invoke actions remotely on the Master.The plugin author does not have to be as mindful about overloading the master, as by default, they are executing on the slave, however, the side effect is that the plugin does not have full access to all the Hudson objects, and must usually send work to the master, e.g. to add an Action to a build, it is necessary to serialize the Action, send it to the master along with a Callable that then takes the deserialized Action and adds it to the real Build. (Note: Adding an action is such a common task that BuildProxy provides convenience methods to do this for us)Don’t Repeat YourselfThe result of this split is that it can be difficult to keep the DRY principles when developing Hudson plugins. Looking at what all plugins do, though, there is a standard pattern for most Publishing plugins:Determine where the information to be published is to be foundProcess/extract the information on the slaveSend the persistent result of the build to the masterFinalize processing of the information on the masterStrictly speaking only one of the last two steps is required, however, in most cases there is a trade-off between tasks that are more performant when executed on the slave and tasks that must be performed on the master as either the required information is not available on the slave or the activity will affect the object instances on the master as an artifact of the serialization call-by-value that occurs on the slave.Thus to keep the DRY principles we need to:Publisher or MavenReporter constructs a Configuration object.If the Configuration requires tasks to execute on the slave, ensure that it is sent to the slave and execute those tasks on the slave.If the Configuration requires tasks to execute on the master, send it (if necessary back) to the master and execute those tasks on the master.There are other issues with respect to Actions, i.e. Actions for a “m2 project type” must extend a specific subclass. However, this is not a problem, as there is nothing to stop us just having all the actions extend this type, the non-“m2 project type” usage will just ignore that it’s extending the subclass.What’s nextIn part 3, I will present a couple of wrapper classes that we can use to ensure that the DRY principle gives us plugin execution in one place. Part 4 will tie these wrapper classes into the Hudson plugin framework, giving us a MavenReporter and a Publisher that both use common code to deliver the plugin functionality. Part 5 will add aggregated reporting for m2 project. Part 6 will add simple trend graphs. Part 7 will close out by actually parsing the JavaNCSS files and implementing our plugin!\n","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"c3e69772abad95741e344aaa8288e419","permalink":"https://stephenc.github.io/post/2008-01-01-writing-a-hudson-plug-in-part-2-understanding-m2-and-freestyle-projects/","publishdate":"2008-01-01T00:00:00Z","relpermalink":"/post/2008-01-01-writing-a-hudson-plug-in-part-2-understanding-m2-and-freestyle-projects/","section":"post","summary":"Before we proceed with developing the plugin, there is an important concept to understand: How the different project types invoke their plugins.Currently, one of the biggest source of confusion for end users of Hudson is that most of the plugins do not work with the “m2 project type”. This is because there are essentially two completely different implementations of plugins.“Normal” Plugins\"Normal\" plugins work with all project types except the “m2 project type”. Typically they will extend Publisher. The model of execution is that the Publisher is invoked on the Hudson Master and can invoke actions remotely on the slave.The plugin author must be mindfull that they do not overload the master with excessive work, either by minimising the amount of work to be performed, or by sending work to the slave for execution. Best performance will be achieved if the heavy lifting is performed on the slave and then finally the results are sent to the master. Multiple trips back and forth between the master and the slave will not be performant.“Maven” Plugins\"Maven\" plugins only work with the “m2 project type”. They must extend MavenReporter. Contrary to the “Normal” plugins, they are executed on the Slave. This is because they are invoked as call-backs from the Maven Embedded that is running on the slave. If the MavenReporter is able to invoke actions remotely on the Master.The plugin author does not have to be as mindful about overloading the master, as by default, they are executing on the slave, however, the side effect is that the plugin does not have full access to all the Hudson objects, and must usually send work to the master, e.g. to add an Action to a build, it is necessary to serialize the Action, send it to the master along with a Callable that then takes the deserialized Action and adds it to the real Build. (Note: Adding an action is such a common task that BuildProxy provides convenience methods to do this for us)Don’t Repeat YourselfThe result of this split is that it can be difficult to keep the DRY principles when developing Hudson plugins. Looking at what all plugins do, though, there is a standard pattern for most Publishing plugins:Determine where the information to be published is to be foundProcess/extract the information on the slaveSend the persistent result of the build to the masterFinalize processing of the information on the masterStrictly speaking only one of the last two steps is required, however, in most cases there is a trade-off between tasks that are more performant when executed on the slave and tasks that must be performed on the master as either the required information is not available on the slave or the activity will affect the object instances on the master as an artifact of the serialization call-by-value that occurs on the slave.Thus to keep the DRY principles we need to:Publisher or MavenReporter constructs a Configuration object.If the Configuration requires tasks to execute on the slave, ensure that it is sent to the slave and execute those tasks on the slave.If the Configuration requires tasks to execute on the master, send it (if necessary back) to the master and execute those tasks on the master.There are other issues with respect to Actions, i.e. Actions for a “m2 project type” must extend a specific subclass. However, this is not a problem, as there is nothing to stop us just having all the actions extend this type, the non-“m2 project type” usage will just ignore that it’s extending the subclass.What’s nextIn part 3, I will present a couple of wrapper classes that we can use to ensure that the DRY principle gives us plugin execution in one place. Part 4 will tie these wrapper classes into the Hudson plugin framework, giving us a MavenReporter and a Publisher that both use common code to deliver the plugin functionality. Part 5 will add aggregated reporting for m2 project. Part 6 will add simple trend graphs. Part 7 will close out by actually parsing the JavaNCSS files and implementing our plugin!\n","tags":["Jenkins"],"title":"Writing a Hudson plug-in (Part 2 – Understanding m2 and freestyle projects)","type":"post"},{"authors":null,"categories":null,"content":"http://burtbeckwith.com/blog/?p=53\n","date":1197590400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1197590400,"objectID":"b93a1d4b367b87be6340f1f6abed6ed7","permalink":"https://stephenc.github.io/post/2007-12-14-jpa-equals-and-hashcode/","publishdate":"2007-12-14T00:00:00Z","relpermalink":"/post/2007-12-14-jpa-equals-and-hashcode/","section":"post","summary":"http://burtbeckwith.com/blog/?p=53\n","tags":["Java","JavaEE"],"title":"JPA, equals() and hashCode()","type":"post"},{"authors":null,"categories":null,"content":"Note to self, for later reading\nhttp://technology.amis.nl/blog/?p=2610\nNot sure why netbeans is essential on this!\n","date":1195603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1195603200,"objectID":"f1eae3df32d5ce50859ecfcc5b328905","permalink":"https://stephenc.github.io/post/2007-11-21-combining-hibernate-and-facelets-with-maven-netbeans-and-glassfish/","publishdate":"2007-11-21T00:00:00Z","relpermalink":"/post/2007-11-21-combining-hibernate-and-facelets-with-maven-netbeans-and-glassfish/","section":"post","summary":"Note to self, for later reading\nhttp://technology.amis.nl/blog/?p=2610\nNot sure why netbeans is essential on this!\n","tags":["Java","Maven","JavaEE"],"title":"Combining Hibernate and Facelets with Maven, Netbeans and Glassfish","type":"post"},{"authors":null,"categories":null,"content":"This morning I discovered sventon (http://www.sventon.org) a Subversion (http://subversion.tigris.org/) repository browser written in Java. And it’s free! Ten minutes later I had this integrated as a Repository browser in Hudson (https://hudson.dev.java.net/ will be available in build 1.157) and I’m loving it. It’s not quite as good as fisheye… but it does everything I need it to!\nHudson is really starting to have kick-ass features that leave everything else for dust.\n","date":1194998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1194998400,"objectID":"7c9046f0bf37e64b162b6f711e4df13c","permalink":"https://stephenc.github.io/post/2007-11-14-sventon-and-hudson/","publishdate":"2007-11-14T00:00:00Z","relpermalink":"/post/2007-11-14-sventon-and-hudson/","section":"post","summary":"This morning I discovered sventon (http://www.sventon.org) a Subversion (http://subversion.tigris.org/) repository browser written in Java. And it’s free! Ten minutes later I had this integrated as a Repository browser in Hudson (https://hudson.dev.java.net/ will be available in build 1.157) and I’m loving it. It’s not quite as good as fisheye… but it does everything I need it to!\nHudson is really starting to have kick-ass features that leave everything else for dust.\n","tags":["Jenkins"],"title":"Sventon and Hudson","type":"post"},{"authors":null,"categories":null,"content":"Note to self, here are some code coverage tools for .NET that are free to use… and therefore good candidates for having the Coverage plugin for Hudson support off the shelf:\nhttp://sourceforge.net/projects/partcover/\nhttp://www.gotdotnet.com/Community/UserSamples/Details.aspx?SampleGuid=881a36c6-6f45-4485-a94e-060130687151\n","date":1194393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1194393600,"objectID":"40de392df5afe181cd543343a6f276e7","permalink":"https://stephenc.github.io/post/2007-11-06-hudson-coverage-plugin/","publishdate":"2007-11-07T00:00:00Z","relpermalink":"/post/2007-11-06-hudson-coverage-plugin/","section":"post","summary":"Note to self, here are some code coverage tools for .NET that are free to use… and therefore good candidates for having the Coverage plugin for Hudson support off the shelf:\nhttp://sourceforge.net/projects/partcover/\nhttp://www.gotdotnet.com/Community/UserSamples/Details.aspx?SampleGuid=881a36c6-6f45-4485-a94e-060130687151\n","tags":["Jenkins"],"title":"Hudson Coverage plugin","type":"post"},{"authors":null,"categories":null,"content":" A UML renderer written in Java http://snipsnap.org/space/SnipGraph/UML+ExampleA\nSequence Diagram renderer written in Java http://sdedit.sourceforge.net/\nA more complex set of UML digrams from UMLet http://www.umlet.com/\nA JavaScript code formatter http://code.google.com/p/google-code-prettify/\n","date":1191801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1191801600,"objectID":"974abab29c7c63768cf742f03f1b3beb","permalink":"https://stephenc.github.io/post/2007-10-08-stumbled-upon/","publishdate":"2007-10-08T00:00:00Z","relpermalink":"/post/2007-10-08-stumbled-upon/","section":"post","summary":" A UML renderer written in Java http://snipsnap.org/space/SnipGraph/UML+ExampleA\nSequence Diagram renderer written in Java http://sdedit.sourceforge.net/\nA more complex set of UML digrams from UMLet http://www.umlet.com/\nA JavaScript code formatter http://code.google.com/p/google-code-prettify/\n","tags":null,"title":"Stumbled upon","type":"post"},{"authors":null,"categories":null,"content":"I am sick of the fun that is getting JAX-WS 2.1 to work on JVM 1.6.\nOh, copy these four jars into the endorsed directory and then you can use JAX-WS 2.1… oh but sometimes it won’t work for some unknown reason and then it will work again.\nHow you are supposed to explain this to end users, I don’t know.\nSo next you need a platform specific installer to put those jars into the correct location, or a platform specific start script to tell the JVM about my alternate endorsed lib folder… or do I write a self-extracting jar file that exctracts the libs and forks a second JVM… no that won’t work for people wanting to use my library..\nWe went through all this pain with SAX and DOM. Did Sun learn nothing?\n","date":1188950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1188950400,"objectID":"d0af43e6509f59f77342f5d903afd0ea","permalink":"https://stephenc.github.io/post/2007-09-05-jax-ws-21-madness/","publishdate":"2007-09-05T00:00:00Z","relpermalink":"/post/2007-09-05-jax-ws-21-madness/","section":"post","summary":"I am sick of the fun that is getting JAX-WS 2.1 to work on JVM 1.6.\nOh, copy these four jars into the endorsed directory and then you can use JAX-WS 2.1… oh but sometimes it won’t work for some unknown reason and then it will work again.\nHow you are supposed to explain this to end users, I don’t know.\nSo next you need a platform specific installer to put those jars into the correct location, or a platform specific start script to tell the JVM about my alternate endorsed lib folder… or do I write a self-extracting jar file that exctracts the libs and forks a second JVM… no that won’t work for people wanting to use my library..\n","tags":["Java","JavaEE"],"title":"JAX-WS 2.1 madness","type":"post"},{"authors":null,"categories":null,"content":"Not perfect, but enough to get you going.\nTo build with this pom:\nYou will need to grab the sources from http://downloads.sourceforge.net/jsf-comp/chartcreator-1.2.0.source.zip and extract into src/main/java\nYou will need to grab the jar and extract the three files in the META-INF (not MANIFEST.MF) into src/main/resources/META-INF\nThen you can install away to your hearts content.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;net.sf.jsf-comp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;chartcreator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0-mavenized\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;ChartCreator\u0026lt;/name\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.4\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.4\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.faces\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsf-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2-b19\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.faces\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsf-impl\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2-b19\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.sun.facelets\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsf-facelets\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.11\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet.jsp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsp-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.portlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;portlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;jfree\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jfreechart\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; ","date":1187830800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1187830800,"objectID":"9720e84f3f601df71d58333f5bab64af","permalink":"https://stephenc.github.io/post/2007-08-01-pom-for-jsf-compsfnets-chartcreator/","publishdate":"2007-08-23T01:00:00Z","relpermalink":"/post/2007-08-01-pom-for-jsf-compsfnets-chartcreator/","section":"post","summary":"Not perfect, but enough to get you going.\nTo build with this pom:\nYou will need to grab the sources from http://downloads.sourceforge.net/jsf-comp/chartcreator-1.2.0.source.zip and extract into src/main/java\nYou will need to grab the jar and extract the three files in the META-INF (not MANIFEST.MF) into src/main/resources/META-INF\nThen you can install away to your hearts content.\n\u003c?xml version=\"1.0\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003enet.sf.jsf-comp\u003c/groupId\u003e \u003cartifactId\u003echartcreator\u003c/artifactId\u003e \u003cversion\u003e1.2.0-mavenized\u003c/version\u003e \u003cpackaging\u003ejar\u003c/packaging\u003e \u003cname\u003eChartCreator\u003c/name\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003csource\u003e1.4\u003c/source\u003e \u003ctarget\u003e1.4\u003c/target\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.faces\u003c/groupId\u003e \u003cartifactId\u003ejsf-api\u003c/artifactId\u003e \u003cversion\u003e1.2-b19\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.faces\u003c/groupId\u003e \u003cartifactId\u003ejsf-impl\u003c/artifactId\u003e \u003cversion\u003e1.2-b19\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.sun.facelets\u003c/groupId\u003e \u003cartifactId\u003ejsf-facelets\u003c/artifactId\u003e \u003cversion\u003e1.1.11\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet.jsp\u003c/groupId\u003e \u003cartifactId\u003ejsp-api\u003c/artifactId\u003e \u003cversion\u003e2.1\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.portlet\u003c/groupId\u003e \u003cartifactId\u003eportlet-api\u003c/artifactId\u003e \u003cversion\u003e1.0\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003eservlet-api\u003c/artifactId\u003e \u003cversion\u003e2.5\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejfree\u003c/groupId\u003e \u003cartifactId\u003ejfreechart\u003c/artifactId\u003e \u003cversion\u003e1.0.5\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e ","tags":["Maven"],"title":"pom for jsf-comp.sf.net's chartcreator","type":"post"},{"authors":null,"categories":null,"content":"Spent ages trying to get close to this… gave up looking at what others had done, here is my version from scratch:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;....\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;....\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;....\u0026lt;/name\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.5\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.5\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.mortbay.jetty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-jetty-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.1H.5-beta\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;contextPath\u0026gt;/\u0026lt;/contextPath\u0026gt; \u0026lt;scanIntervalSeconds\u0026gt;10\u0026lt;/scanIntervalSeconds\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.faces\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsf-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2-b19\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.faces\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsf-impl\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2-b19\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.sun.facelets\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsf-facelets\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-digester\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-digester\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-beanutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-beanutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-collections\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jstl\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; ","date":1187827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1187827200,"objectID":"bf4277d9f49211e970f0cccdbfcb8fa2","permalink":"https://stephenc.github.io/post/2007-08-23-near-minimal-maven-2-pomxml-for-jetty-development-of-facelets-applications-using-jsf-ri-12/","publishdate":"2007-08-23T00:00:00Z","relpermalink":"/post/2007-08-23-near-minimal-maven-2-pomxml-for-jetty-development-of-facelets-applications-using-jsf-ri-12/","section":"post","summary":"Spent ages trying to get close to this… gave up looking at what others had done, here is my version from scratch:\n\u003c?xml version=\"1.0\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003e....\u003c/groupId\u003e \u003cartifactId\u003e....\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cpackaging\u003ewar\u003c/packaging\u003e \u003cname\u003e....\u003c/name\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003csource\u003e1.5\u003c/source\u003e \u003ctarget\u003e1.5\u003c/target\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.mortbay.jetty\u003c/groupId\u003e \u003cartifactId\u003emaven-jetty-plugin\u003c/artifactId\u003e \u003cversion\u003e6.1H.5-beta\u003c/version\u003e \u003cconfiguration\u003e \u003ccontextPath\u003e/\u003c/contextPath\u003e \u003cscanIntervalSeconds\u003e10\u003c/scanIntervalSeconds\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.faces\u003c/groupId\u003e \u003cartifactId\u003ejsf-api\u003c/artifactId\u003e \u003cversion\u003e1.2-b19\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.faces\u003c/groupId\u003e \u003cartifactId\u003ejsf-impl\u003c/artifactId\u003e \u003cversion\u003e1.2-b19\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.sun.facelets\u003c/groupId\u003e \u003cartifactId\u003ejsf-facelets\u003c/artifactId\u003e \u003cversion\u003e1.1.11\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecommons-digester\u003c/groupId\u003e \u003cartifactId\u003ecommons-digester\u003c/artifactId\u003e \u003cversion\u003e1.7\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecommons-beanutils\u003c/groupId\u003e \u003cartifactId\u003ecommons-beanutils\u003c/artifactId\u003e \u003cversion\u003e1.7.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecommons-collections\u003c/groupId\u003e \u003cartifactId\u003ecommons-collections\u003c/artifactId\u003e \u003cversion\u003e3.2\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejstl\u003c/artifactId\u003e \u003cversion\u003e1.1.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003eservlet-api\u003c/artifactId\u003e \u003cversion\u003e2.5\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e ","tags":["Maven"],"title":"Near minimal Maven 2 pom.xml for Jetty development of Facelets applications using JSF RI 1.2","type":"post"},{"authors":null,"categories":null,"content":"Working on this to add to EasyGloss.\nThere are a number of rules that JPA entities must obey:\nequals and hashCode must only be based on the persistent fields that are @Id annotated. annotations must be applied to either fields or getters, no mix \u0026amp; match (although future versions of the spec may provide for such) In general, getters and setters should be simple methods (i.e. no complex processing) I want to have a JPA Entity excerciser that will check these rules for you (and can be included in your unit tests)\n","date":1184889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1184889600,"objectID":"fa606161a8970abd57ba85bd5c4a5c0c","permalink":"https://stephenc.github.io/post/2007-07-01-jpa-entity-exerciser/","publishdate":"2007-07-20T00:00:00Z","relpermalink":"/post/2007-07-01-jpa-entity-exerciser/","section":"post","summary":"Working on this to add to EasyGloss.\nThere are a number of rules that JPA entities must obey:\nequals and hashCode must only be based on the persistent fields that are @Id annotated. annotations must be applied to either fields or getters, no mix \u0026 match (although future versions of the spec may provide for such) In general, getters and setters should be simple methods (i.e. no complex processing) I want to have a JPA Entity excerciser that will check these rules for you (and can be included in your unit tests)\n","tags":["Java","JavaEE"],"title":"JPA Entity exerciser","type":"post"},{"authors":null,"categories":null,"content":"I have been reading a book on C# recently, and it got me thinking about Java’s hashCode() in a little bit more detail than I had before.\nConsider the following Java class.\npublic class Person { private String firstName; private String surname; public Person(String firstName, String surname) { this.firstName = firstName; this.surname = surname; } public boolean equals(Object other) { /* proper equals checking firstName and surname */ } public int hashCode() { int code = surname.hashCode(); code = 31 * code + firstName.hashCode(); return code; } public String getFirstName() { /* getter */ } public void setFirstName(String firstName) { /* setter */ } public String getSurname() { /* getter */ } public void setSurname(String surname) { /* setter */ } } What is wrong with the above? Ignore that the hash code may not be well designed given that names are usually A-Z only and the prime factor may not be the most efficient algorithm for calculating hash codes for our data set.\nOK, so I have cheated… the problem is the setters that I glossed over.\nOur hash code is not calculated on the basis of immutable values.Let’s try using it with a HashSet…\nPerson joe = new Person(\u0026#34;Joe\u0026#34;, \u0026#34;Bloggs\u0026#34;); Set people = new HashSet(); people.add(joe); assert people.contains(joe); // this works assert people.contains(new Person(\u0026#34;Joe\u0026#34;, \u0026#34;Bloggs\u0026#34;)); // this works joe.setSurname(\u0026#34;Smith\u0026#34;); assert !people.contains(new Person(\u0026#34;Joe\u0026#34;, \u0026#34;Bloggs\u0026#34;)); // this works assert people.contains(new Person(\u0026#34;Joe\u0026#34;, \u0026#34;Smith\u0026#34;)); // this fails!!! assert people.contains(joe); // this fails!!! boolean found = false; for (Person person: people) { if (person == joe) { found = true; break; } } assert found; // this works!!! So what is going on?\nWhen we put joe into the HashSet, the HashSet selects a bucket based on the hash code for joe. When we ask the HashSet if it contains a Person, it computes the hash code of the object that it’s looking for and searches only in that bucket.\nAs our hashCode() is based on non-final fields, the hash code can change behind the scenes of our HashSet (and it won’t find out until it has too few buckets and needs some more to optimise searching). Thus completely invalidating the basic assumption of the HashSet.\nA correct implementation for the Person class would either have the names as final, or have hashCode like so\npublic int hashCode() { return 0; // we have no non-final identity fields to calculate the hashCode from } ","date":1172448e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1172448e3,"objectID":"7120c4c30300915057ae6e446b3f5d2f","permalink":"https://stephenc.github.io/post/2007-02-26-hashcode-pitfalls-with-hashset-and-hashmap/","publishdate":"2007-02-26T00:00:00Z","relpermalink":"/post/2007-02-26-hashcode-pitfalls-with-hashset-and-hashmap/","section":"post","summary":"I have been reading a book on C# recently, and it got me thinking about Java’s hashCode() in a little bit more detail than I had before.\nConsider the following Java class.\npublic class Person { private String firstName; private String surname; public Person(String firstName, String surname) { this.firstName = firstName; this.surname = surname; } public boolean equals(Object other) { /* proper equals checking firstName and surname */ } public int hashCode() { int code = surname.hashCode(); code = 31 * code + firstName.hashCode(); return code; } public String getFirstName() { /* getter */ } public void setFirstName(String firstName) { /* setter */ } public String getSurname() { /* getter */ } public void setSurname(String surname) { /* setter */ } } What is wrong with the above? Ignore that the hash code may not be well designed given that names are usually A-Z only and the prime factor may not be the most efficient algorithm for calculating hash codes for our data set.\n","tags":null,"title":"hashCode() pitfalls with HashSet and HashMap","type":"post"},{"authors":null,"categories":null,"content":"Let’s have a look at some em.merge related fun.\nFrom discussions on a number of forums, here is my explanation for what goes on when you call em.merge.\nWe will use the following classes as an example:\n@Entity public class Parent { // ... private List\u0026lt;Child\u0026gt; children; // ... public List\u0026lt;Child\u0026gt; getChildren() { return this.children; } public void setChildren(List\u0026lt;Child\u0026gt; children) { this.children = children; } // ... } @Entity public class Child { // ... private Parent parent; // ... public Parent getParent() { return this.parent; } public void setParent(Parent parent) { this.parent = parent; } // ... } To aid in understanding, we will assume that our client has a UserTransaction ut (this is to allow us to force entity instances to become detached. Entity instances can becomedetached without using a UserTransaction, however, we want to show what happens to the entities;\nSo our client goes something like:\nParent parent = null; // ... ut.begin(); parent = em.find(Parent.class, aParentId); // ... At this point the client has a reference to a managed instance. We can illustrate this like so:\n[image lost - ed]\nNow at some point we have to commit the transaction and the transaction ends.\n// ... ut.commit(); // ... So now parent still points to an instance of the class Parent that still holds the data as before, however, the instances have lost their connection to the entity manager (as the connection depended on the transaction.)\nWe can illustrate this like so:\n[image lost - ed]\nLater on, we want to synchronise the parent object back to the database, so we call em.merge:\n// ... ut.begin(); Parent managedParent = em.merge(parent); // ... Now, the transaction is still active, so the instances pointed to by managedParent are still managed instances, i.e. changes made to fields will be reflected back into the database.\nThe instances pointed to by parent are still detached instances, i.e. changes made to fields do not get persisted back to the database. em.merge has done two things for us:\nFetched new managed instances of the objects we already have Synchronised all the changes in the instances we have back to the managed instances (and therefore back to the database) We can illustrate this like so:\n[image lost - ed]\nOnce we commit or otherwise end the transaction, we will now have two sets of detached instances.\nSome people want to not have references to our old detached instance lying around… so they will typically reuse the parent instance variable like so:\n// ... ut.begin() parent = em.merge(parent); // ... This is OK, provided that there are no other references to the detached entities lying around.\nIf you had done something like\n// ... Child child = parent.getChildren().get(0); ut.begin(); parent = em.merge(parent); ut.commit(); // ... Then you are in a dangerous situation as child points to a different detatched instance of the same persisted entity!!!\n[image lost - ed]\nThe moral of the story is that when you call em.merge, you need to know what instances you are merging and what you will do with the detatched instances after you have finished merging\n","date":1150416e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1150416e3,"objectID":"ded9a808988395d92d09e21563b6c638","permalink":"https://stephenc.github.io/post/2006-06-16-how-emmerge-actually-works/","publishdate":"2006-06-16T00:00:00Z","relpermalink":"/post/2006-06-16-how-emmerge-actually-works/","section":"post","summary":"Let’s have a look at some em.merge related fun.\nFrom discussions on a number of forums, here is my explanation for what goes on when you call em.merge.\nWe will use the following classes as an example:\n@Entity public class Parent { // ... private List\u003cChild\u003e children; // ... public List\u003cChild\u003e getChildren() { return this.children; } public void setChildren(List\u003cChild\u003e children) { this.children = children; } // ... } @Entity public class Child { // ... private Parent parent; // ... public Parent getParent() { return this.parent; } public void setParent(Parent parent) { this.parent = parent; } // ... } To aid in understanding, we will assume that our client has a UserTransaction ut (this is to allow us to force entity instances to become detached. Entity instances can becomedetached without using a UserTransaction, however, we want to show what happens to the entities;\n","tags":null,"title":"How em.merge actually works","type":"post"},{"authors":null,"categories":null,"content":"Borys Burnayev has an interesting article with some useful ideas on testing annotated entities and EJB3 classes requiring injection to work.\nhttp://www-128.ibm.com/developerworks/java/library/j-ejb3jpa.html\n","date":1144886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1144886400,"objectID":"e3cb4144b0f6cb4d5ee14d73af5e6f53","permalink":"https://stephenc.github.io/post/2006-04-13-another-view-on-unit-testing-annotated-entities/","publishdate":"2006-04-13T00:00:00Z","relpermalink":"/post/2006-04-13-another-view-on-unit-testing-annotated-entities/","section":"post","summary":"Borys Burnayev has an interesting article with some useful ideas on testing annotated entities and EJB3 classes requiring injection to work.\nhttp://www-128.ibm.com/developerworks/java/library/j-ejb3jpa.html\n","tags":null,"title":"Another view on unit testing annotated entities","type":"post"},{"authors":null,"categories":null,"content":"EasyGloss has been accepted as an incubator project on dev.java.net https://easygloss.dev.java.net/\n","date":11448e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":11448e5,"objectID":"a97a8714427818c45c9fbd3376836c4b","permalink":"https://stephenc.github.io/post/2006-04-12-unit-testing-of-annotated-classes-part-2/","publishdate":"2006-04-12T00:00:00Z","relpermalink":"/post/2006-04-12-unit-testing-of-annotated-classes-part-2/","section":"post","summary":"EasyGloss has been accepted as an incubator project on dev.java.net https://easygloss.dev.java.net/\n","tags":null,"title":"Unit testing of annotated classes (part 2)","type":"post"},{"authors":null,"categories":null,"content":"I ran into some fun while trying to unit test my annotated entities as some of the annotations were on private fields.\nRather than create constructors to do the injection for me, or change the access type on the fields, I came up with this little framework that people might be interested in. (Or be able to help improve)\nTemporary home: http://www.stvconsultants.com/community/easygloss/\nPermanent home: hopefully on dev.java.net\nHas anyone any comments?\n","date":1144713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1144713600,"objectID":"0d42580869ec698425997cc3a0c08f36","permalink":"https://stephenc.github.io/post/2006-04-11-unit-testing-of-annotated-classes/","publishdate":"2006-04-11T00:00:00Z","relpermalink":"/post/2006-04-11-unit-testing-of-annotated-classes/","section":"post","summary":"I ran into some fun while trying to unit test my annotated entities as some of the annotations were on private fields.\nRather than create constructors to do the injection for me, or change the access type on the fields, I came up with this little framework that people might be interested in. (Or be able to help improve)\nTemporary home: http://www.stvconsultants.com/community/easygloss/\nPermanent home: hopefully on dev.java.net\nHas anyone any comments?\n","tags":null,"title":"Unit testing of annotated classes","type":"post"},{"authors":null,"categories":null,"content":"Here are my initial thoughts (which I posted as a forum comment elsewhere)\nLayer 0. Test the entity beans are deployable (You’ll need some of the framework from Layer 4 for this). Basically, you need to know that all your annotations work. Things to watch out for are multiple @Id fields in one class or @EmbeddedID or @IdClass in conjunction with @ManyToOne, @ManyToMany, @OneToMany, @OneToOne and fun with @JoinTable, @JoinColumn and @JoinColumns. Once you know how these are supposed to work with the specification, it’s not too bad to write it correctly each time. But there are some gotchas that will break things later on.\nLayer 1. Do the functions in the classes that don’t depend on annotations work as expected. Typically, this is just going to be the getters and setters in your entity classes. Of course JUnit best practice says we don’t bother testing functions that look like:\npublic T getX() { return this.x; } // or public void setX(T x) { this.x = x; } as there is nothing that can go wrong with them. So in that case, your level 1 tests will just be initial values specified from constructors and verifying that the non-get/set pairs work, and that the getters you have tagged @Transient work (because you’ve likely put some logic in them)\nLayer 2. Test the session bean methods that don’t require injection to work.\nLayer 3. Test the session bean methods that require injection (Mock Objects). Simulate the injection for yourself, injecting Mock Objects for the entity manager. Then you can confirm that the correct methods are being called in the correct sequences, etc.\n[Note this may require some skill in designing the mock. I’m working on developing my own entitymanager mock, and if it looks useful I’ll release it to the world.]\nLayer 4. Test the session bean methods that require injection (Real entity manager) (See Layer 0) For this you will need an out of container persistence implementation. Currently Hibernate and Glassfish provide beta versions. You will need a different persistence.xml file that lists all the entities. You will have to use reflection to inject the entity manager(s) that you create from an entity manager factory unless you provide a constructor that takes an EntityManager as a parameter. You may need to use reflection to call any @PostConstruct method if you made it private.\nLayer 5. Navigate the relationships in the objects returned from Layer 4 using a database that has been loaded with test data. I am currently using Layers 0, 1, 2 \u0026amp; 4 to test my session beans and entity beans.\nHas anyone else any other ideas?\n","date":1144368e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1144368e3,"objectID":"6ca4cf13876b9a34950beba7ee75de86","permalink":"https://stephenc.github.io/post/2006-04-07-junit-testing-strategies-for-ejb3-entities-and-beans/","publishdate":"2006-04-07T00:00:00Z","relpermalink":"/post/2006-04-07-junit-testing-strategies-for-ejb3-entities-and-beans/","section":"post","summary":"Here are my initial thoughts (which I posted as a forum comment elsewhere)\nLayer 0. Test the entity beans are deployable (You’ll need some of the framework from Layer 4 for this). Basically, you need to know that all your annotations work. Things to watch out for are multiple @Id fields in one class or @EmbeddedID or @IdClass in conjunction with @ManyToOne, @ManyToMany, @OneToMany, @OneToOne and fun with @JoinTable, @JoinColumn and @JoinColumns. Once you know how these are supposed to work with the specification, it’s not too bad to write it correctly each time. But there are some gotchas that will break things later on.\n","tags":null,"title":"JUnit testing strategies for EJB3 entities and beans","type":"post"},{"authors":null,"categories":null,"content":"From the spec:\nThe deployment tool must first read the Java EE application deployment descriptor from the application .ear file (META-INF/application.xml). If the deployment descriptor is present, it fully specifies the modules included in the application. If no deployment descriptor is present, the deployment tool uses the following rules to determine the modules included in the application.\nIt would be nice if glassfish gave some warning that your application.xml might not be completely specified!\n","date":114282e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":114282e4,"objectID":"d0b7a03f56797fe2384a2d8048710ca7","permalink":"https://stephenc.github.io/post/2006-03-20-nope-its-in-the-spec/","publishdate":"2006-03-20T02:00:00Z","relpermalink":"/post/2006-03-20-nope-its-in-the-spec/","section":"post","summary":"From the spec:\nThe deployment tool must first read the Java EE application deployment descriptor from the application .ear file (META-INF/application.xml). If the deployment descriptor is present, it fully specifies the modules included in the application. If no deployment descriptor is present, the deployment tool uses the following rules to determine the modules included in the application.\nIt would be nice if glassfish gave some warning that your application.xml might not be completely specified!\n","tags":null,"title":"Nope, it's in the spec","type":"post"},{"authors":null,"categories":null,"content":"I have been going nuts trying to trace problems with deployment ofenterprise applications and resource injection.\nI think the issue is around the application.xml file in a .ear! Without an application.xml file, everything is fine and dandy. As soon as you add an application.xml file, things start breaking… it seems that when you have defined an application.xml file only those modules that are defined in the application.xml file are loaded. Without an application.xml file, all the .jar files are scanned for @Stateless and @Statefull annotations and the modules are inferred. It would help if there was some notification that maybe your application.xml file was incomplete, or else some way of restoring the scanning behaviour if you want it. Now to go digging through the spec to see if I’m just stupidly missing something or if I need to file a bug report.\n","date":1142816400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1142816400,"objectID":"fb03a5edb6caca0710089b1598ae4bb0","permalink":"https://stephenc.github.io/post/2006-03-20-applicationxml-related-stuff/","publishdate":"2006-03-20T01:00:00Z","relpermalink":"/post/2006-03-20-applicationxml-related-stuff/","section":"post","summary":"I have been going nuts trying to trace problems with deployment ofenterprise applications and resource injection.\nI think the issue is around the application.xml file in a .ear! Without an application.xml file, everything is fine and dandy. As soon as you add an application.xml file, things start breaking… it seems that when you have defined an application.xml file only those modules that are defined in the application.xml file are loaded. Without an application.xml file, all the .jar files are scanned for @Stateless and @Statefull annotations and the modules are inferred. It would help if there was some notification that maybe your application.xml file was incomplete, or else some way of restoring the scanning behaviour if you want it. Now to go digging through the spec to see if I’m just stupidly missing something or if I need to file a bug report.\n","tags":null,"title":"application.xml related stuff","type":"post"},{"authors":null,"categories":null,"content":"ELResolvers are where you get to extend the new unified EL for your own pages. They are not that difficult to extend, it’s just a case of:\nHave your class extend from ELResolver Implement the abstract methods Add an \u0026lt;el-resolver\u0026gt; element to your \u0026lt;application\u0026gt; section in faces-config.xml Start using your resolver! OK, so why would you want to do this? Well, for one it can make some things a lot easier. I was driven to find this solution in order to dynamically generate h:dataTables with variable numbers of columns. Ordinarily you would need to bind the h:dataTable to a backing bean and have the backing bean add in the extra columns, but with c:forEach now being compatible with JSF, we have an alternative.\nHere’s the model of the data we are trying to present: (the classes are coming from EJB entities which are mapping to a legacy database)\npublic class Result { // ... private Sample sample; private ResultType resultType; private String value; // ... } public class Sample { // ... private String name; private Collection\u0026lt;Result\u0026gt; results; // ... } public class Project { // ... private String name; private Collection\u0026lt;Sample\u0026gt; samples; // ... } We want to display a results table for all the samples from the project object we have been passed… it should look something like\nSample TypeA TypeB TypeC … 1 … … … … 2 … … … … … … … … … where there are as many columns as there are types. We add a method to the project class that returns Collection\u0026lt;ResultType\u0026gt; and what we’d like to do is:\n\u0026lt;h:dataTable value=\u0026#34;#{project.samples}\u0026#34; var=\u0026#34;sample\u0026#34;\u0026gt; \u0026lt;h:column\u0026gt; \u0026lt;h:outputText value=\u0026#34;#{sample.name}\u0026#34;/\u0026gt; \u0026lt;/h:column\u0026gt; \u0026lt;c:forEach items=\u0026#34;#{project.resultTypes}\u0026#34; var=\u0026#34;resultType\u0026#34;\u0026gt; \u0026lt;h:column\u0026gt; \u0026lt;h:outputText value=\u0026#34;#{sample.results[resultType].value}\u0026#34;/\u0026gt; \u0026lt;/h:column\u0026gt; \u0026lt;/c:forEach\u0026gt; \u0026lt;/h:dataTable\u0026gt; Normally this would only work if sample.results is a Map\u0026lt;String,Result\u0026gt; and each ResultType can be converted into a string that happens to be the key of the map. We end up writing a wrapper class for a Map and since we’ve been given a collection and not a map, efficiency is not the best.\nBut a custom ELResolver can help us:\nI’ll post more when I have simplified my resolver to fit this example\n","date":1141786800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1141786800,"objectID":"48818e2890298a04d70b1b0d0f68b513","permalink":"https://stephenc.github.io/post/2006-03-08-rolling-your-own-elresolver/","publishdate":"2006-03-08T03:00:00Z","relpermalink":"/post/2006-03-08-rolling-your-own-elresolver/","section":"post","summary":"ELResolvers are where you get to extend the new unified EL for your own pages. They are not that difficult to extend, it’s just a case of:\nHave your class extend from ELResolver Implement the abstract methods Add an \u003cel-resolver\u003e element to your \u003capplication\u003e section in faces-config.xml Start using your resolver! OK, so why would you want to do this? Well, for one it can make some things a lot easier. I was driven to find this solution in order to dynamically generate h:dataTables with variable numbers of columns. Ordinarily you would need to bind the h:dataTable to a backing bean and have the backing bean add in the extra columns, but with c:forEach now being compatible with JSF, we have an alternative.\n","tags":null,"title":"Rolling your own ELResolver","type":"post"},{"authors":null,"categories":null,"content":"The path to the solution to authorization woes could start here http://www.thoughtsabout.net/blog/archives/000033.html\n","date":1141344e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1141344e3,"objectID":"f955bfe00b22319f45a7ee953bf646ab","permalink":"https://stephenc.github.io/post/2006-03-03-note-to-self/","publishdate":"2006-03-03T00:00:00Z","relpermalink":"/post/2006-03-03-note-to-self/","section":"post","summary":"The path to the solution to authorization woes could start here http://www.thoughtsabout.net/blog/archives/000033.html\n","tags":null,"title":"Note to self","type":"post"},{"authors":null,"categories":null,"content":"Are you keeping up with the latest glassfish builds? Are you running windows 2k or higher? Are you fed up having to manually reinstall the server whenever a new weekly build comes out?\nWell I was, so here’s a very basic Windows NT command script.\n@ECHO OFF REM Change these environment variables to your own config SET GLASSFISH_DOWNLOADS=c:\\java\\downloads SET GLASSFISH_DRIVE=c: SET GLASSFISH_PARENT_DIR=c:\\java REM Make sure we are in the correct location %GLASSFISH_DRIVE% CD %GLASSFISH_PARENT_DIR% REM Find the latest build that has been downloaded SET BUILD=aaa FOR %%i IN (%GLASSFISH_DOWNLOADS%\\glassfish-installer-9.0-*.jar) DO IF %%i GTR %BUILD% SET BUILD=%%i IF A%BUILD%A==AaaaA GOTO no_build CLS ECHO . ECHO . ECHO Newest build found is: %BUILD% IF EXIST glassfish.bld (TYPE glassfish.bld) ELSE (ECHO Current installed build: I don\u0026#39;t know) ECHO . ECHO . ECHO . ECHO [%0] About to remove current installation of Glassfish... ECHO . ECHO This will delete any currently deployed applications, so you would want to ECHO either not care about them or have made a backup already! ECHO . ECHO . ECHO This is your last chance to press Ctrl+C to abort otherwise ECHO press any other key to continue... PAUSE \u0026gt;\u0026gt; NUL ECHO . ECHO . ECHO . ECHO [%0] Stopping domain1... ECHO . CALL ASADMIN stop-domain domain1 ECHO . ECHO . ECHO . ECHO [%0] Removing current installation... ECHO . RMDIR /S /Q %GLASSFISH_PARENT_DIR%\\glassfish ECHO . ECHO . ECHO . ECHO [%0] Starting installer... ECHO .JAVA -Xmx256m -jar %BUILD% ECHO Current installed build: %BUILD% \u0026gt; glassfish.bld ECHO . ECHO . ECHO . ECHO [%0] Setting up domain1... ECHO . CD glassfish CALL ANT -f setup.xml ECHO . ECHO . ECHO . ECHO [%0] Starting domain1... ECHO . CALL ASADMIN start-domain domain1 ECHO . ECHO . ECHO . ECHO [%0] Glassfish reinstalled! ECHO . GOTO end :no_build ECHO . ECHO . ECHO . ECHO Cannot find any glassfish builds in %GLASSFISH_DOWNLOADS% ECHO . :end ECHO . ECHO . ECHO . ECHO [%0] I\u0026#39;m done, press a key and I\u0026#39;ll be out of here... ECHO . PAUSE \u0026gt;\u0026gt; NUL Save it as, e.g. REINSTALL-GLASSFISH.CMD and all you need to do is run it every time you download a new build!\nTodo:\nAdd some stuff to make it go fetch the latest build from the download page Add some stuff to pull out all the applications from the autodeploy directory before removing the current build and put them back in afterwards. ","date":1138752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1138752e3,"objectID":"9b815235a988c3fae997dde2589270be","permalink":"https://stephenc.github.io/post/2006-02-01-keeping-up-with-the-latest-glassfish-builds/","publishdate":"2006-02-01T00:00:00Z","relpermalink":"/post/2006-02-01-keeping-up-with-the-latest-glassfish-builds/","section":"post","summary":"Are you keeping up with the latest glassfish builds? Are you running windows 2k or higher? Are you fed up having to manually reinstall the server whenever a new weekly build comes out?\nWell I was, so here’s a very basic Windows NT command script.\n@ECHO OFF REM Change these environment variables to your own config SET GLASSFISH_DOWNLOADS=c:\\java\\downloads SET GLASSFISH_DRIVE=c: SET GLASSFISH_PARENT_DIR=c:\\java REM Make sure we are in the correct location %GLASSFISH_DRIVE% CD %GLASSFISH_PARENT_DIR% REM Find the latest build that has been downloaded SET BUILD=aaa FOR %%i IN (%GLASSFISH_DOWNLOADS%\\glassfish-installer-9.0-*.jar) DO IF %%i GTR %BUILD% SET BUILD=%%i IF A%BUILD%A==AaaaA GOTO no_build CLS ECHO . ECHO . ECHO Newest build found is: %BUILD% IF EXIST glassfish.bld (TYPE glassfish.bld) ELSE (ECHO Current installed build: I don't know) ECHO . ECHO . ECHO . ECHO [%0] About to remove current installation of Glassfish... ECHO . ECHO This will delete any currently deployed applications, so you would want to ECHO either not care about them or have made a backup already! ECHO . ECHO . ECHO This is your last chance to press Ctrl+C to abort otherwise ECHO press any other key to continue... PAUSE \u003e\u003e NUL ECHO . ECHO . ECHO . ECHO [%0] Stopping domain1... ECHO . CALL ASADMIN stop-domain domain1 ECHO . ECHO . ECHO . ECHO [%0] Removing current installation... ECHO . RMDIR /S /Q %GLASSFISH_PARENT_DIR%\\glassfish ECHO . ECHO . ECHO . ECHO [%0] Starting installer... ECHO .JAVA -Xmx256m -jar %BUILD% ECHO Current installed build: %BUILD% \u003e glassfish.bld ECHO . ECHO . ECHO . ECHO [%0] Setting up domain1... ECHO . CD glassfish CALL ANT -f setup.xml ECHO . ECHO . ECHO . ECHO [%0] Starting domain1... ECHO . CALL ASADMIN start-domain domain1 ECHO . ECHO . ECHO . ECHO [%0] Glassfish reinstalled! ECHO . GOTO end :no_build ECHO . ECHO . ECHO . ECHO Cannot find any glassfish builds in %GLASSFISH_DOWNLOADS% ECHO . :end ECHO . ECHO . ECHO . ECHO [%0] I'm done, press a key and I'll be out of here... ECHO . PAUSE \u003e\u003e NUL Save it as, e.g. REINSTALL-GLASSFISH.CMD and all you need to do is run it every time you download a new build!\n","tags":null,"title":"Keeping up with the latest glassfish builds","type":"post"},{"authors":null,"categories":null,"content":"These are older project sites that are still hosted under this domain. They are likely stale but kept here for reference and historical interest.\njcip-annotations high-scale-lib java-iso-tools eaio-uuid findbugs-annotations raas wagon-gitsite junit scale7-pelops redmine-java-api-nodep redmine-java-api definalizer scale7-core ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"249ca6efec1e404f950747ddfea3ba71","permalink":"https://stephenc.github.io/legacy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/legacy/","section":"","summary":"These are older project sites that are still hosted under this domain. They are likely stale but kept here for reference and historical interest.\njcip-annotations high-scale-lib java-iso-tools eaio-uuid findbugs-annotations raas wagon-gitsite junit scale7-pelops redmine-java-api-nodep redmine-java-api definalizer scale7-core ","tags":null,"title":"Legacy project sites","type":"page"}]