<!doctype html><html lang=en-gb><head><meta charset=utf-8><meta name=viewport content="width=device-width"><script type=application/javascript src=https://stephenc.github.io/js/theme-mode.js></script><link rel=stylesheet href=https://stephenc.github.io/css/frameworks.min.css><link rel=stylesheet href=https://stephenc.github.io/css/github.min.css><link rel=stylesheet href=https://stephenc.github.io/css/github-style.css><link rel=stylesheet href=https://stephenc.github.io/css/light.css><link rel=stylesheet href=https://stephenc.github.io/css/dark.css><link rel=stylesheet href=https://stephenc.github.io/css/syntax.css><title>Writing a Hudson plugin (Part 6 - Parsing the results) - Stephen's technical blog</title><link rel=icon type=image/x-icon href=https://stephenc.github.io/images/favicon.ico><meta name=theme-color content="#1e2327"><meta name=description content='In some ways parsing the JavaNCSS results is the least interesting part of developing a Hudson plugin, as once I have implemented the parser, it is available for everyone. For that reason I will focus more on:best practice techniques for parsing resultscommon gotchasdesigning for extensionGetting startedFirst off, we need to analyse the results file format. In the case of JavaNCSS there are multiple ways that the results file can be generated: from the JavaNCSS program directly, from ANT or from Maven. This leads us onto gotcha #1Gotcha #1:Never assume that a build tool generates the same format of output when run from the command line, ANT or Maven.A case in point for Gotcha #1 is Findbugs which generates one XML format from the command line and ANT, and generates a different format that appears similar at first glance when run from Maven (mail thread). In this case it turns out that Maven 1 used the different format output, and it is feared that some people came to depend on this Maven 1 format, so when the plugin for Maven 2 was developed, they kept the Maven 1 format. In any case, the moral is don’t assume, check!So we use the sample projects from Part 1 and generate an ANT and a Maven 2 XML report. First off, here is the report from ANT:2008-04-1211:22:30 com.onedash.common 1 3 10 3 <javadoc_lines>12</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> &mldr; &mldr; 5 8 46 9 <javadoc_lines>37</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> PackagesClassesFunctionsNCSSJavadocsper 4.005.008.0046.009.00Project 1.252.0011.502.25Package 1.609.201.80Class 5.751.13Function com.onedash.common.Factory 7 3 0 3 &mldr; &mldr; 6.60 1.60 0.00 1.80 46.00 com.onedash.common.Factory.Factory() 1 1 1 &mldr; &mldr; 46.00OK, first off, for those following the tutorial exactly, I have cheated a little. I added some more source files into the project to make sure that I have multiple classes is different packages. You can see the source code I built from here. Additionally, I have trimmed the output somewhat to highlight the interesting bits, removing the duplicate entries.From this report file we can see a basic XML structure:The root element is and has child elements: , , , , and The and elements are the timestamp when the report was generated with the date in YYYY-MM-DD format and the time in HH:MM:SS formatThe element has child elements: , , and . There are multiple ; elements, but only one and element.The elements have child elements: , , , , , <javadoc_lines>, <single_comment_lines> and <multi_comment_lines>. The element contains the name of the package as a String and the other elements contain totals as Integers.The element has child elements: , , , , <javadoc_lines>, <single_comment_lines> and <multi_comment_lines>. These elements are the sum of all the corresponding children inside the parentThe element seems to be a HTML table.The element has child elements: , and . There are multiple elements, the element contains the average results for all the elements and the element providing some form of total or average.The element has child elements: and . Again there are multiple elements with the element providing some form of total or average (interestingly the result appears to be the same as from ).Now, let’s take a look at what Maven 2 gives us:2008-04-1211:43:06 com.onedash.common 1 3 10 3 <javadoc_lines>12</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> &mldr; &mldr; 5 8 46 10 <javadoc_lines>42</javadoc_lines> <single_comment_lines>3</single_comment_lines> <multi_comment_lines>3</multi_comment_lines> PackagesClassesFunctionsNCSSJava 4.005.008.0046.0010.00P 1.252.0011.502.50Packag 1.609.202.00Class< 5.751.25Function</ com.onedash.common.api.Namer 2 1 0 1 &mldr; &mldr; 6.60 1.60 0.00 2.00 46.00 com.onedash.common.api.Namer.newName() 1 1 0 &mldr; 46.00Thankfully, this is the same format as for ANT. You will also be relieved to know that this is the format generated by the JavaNCSS program directly. Thus we only have to write one parser, and we do not have to detect what format we are parsing. But before I forget:Best Practice #1:When there are multiple formats of a report generated by different tools, make sure that your Hudson plugin can detect the different formats and can handle them appropriately (by either delegating to a different parser implementation, or by handling the differences on the fly).One of the goals of Hudson is to minimise configuration. So when a plugin can detect an configuration option automatically, it should detect it automatically (possibly providing an “Advanced” option button to let users override the detection if Hudson gets it wrong)Start smallLooking at the JavaNCSS output, I see that there is a lot of information&mldr; and I only have one more Part left in this series! So I am not going to parse everything. I am sure that in the future I will extend the Hudson plugin to parse all of the file, but for now I am just going to concentrate on the element. This gives users something useful and it’s better than nothing.But what happens when I do get around to parsing the and elements? People may have lots of old builds and they will want to see the trends of the and results. I have two choices:Tell them “Sorry, out of luck”Save the results with the build, and then the newer parser can extract the results when people want the trend.Choosing between these two options can be difficult. My preference is to go with option two, as long as the results are not a really big file.Best Practice #2:If you are not parsing everything in the results file, and the results file is not too big, and it can be parsed without reference to the source code, copy the results file to Hudson so that future versions of your plugin can read the information you are not currently parsing.Don’t over parseThe results that we parse are going to be placed into an Action object. This Action object will be serialized. When Hudson starts up, it reads all the results of all the builds. If we place too much information in our Action object, this can have a detrimental effect on Hudson’s performance. When users have 50+ projects each with a couple of hundred builds, they will thank you for keeping your Action objects small.Gotcha #2:Don’t store too much in your Action objects.Don’t under parseOK, so I have just given out about storing too much in your Action objects. There is a second problem&mldr; not storing enough! Most reporting plugins try to present a trend graph to show progress over a number of builds. If we don’t store the information required to generate this trend graph inside our Action objects, then displaying the trend graph will require parsing all the result files for all builds of a project. This can have a detrimental effect on Hudson’s performance. When users have projects with a couple of hundred builds, they will thank you for keeping the information to generate the main trend graph inside your Action objects.Gotcha #3:Store the information for generating the Project level trend graph in your Action objects.A case in point for Gotach #3 is the cobertura plugin, which at the time of writing, does not store the information for the main trend graph in the Action object. I fully intend to fix this situation once I have finished this series!How to parseMost of the result files that you will encounter are XML based. We are writing our plugins in Java, so that gives us a range of parsers to choose from, e.g.SAXDOMStAXRoll your ownEtc.Given that report files can end up very big for very big projects, we need to be careful how we parse the results:Gotcha #4:Don’t parse XML results using DOM, as this will require reading the entire report file into memory.I am going to stick my neck out and make a recommendation:Best Practice #3:Use an XML pull parser to parse XML report files.They are generally faster, use less memory, and are better suited to a “hit-and-run” style of result extraction.Be able to aggregate parsing resultsYou may think that there will only ever be one result file that you need to parse. Maven 2 usually throws a spanner into that model, and everyone has their own ANT build script, so:Gotcha #5:Don’t assume you only have to parse one report file for each project.This gotcha arrives from the code coverage plugins (emma, clover, cobertura). Initially, you would think that people are only interested in one code coverage result, i.e. the coverage for the project&mldr; so they will only have one result file that we need to parse, right? Wrong! Some tools/build scripts generate a report for each module but only generate a summary report in non-conforming HTML. Some tools / build scripts generate a report for unit tests and integration tests separately. It’s a mess, and don’t get me started on using different tools for different test types&mldr;The parsing engineOk, so here is the parsing engine:package hudson.plugins.javancss.parser;import hudson.model.AbstractBuild;import hudson.util.IOException2;import org.xmlpull.v1.XmlPullParser;import org.xmlpull.v1.XmlPullParserException;import org.xmlpull.v1.XmlPullParserFactory;import java.io.;import java.util.;public class Statistic implements Serializable { private AbstractBuild owner; private String name; private long classes; private long functions; private long ncss; private long javadocs; private long javadocLines; private long singleCommentLines; private long multiCommentLines; public static Collection parse(File inFile) throws IOException, XmlPullParserException { Collection results = new ArrayList(); FileInputStream fis = null; BufferedInputStream bis = null; try { fis = new FileInputStream(inFile); bis = new BufferedInputStream(fis); XmlPullParserFactory factory = XmlPullParserFactory.newInstance(); factory.setNamespaceAware(true); factory.setValidating(false); XmlPullParser parser = factory.newPullParser(); parser.setInput(bis, null); // check that the first tag is expectNextTag(parser, &ldquo;javancss&rdquo;); // skip until we get to the tag while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;packages&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;package&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() >= 2 && parser.getEventType() == XmlPullParser.START_TAG && &ldquo;package&rdquo;.equals(parser.getName())) { Map<String, String> data = new HashMap<String, String>(); String lastTag = null; String lastText = null; int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); switch (parser.getEventType()) { case XmlPullParser.START_TAG: lastTag = parser.getName(); break; case XmlPullParser.TEXT: lastText = parser.getText(); break; case XmlPullParser.END_TAG: if (parser.getDepth() == 4 && lastTag != null && lastText != null) { data.put(lastTag, lastText); } lastTag = null; lastText = null; break; } } if (data.containsKey(&ldquo;name&rdquo;)) { Statistic s = new Statistic(data.get(&ldquo;name&rdquo;)); s.setClasses(Long.valueOf(data.get(&ldquo;classes&rdquo;))); s.setFunctions(Long.valueOf(data.get(&ldquo;functions&rdquo;))); s.setNcss(Long.valueOf(data.get(&ldquo;ncss&rdquo;))); s.setJavadocs(Long.valueOf(data.get(&ldquo;javadocs&rdquo;))); s.setJavadocLines(Long.valueOf(data.get(&ldquo;javadoc_lines&rdquo;))); s.setSingleCommentLines(Long.valueOf(data.get(&ldquo;single_comment_lines&rdquo;))); s.setMultiCommentLines(Long.valueOf(data.get(&ldquo;multi_comment_lines&rdquo;))); results.add(s); } parser.next(); } } catch (XmlPullParserException e) { throw new IOException2(e); } finally { if (bis != null) { bis.close(); } if (fis != null) { fis.close(); } } return results; } private static void skipTag(XmlPullParser parser) throws IOException, XmlPullParserException { parser.next(); endElement(parser); } private static void expectNextTag(XmlPullParser parser, String tag) throws IOException, XmlPullParserException { while (true) { if (parser.getEventType() != XmlPullParser.START_TAG) { parser.next(); continue; } if (parser.getName().equals(tag)) { return; } throw new IOException(&ldquo;Expecting tag " + tag); } } private static void endElement(XmlPullParser parser) throws IOException, XmlPullParserException { int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); } } public Statistic(String name) { this.name = name; } &mldr; // Simple getters and setters for all the private fields &mldr; // equals based on all private fields, hashCode based on // name and owner. &mldr; // toString &mldr;}Essentially the main work is done in the static parse method. It takes a File and tries to parse it. We get an XML Pull Parser for the stream and ensure that it is neither namespace aware nor validating as the file format does not use namespaces and we will be forgiving on the XML format.The first tag should be and after that we skip until we get a tag. Once we have found the tag we skip until we hit the first tag.We are reverse engineering the JavaNCSS file format, so we will not make any assumptions about the order of the child elements in the element. We put all the child elements into a Map keyed by the element name, and then when we reach the end of the element we pull out the information we were after from the Map and put it into a Statistic object and add that to the collection of results that we will return.As soon as we hit the end of the element, we stop parsing.Supporting aggregationIn order to support aggregation of multiple results, we&rsquo;ll add some utility methods to the Statistic class, first we need methods that allow us to calculate totals:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Statistic total(Collection&mldr; results) { Collection merged = merge(results); Statistic total = new Statistic(&rdquo;"); for (Statistic individual : merged) { total.add(individual); } return total; } public void add(Statistic r) { classes += r.classes; functions += r.functions; ncss += r.ncss; javadocs += r.javadocs; javadocLines += r.javadocLines; singleCommentLines += r.singleCommentLines; multiCommentLines += r.multiCommentLines; } &mldr;}The total method just calculates the total of all the statistics in a collection of statistics. We will also need to be able to merge different result sets. This should aggregate totals for each package separately and return a collection with one total statistic for each package:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Collection merge( Collection&mldr; results) { if (results.length == 0) { return Collections.emptySet(); } else if (results.length == 1) { return results[0]; } else { Map<String, Statistic> merged = new HashMap<String, Statistic>(); for (Collection result : results) { for (Statistic individual : result) { if (!merged.containsKey(individual.name)) { merged.put(individual.name, new Statistic(individual.name)); } merged.get(individual.name).add(individual); } } return merged.values(); } } &mldr;}That is pretty much it for the parser engine.The GhostwriterNow we need to hook the engine into our publisher. We will need to configure the UI elements and the Actions&mldr; all tasks for the final part, but for now, we&rsquo;ll just hook it up. We want to run the parsing on the slave side so we implement Ghostwriter.SlaveGhostwriter.package hudson.plugins.javancss;import hudson.FilePath;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.helpers.Ghostwriter;import hudson.plugins.javancss.parser.Statistic;import org.xmlpull.v1.XmlPullParserException;import java.io.File;import java.io.IOException;import java.util.Collection;import java.util.HashSet;import java.util.Set;public class JavaNCSSGhostwriter implements Ghostwriter, Ghostwriter.SlaveGhostwriter { private final String reportFilenamePattern; public JavaNCSSGhostwriter(String reportFilenamePattern) { this.reportFilenamePattern = reportFilenamePattern; } public boolean performFromSlave( BuildProxy build, BuildListener listener) throws InterruptedException, IOException { FilePath[] paths = build.getExecutionRootDir() .list(reportFilenamePattern); Collection results = null; Set parsedFiles = new HashSet(); for (FilePath path : paths) { final String pathStr = path.getRemote(); if (!parsedFiles.contains(pathStr)) { parsedFiles.add(pathStr); try { Collection result = Statistic.parse(new File(pathStr)); if (results == null) { results = result; } else { results = Statistic.merge(results, result); } // TODO copy the parsed file to the master } catch (XmlPullParserException e) { e.printStackTrace(listener.getLogger()); } } } // TODO add the results into an Action an attach it to the // build. return true; }}Basically, we search the supplied wildcard-path for report files and merge all the results together into a collection of results. In the final part of this series we will create our Action to hold the results and wire everything together.
'><meta name=keywords content='blog'><meta name=robots content="noodp"><link rel=canonical href=https://stephenc.github.io/post/2008-04-01-writing-a-hudson-plugin-part-6-parsing-the-results/><meta name=twitter:card content="summary"><meta name=twitter:title content="Writing a Hudson plugin (Part 6 - Parsing the results) - Stephen's technical blog"><meta name=twitter:description content='In some ways parsing the JavaNCSS results is the least interesting part of developing a Hudson plugin, as once I have implemented the parser, it is available for everyone. For that reason I will focus more on:best practice techniques for parsing resultscommon gotchasdesigning for extensionGetting startedFirst off, we need to analyse the results file format. In the case of JavaNCSS there are multiple ways that the results file can be generated: from the JavaNCSS program directly, from ANT or from Maven. This leads us onto gotcha #1Gotcha #1:Never assume that a build tool generates the same format of output when run from the command line, ANT or Maven.A case in point for Gotcha #1 is Findbugs which generates one XML format from the command line and ANT, and generates a different format that appears similar at first glance when run from Maven (mail thread). In this case it turns out that Maven 1 used the different format output, and it is feared that some people came to depend on this Maven 1 format, so when the plugin for Maven 2 was developed, they kept the Maven 1 format. In any case, the moral is don’t assume, check!So we use the sample projects from Part 1 and generate an ANT and a Maven 2 XML report. First off, here is the report from ANT:2008-04-1211:22:30 com.onedash.common 1 3 10 3 <javadoc_lines>12</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> &mldr; &mldr; 5 8 46 9 <javadoc_lines>37</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> PackagesClassesFunctionsNCSSJavadocsper 4.005.008.0046.009.00Project 1.252.0011.502.25Package 1.609.201.80Class 5.751.13Function com.onedash.common.Factory 7 3 0 3 &mldr; &mldr; 6.60 1.60 0.00 1.80 46.00 com.onedash.common.Factory.Factory() 1 1 1 &mldr; &mldr; 46.00OK, first off, for those following the tutorial exactly, I have cheated a little. I added some more source files into the project to make sure that I have multiple classes is different packages. You can see the source code I built from here. Additionally, I have trimmed the output somewhat to highlight the interesting bits, removing the duplicate entries.From this report file we can see a basic XML structure:The root element is and has child elements: , , , , and The and elements are the timestamp when the report was generated with the date in YYYY-MM-DD format and the time in HH:MM:SS formatThe element has child elements: , , and . There are multiple ; elements, but only one and element.The elements have child elements: , , , , , <javadoc_lines>, <single_comment_lines> and <multi_comment_lines>. The element contains the name of the package as a String and the other elements contain totals as Integers.The element has child elements: , , , , <javadoc_lines>, <single_comment_lines> and <multi_comment_lines>. These elements are the sum of all the corresponding children inside the parentThe element seems to be a HTML table.The element has child elements: , and . There are multiple elements, the element contains the average results for all the elements and the element providing some form of total or average.The element has child elements: and . Again there are multiple elements with the element providing some form of total or average (interestingly the result appears to be the same as from ).Now, let’s take a look at what Maven 2 gives us:2008-04-1211:43:06 com.onedash.common 1 3 10 3 <javadoc_lines>12</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> &mldr; &mldr; 5 8 46 10 <javadoc_lines>42</javadoc_lines> <single_comment_lines>3</single_comment_lines> <multi_comment_lines>3</multi_comment_lines> PackagesClassesFunctionsNCSSJava 4.005.008.0046.0010.00P 1.252.0011.502.50Packag 1.609.202.00Class< 5.751.25Function</ com.onedash.common.api.Namer 2 1 0 1 &mldr; &mldr; 6.60 1.60 0.00 2.00 46.00 com.onedash.common.api.Namer.newName() 1 1 0 &mldr; 46.00Thankfully, this is the same format as for ANT. You will also be relieved to know that this is the format generated by the JavaNCSS program directly. Thus we only have to write one parser, and we do not have to detect what format we are parsing. But before I forget:Best Practice #1:When there are multiple formats of a report generated by different tools, make sure that your Hudson plugin can detect the different formats and can handle them appropriately (by either delegating to a different parser implementation, or by handling the differences on the fly).One of the goals of Hudson is to minimise configuration. So when a plugin can detect an configuration option automatically, it should detect it automatically (possibly providing an “Advanced” option button to let users override the detection if Hudson gets it wrong)Start smallLooking at the JavaNCSS output, I see that there is a lot of information&mldr; and I only have one more Part left in this series! So I am not going to parse everything. I am sure that in the future I will extend the Hudson plugin to parse all of the file, but for now I am just going to concentrate on the element. This gives users something useful and it’s better than nothing.But what happens when I do get around to parsing the and elements? People may have lots of old builds and they will want to see the trends of the and results. I have two choices:Tell them “Sorry, out of luck”Save the results with the build, and then the newer parser can extract the results when people want the trend.Choosing between these two options can be difficult. My preference is to go with option two, as long as the results are not a really big file.Best Practice #2:If you are not parsing everything in the results file, and the results file is not too big, and it can be parsed without reference to the source code, copy the results file to Hudson so that future versions of your plugin can read the information you are not currently parsing.Don’t over parseThe results that we parse are going to be placed into an Action object. This Action object will be serialized. When Hudson starts up, it reads all the results of all the builds. If we place too much information in our Action object, this can have a detrimental effect on Hudson’s performance. When users have 50+ projects each with a couple of hundred builds, they will thank you for keeping your Action objects small.Gotcha #2:Don’t store too much in your Action objects.Don’t under parseOK, so I have just given out about storing too much in your Action objects. There is a second problem&mldr; not storing enough! Most reporting plugins try to present a trend graph to show progress over a number of builds. If we don’t store the information required to generate this trend graph inside our Action objects, then displaying the trend graph will require parsing all the result files for all builds of a project. This can have a detrimental effect on Hudson’s performance. When users have projects with a couple of hundred builds, they will thank you for keeping the information to generate the main trend graph inside your Action objects.Gotcha #3:Store the information for generating the Project level trend graph in your Action objects.A case in point for Gotach #3 is the cobertura plugin, which at the time of writing, does not store the information for the main trend graph in the Action object. I fully intend to fix this situation once I have finished this series!How to parseMost of the result files that you will encounter are XML based. We are writing our plugins in Java, so that gives us a range of parsers to choose from, e.g.SAXDOMStAXRoll your ownEtc.Given that report files can end up very big for very big projects, we need to be careful how we parse the results:Gotcha #4:Don’t parse XML results using DOM, as this will require reading the entire report file into memory.I am going to stick my neck out and make a recommendation:Best Practice #3:Use an XML pull parser to parse XML report files.They are generally faster, use less memory, and are better suited to a “hit-and-run” style of result extraction.Be able to aggregate parsing resultsYou may think that there will only ever be one result file that you need to parse. Maven 2 usually throws a spanner into that model, and everyone has their own ANT build script, so:Gotcha #5:Don’t assume you only have to parse one report file for each project.This gotcha arrives from the code coverage plugins (emma, clover, cobertura). Initially, you would think that people are only interested in one code coverage result, i.e. the coverage for the project&mldr; so they will only have one result file that we need to parse, right? Wrong! Some tools/build scripts generate a report for each module but only generate a summary report in non-conforming HTML. Some tools / build scripts generate a report for unit tests and integration tests separately. It’s a mess, and don’t get me started on using different tools for different test types&mldr;The parsing engineOk, so here is the parsing engine:package hudson.plugins.javancss.parser;import hudson.model.AbstractBuild;import hudson.util.IOException2;import org.xmlpull.v1.XmlPullParser;import org.xmlpull.v1.XmlPullParserException;import org.xmlpull.v1.XmlPullParserFactory;import java.io.;import java.util.;public class Statistic implements Serializable { private AbstractBuild owner; private String name; private long classes; private long functions; private long ncss; private long javadocs; private long javadocLines; private long singleCommentLines; private long multiCommentLines; public static Collection parse(File inFile) throws IOException, XmlPullParserException { Collection results = new ArrayList(); FileInputStream fis = null; BufferedInputStream bis = null; try { fis = new FileInputStream(inFile); bis = new BufferedInputStream(fis); XmlPullParserFactory factory = XmlPullParserFactory.newInstance(); factory.setNamespaceAware(true); factory.setValidating(false); XmlPullParser parser = factory.newPullParser(); parser.setInput(bis, null); // check that the first tag is expectNextTag(parser, &ldquo;javancss&rdquo;); // skip until we get to the tag while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;packages&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;package&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() >= 2 && parser.getEventType() == XmlPullParser.START_TAG && &ldquo;package&rdquo;.equals(parser.getName())) { Map<String, String> data = new HashMap<String, String>(); String lastTag = null; String lastText = null; int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); switch (parser.getEventType()) { case XmlPullParser.START_TAG: lastTag = parser.getName(); break; case XmlPullParser.TEXT: lastText = parser.getText(); break; case XmlPullParser.END_TAG: if (parser.getDepth() == 4 && lastTag != null && lastText != null) { data.put(lastTag, lastText); } lastTag = null; lastText = null; break; } } if (data.containsKey(&ldquo;name&rdquo;)) { Statistic s = new Statistic(data.get(&ldquo;name&rdquo;)); s.setClasses(Long.valueOf(data.get(&ldquo;classes&rdquo;))); s.setFunctions(Long.valueOf(data.get(&ldquo;functions&rdquo;))); s.setNcss(Long.valueOf(data.get(&ldquo;ncss&rdquo;))); s.setJavadocs(Long.valueOf(data.get(&ldquo;javadocs&rdquo;))); s.setJavadocLines(Long.valueOf(data.get(&ldquo;javadoc_lines&rdquo;))); s.setSingleCommentLines(Long.valueOf(data.get(&ldquo;single_comment_lines&rdquo;))); s.setMultiCommentLines(Long.valueOf(data.get(&ldquo;multi_comment_lines&rdquo;))); results.add(s); } parser.next(); } } catch (XmlPullParserException e) { throw new IOException2(e); } finally { if (bis != null) { bis.close(); } if (fis != null) { fis.close(); } } return results; } private static void skipTag(XmlPullParser parser) throws IOException, XmlPullParserException { parser.next(); endElement(parser); } private static void expectNextTag(XmlPullParser parser, String tag) throws IOException, XmlPullParserException { while (true) { if (parser.getEventType() != XmlPullParser.START_TAG) { parser.next(); continue; } if (parser.getName().equals(tag)) { return; } throw new IOException(&ldquo;Expecting tag " + tag); } } private static void endElement(XmlPullParser parser) throws IOException, XmlPullParserException { int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); } } public Statistic(String name) { this.name = name; } &mldr; // Simple getters and setters for all the private fields &mldr; // equals based on all private fields, hashCode based on // name and owner. &mldr; // toString &mldr;}Essentially the main work is done in the static parse method. It takes a File and tries to parse it. We get an XML Pull Parser for the stream and ensure that it is neither namespace aware nor validating as the file format does not use namespaces and we will be forgiving on the XML format.The first tag should be and after that we skip until we get a tag. Once we have found the tag we skip until we hit the first tag.We are reverse engineering the JavaNCSS file format, so we will not make any assumptions about the order of the child elements in the element. We put all the child elements into a Map keyed by the element name, and then when we reach the end of the element we pull out the information we were after from the Map and put it into a Statistic object and add that to the collection of results that we will return.As soon as we hit the end of the element, we stop parsing.Supporting aggregationIn order to support aggregation of multiple results, we&rsquo;ll add some utility methods to the Statistic class, first we need methods that allow us to calculate totals:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Statistic total(Collection&mldr; results) { Collection merged = merge(results); Statistic total = new Statistic(&rdquo;"); for (Statistic individual : merged) { total.add(individual); } return total; } public void add(Statistic r) { classes += r.classes; functions += r.functions; ncss += r.ncss; javadocs += r.javadocs; javadocLines += r.javadocLines; singleCommentLines += r.singleCommentLines; multiCommentLines += r.multiCommentLines; } &mldr;}The total method just calculates the total of all the statistics in a collection of statistics. We will also need to be able to merge different result sets. This should aggregate totals for each package separately and return a collection with one total statistic for each package:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Collection merge( Collection&mldr; results) { if (results.length == 0) { return Collections.emptySet(); } else if (results.length == 1) { return results[0]; } else { Map<String, Statistic> merged = new HashMap<String, Statistic>(); for (Collection result : results) { for (Statistic individual : result) { if (!merged.containsKey(individual.name)) { merged.put(individual.name, new Statistic(individual.name)); } merged.get(individual.name).add(individual); } } return merged.values(); } } &mldr;}That is pretty much it for the parser engine.The GhostwriterNow we need to hook the engine into our publisher. We will need to configure the UI elements and the Actions&mldr; all tasks for the final part, but for now, we&rsquo;ll just hook it up. We want to run the parsing on the slave side so we implement Ghostwriter.SlaveGhostwriter.package hudson.plugins.javancss;import hudson.FilePath;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.helpers.Ghostwriter;import hudson.plugins.javancss.parser.Statistic;import org.xmlpull.v1.XmlPullParserException;import java.io.File;import java.io.IOException;import java.util.Collection;import java.util.HashSet;import java.util.Set;public class JavaNCSSGhostwriter implements Ghostwriter, Ghostwriter.SlaveGhostwriter { private final String reportFilenamePattern; public JavaNCSSGhostwriter(String reportFilenamePattern) { this.reportFilenamePattern = reportFilenamePattern; } public boolean performFromSlave( BuildProxy build, BuildListener listener) throws InterruptedException, IOException { FilePath[] paths = build.getExecutionRootDir() .list(reportFilenamePattern); Collection results = null; Set parsedFiles = new HashSet(); for (FilePath path : paths) { final String pathStr = path.getRemote(); if (!parsedFiles.contains(pathStr)) { parsedFiles.add(pathStr); try { Collection result = Statistic.parse(new File(pathStr)); if (results == null) { results = result; } else { results = Statistic.merge(results, result); } // TODO copy the parsed file to the master } catch (XmlPullParserException e) { e.printStackTrace(listener.getLogger()); } } } // TODO add the results into an Action an attach it to the // build. return true; }}Basically, we search the supplied wildcard-path for report files and merge all the results together into a collection of results. In the final part of this series we will create our Action to hold the results and wire everything together.
'><meta name=twitter:site content="https://stephenc.github.io/"><meta name=twitter:creator content><meta name=twitter:image content="https://stephenc.github.io/"><meta property="og:type" content="article"><meta property="og:title" content="Writing a Hudson plugin (Part 6 - Parsing the results) - Stephen's technical blog"><meta property="og:description" content='In some ways parsing the JavaNCSS results is the least interesting part of developing a Hudson plugin, as once I have implemented the parser, it is available for everyone. For that reason I will focus more on:best practice techniques for parsing resultscommon gotchasdesigning for extensionGetting startedFirst off, we need to analyse the results file format. In the case of JavaNCSS there are multiple ways that the results file can be generated: from the JavaNCSS program directly, from ANT or from Maven. This leads us onto gotcha #1Gotcha #1:Never assume that a build tool generates the same format of output when run from the command line, ANT or Maven.A case in point for Gotcha #1 is Findbugs which generates one XML format from the command line and ANT, and generates a different format that appears similar at first glance when run from Maven (mail thread). In this case it turns out that Maven 1 used the different format output, and it is feared that some people came to depend on this Maven 1 format, so when the plugin for Maven 2 was developed, they kept the Maven 1 format. In any case, the moral is don’t assume, check!So we use the sample projects from Part 1 and generate an ANT and a Maven 2 XML report. First off, here is the report from ANT:2008-04-1211:22:30 com.onedash.common 1 3 10 3 <javadoc_lines>12</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> &mldr; &mldr; 5 8 46 9 <javadoc_lines>37</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> PackagesClassesFunctionsNCSSJavadocsper 4.005.008.0046.009.00Project 1.252.0011.502.25Package 1.609.201.80Class 5.751.13Function com.onedash.common.Factory 7 3 0 3 &mldr; &mldr; 6.60 1.60 0.00 1.80 46.00 com.onedash.common.Factory.Factory() 1 1 1 &mldr; &mldr; 46.00OK, first off, for those following the tutorial exactly, I have cheated a little. I added some more source files into the project to make sure that I have multiple classes is different packages. You can see the source code I built from here. Additionally, I have trimmed the output somewhat to highlight the interesting bits, removing the duplicate entries.From this report file we can see a basic XML structure:The root element is and has child elements: , , , , and The and elements are the timestamp when the report was generated with the date in YYYY-MM-DD format and the time in HH:MM:SS formatThe element has child elements: , , and . There are multiple ; elements, but only one and element.The elements have child elements: , , , , , <javadoc_lines>, <single_comment_lines> and <multi_comment_lines>. The element contains the name of the package as a String and the other elements contain totals as Integers.The element has child elements: , , , , <javadoc_lines>, <single_comment_lines> and <multi_comment_lines>. These elements are the sum of all the corresponding children inside the parentThe element seems to be a HTML table.The element has child elements: , and . There are multiple elements, the element contains the average results for all the elements and the element providing some form of total or average.The element has child elements: and . Again there are multiple elements with the element providing some form of total or average (interestingly the result appears to be the same as from ).Now, let’s take a look at what Maven 2 gives us:2008-04-1211:43:06 com.onedash.common 1 3 10 3 <javadoc_lines>12</javadoc_lines> <single_comment_lines>0</single_comment_lines> <multi_comment_lines>0</multi_comment_lines> &mldr; &mldr; 5 8 46 10 <javadoc_lines>42</javadoc_lines> <single_comment_lines>3</single_comment_lines> <multi_comment_lines>3</multi_comment_lines> PackagesClassesFunctionsNCSSJava 4.005.008.0046.0010.00P 1.252.0011.502.50Packag 1.609.202.00Class< 5.751.25Function</ com.onedash.common.api.Namer 2 1 0 1 &mldr; &mldr; 6.60 1.60 0.00 2.00 46.00 com.onedash.common.api.Namer.newName() 1 1 0 &mldr; 46.00Thankfully, this is the same format as for ANT. You will also be relieved to know that this is the format generated by the JavaNCSS program directly. Thus we only have to write one parser, and we do not have to detect what format we are parsing. But before I forget:Best Practice #1:When there are multiple formats of a report generated by different tools, make sure that your Hudson plugin can detect the different formats and can handle them appropriately (by either delegating to a different parser implementation, or by handling the differences on the fly).One of the goals of Hudson is to minimise configuration. So when a plugin can detect an configuration option automatically, it should detect it automatically (possibly providing an “Advanced” option button to let users override the detection if Hudson gets it wrong)Start smallLooking at the JavaNCSS output, I see that there is a lot of information&mldr; and I only have one more Part left in this series! So I am not going to parse everything. I am sure that in the future I will extend the Hudson plugin to parse all of the file, but for now I am just going to concentrate on the element. This gives users something useful and it’s better than nothing.But what happens when I do get around to parsing the and elements? People may have lots of old builds and they will want to see the trends of the and results. I have two choices:Tell them “Sorry, out of luck”Save the results with the build, and then the newer parser can extract the results when people want the trend.Choosing between these two options can be difficult. My preference is to go with option two, as long as the results are not a really big file.Best Practice #2:If you are not parsing everything in the results file, and the results file is not too big, and it can be parsed without reference to the source code, copy the results file to Hudson so that future versions of your plugin can read the information you are not currently parsing.Don’t over parseThe results that we parse are going to be placed into an Action object. This Action object will be serialized. When Hudson starts up, it reads all the results of all the builds. If we place too much information in our Action object, this can have a detrimental effect on Hudson’s performance. When users have 50+ projects each with a couple of hundred builds, they will thank you for keeping your Action objects small.Gotcha #2:Don’t store too much in your Action objects.Don’t under parseOK, so I have just given out about storing too much in your Action objects. There is a second problem&mldr; not storing enough! Most reporting plugins try to present a trend graph to show progress over a number of builds. If we don’t store the information required to generate this trend graph inside our Action objects, then displaying the trend graph will require parsing all the result files for all builds of a project. This can have a detrimental effect on Hudson’s performance. When users have projects with a couple of hundred builds, they will thank you for keeping the information to generate the main trend graph inside your Action objects.Gotcha #3:Store the information for generating the Project level trend graph in your Action objects.A case in point for Gotach #3 is the cobertura plugin, which at the time of writing, does not store the information for the main trend graph in the Action object. I fully intend to fix this situation once I have finished this series!How to parseMost of the result files that you will encounter are XML based. We are writing our plugins in Java, so that gives us a range of parsers to choose from, e.g.SAXDOMStAXRoll your ownEtc.Given that report files can end up very big for very big projects, we need to be careful how we parse the results:Gotcha #4:Don’t parse XML results using DOM, as this will require reading the entire report file into memory.I am going to stick my neck out and make a recommendation:Best Practice #3:Use an XML pull parser to parse XML report files.They are generally faster, use less memory, and are better suited to a “hit-and-run” style of result extraction.Be able to aggregate parsing resultsYou may think that there will only ever be one result file that you need to parse. Maven 2 usually throws a spanner into that model, and everyone has their own ANT build script, so:Gotcha #5:Don’t assume you only have to parse one report file for each project.This gotcha arrives from the code coverage plugins (emma, clover, cobertura). Initially, you would think that people are only interested in one code coverage result, i.e. the coverage for the project&mldr; so they will only have one result file that we need to parse, right? Wrong! Some tools/build scripts generate a report for each module but only generate a summary report in non-conforming HTML. Some tools / build scripts generate a report for unit tests and integration tests separately. It’s a mess, and don’t get me started on using different tools for different test types&mldr;The parsing engineOk, so here is the parsing engine:package hudson.plugins.javancss.parser;import hudson.model.AbstractBuild;import hudson.util.IOException2;import org.xmlpull.v1.XmlPullParser;import org.xmlpull.v1.XmlPullParserException;import org.xmlpull.v1.XmlPullParserFactory;import java.io.;import java.util.;public class Statistic implements Serializable { private AbstractBuild owner; private String name; private long classes; private long functions; private long ncss; private long javadocs; private long javadocLines; private long singleCommentLines; private long multiCommentLines; public static Collection parse(File inFile) throws IOException, XmlPullParserException { Collection results = new ArrayList(); FileInputStream fis = null; BufferedInputStream bis = null; try { fis = new FileInputStream(inFile); bis = new BufferedInputStream(fis); XmlPullParserFactory factory = XmlPullParserFactory.newInstance(); factory.setNamespaceAware(true); factory.setValidating(false); XmlPullParser parser = factory.newPullParser(); parser.setInput(bis, null); // check that the first tag is expectNextTag(parser, &ldquo;javancss&rdquo;); // skip until we get to the tag while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;packages&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;package&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() >= 2 && parser.getEventType() == XmlPullParser.START_TAG && &ldquo;package&rdquo;.equals(parser.getName())) { Map<String, String> data = new HashMap<String, String>(); String lastTag = null; String lastText = null; int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); switch (parser.getEventType()) { case XmlPullParser.START_TAG: lastTag = parser.getName(); break; case XmlPullParser.TEXT: lastText = parser.getText(); break; case XmlPullParser.END_TAG: if (parser.getDepth() == 4 && lastTag != null && lastText != null) { data.put(lastTag, lastText); } lastTag = null; lastText = null; break; } } if (data.containsKey(&ldquo;name&rdquo;)) { Statistic s = new Statistic(data.get(&ldquo;name&rdquo;)); s.setClasses(Long.valueOf(data.get(&ldquo;classes&rdquo;))); s.setFunctions(Long.valueOf(data.get(&ldquo;functions&rdquo;))); s.setNcss(Long.valueOf(data.get(&ldquo;ncss&rdquo;))); s.setJavadocs(Long.valueOf(data.get(&ldquo;javadocs&rdquo;))); s.setJavadocLines(Long.valueOf(data.get(&ldquo;javadoc_lines&rdquo;))); s.setSingleCommentLines(Long.valueOf(data.get(&ldquo;single_comment_lines&rdquo;))); s.setMultiCommentLines(Long.valueOf(data.get(&ldquo;multi_comment_lines&rdquo;))); results.add(s); } parser.next(); } } catch (XmlPullParserException e) { throw new IOException2(e); } finally { if (bis != null) { bis.close(); } if (fis != null) { fis.close(); } } return results; } private static void skipTag(XmlPullParser parser) throws IOException, XmlPullParserException { parser.next(); endElement(parser); } private static void expectNextTag(XmlPullParser parser, String tag) throws IOException, XmlPullParserException { while (true) { if (parser.getEventType() != XmlPullParser.START_TAG) { parser.next(); continue; } if (parser.getName().equals(tag)) { return; } throw new IOException(&ldquo;Expecting tag " + tag); } } private static void endElement(XmlPullParser parser) throws IOException, XmlPullParserException { int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); } } public Statistic(String name) { this.name = name; } &mldr; // Simple getters and setters for all the private fields &mldr; // equals based on all private fields, hashCode based on // name and owner. &mldr; // toString &mldr;}Essentially the main work is done in the static parse method. It takes a File and tries to parse it. We get an XML Pull Parser for the stream and ensure that it is neither namespace aware nor validating as the file format does not use namespaces and we will be forgiving on the XML format.The first tag should be and after that we skip until we get a tag. Once we have found the tag we skip until we hit the first tag.We are reverse engineering the JavaNCSS file format, so we will not make any assumptions about the order of the child elements in the element. We put all the child elements into a Map keyed by the element name, and then when we reach the end of the element we pull out the information we were after from the Map and put it into a Statistic object and add that to the collection of results that we will return.As soon as we hit the end of the element, we stop parsing.Supporting aggregationIn order to support aggregation of multiple results, we&rsquo;ll add some utility methods to the Statistic class, first we need methods that allow us to calculate totals:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Statistic total(Collection&mldr; results) { Collection merged = merge(results); Statistic total = new Statistic(&rdquo;"); for (Statistic individual : merged) { total.add(individual); } return total; } public void add(Statistic r) { classes += r.classes; functions += r.functions; ncss += r.ncss; javadocs += r.javadocs; javadocLines += r.javadocLines; singleCommentLines += r.singleCommentLines; multiCommentLines += r.multiCommentLines; } &mldr;}The total method just calculates the total of all the statistics in a collection of statistics. We will also need to be able to merge different result sets. This should aggregate totals for each package separately and return a collection with one total statistic for each package:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Collection merge( Collection&mldr; results) { if (results.length == 0) { return Collections.emptySet(); } else if (results.length == 1) { return results[0]; } else { Map<String, Statistic> merged = new HashMap<String, Statistic>(); for (Collection result : results) { for (Statistic individual : result) { if (!merged.containsKey(individual.name)) { merged.put(individual.name, new Statistic(individual.name)); } merged.get(individual.name).add(individual); } } return merged.values(); } } &mldr;}That is pretty much it for the parser engine.The GhostwriterNow we need to hook the engine into our publisher. We will need to configure the UI elements and the Actions&mldr; all tasks for the final part, but for now, we&rsquo;ll just hook it up. We want to run the parsing on the slave side so we implement Ghostwriter.SlaveGhostwriter.package hudson.plugins.javancss;import hudson.FilePath;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.helpers.Ghostwriter;import hudson.plugins.javancss.parser.Statistic;import org.xmlpull.v1.XmlPullParserException;import java.io.File;import java.io.IOException;import java.util.Collection;import java.util.HashSet;import java.util.Set;public class JavaNCSSGhostwriter implements Ghostwriter, Ghostwriter.SlaveGhostwriter { private final String reportFilenamePattern; public JavaNCSSGhostwriter(String reportFilenamePattern) { this.reportFilenamePattern = reportFilenamePattern; } public boolean performFromSlave( BuildProxy build, BuildListener listener) throws InterruptedException, IOException { FilePath[] paths = build.getExecutionRootDir() .list(reportFilenamePattern); Collection results = null; Set parsedFiles = new HashSet(); for (FilePath path : paths) { final String pathStr = path.getRemote(); if (!parsedFiles.contains(pathStr)) { parsedFiles.add(pathStr); try { Collection result = Statistic.parse(new File(pathStr)); if (results == null) { results = result; } else { results = Statistic.merge(results, result); } // TODO copy the parsed file to the master } catch (XmlPullParserException e) { e.printStackTrace(listener.getLogger()); } } } // TODO add the results into an Action an attach it to the // build. return true; }}Basically, we search the supplied wildcard-path for report files and merge all the results together into a collection of results. In the final part of this series we will create our Action to hold the results and wire everything together.
'><meta property="og:url" content="https://stephenc.github.io/post/2008-04-01-writing-a-hudson-plugin-part-6-parsing-the-results/"><meta property="og:site_name" content="Writing a Hudson plugin (Part 6 - Parsing the results)"><meta property="og:image" content="https://stephenc.github.io/"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2008-04-01 00:00:00 +0000 UTC"></head><body><div style=position:relative><header class="Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap open Details--on"><div class="Header-item mobile-none" style=margin-top:-4px;margin-bottom:-4px><a class=Header-link href=https://stephenc.github.io/><img class=octicon height=32 width=32 src=/images/top-icon.png></a></div><div class="Header-item d-md-none"><button class="Header-link btn-link js-details-target" type=button onclick='document.querySelector("#header-search").style.display=document.querySelector("#header-search").style.display=="none"?"block":"none"'>
<svg height="24" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button></div><div style=display:none id=header-search class="Header-item Header-item--full flex-column flex-md-row width-full flex-order-2 flex-md-order-none mr-0 mr-md-3 mt-3 mt-md-0 Details-content--hidden-not-important d-md-flex"><div class="Header-search header-search flex-auto js-site-search position-relative flex-self-stretch flex-md-self-auto mb-3 mb-md-0 mr-0 mr-md-3 scoped-search site-scoped-search js-jump-to"><div class=position-relative><form target=_blank id=search-form accept-charset=UTF-8 method=get autocomplete=off><label class="Header-search-label form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center"><input type=text class="Header-search-input form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable" name=q placeholder=Search autocomplete=off></label></form></div></div></div><div class="Header-item Header-item--full flex-justify-center d-md-none position-relative"><a class=Header-link href=https://stephenc.github.io/><img class="octicon octicon-mark-github v-align-middle" height=32 width=32 src=/images/top-icon.png></a></div><div class=Header-item style=margin-right:0><a href=javascript:void(0) class="Header-link no-select" onclick=switchTheme()><svg style="fill:var(--color-profile-color-modes-toggle-moon)" class="no-select" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754c3.05612.0 5.53362-2.47748 5.53362-5.5336C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961 9.95801 1.07727 10.3495.771159 10.6474.99992c1.4679 1.12724 2.4141 2.90007 2.4141 4.89391.0 3.40575-2.7609 6.16667-6.16665 6.16667-2.94151.0-5.40199-2.0595-6.018122-4.81523C.794841 6.87902 1.23668 6.65289 1.55321 6.85451 2.41106 7.40095 3.4296 7.71754 4.52208 7.71754z"/></svg></a></div></header></div><div id=search-result class="container-lg px-3 new-discussion-timeline" style=display:none></div><div class=application-main><div><main><div class="gisthead pagehead bg-gray-light pb-0 pt-3 mb-4"><div class=px-0><div class="mb-3 d-flex px-3 px-md-3 px-lg-5"><div class="flex-auto min-width-0 width-fit mr-3"><div class=d-flex><div class="d-none d-md-block"><a class="avatar mr-2 flex-shrink-0" href=https://stephenc.github.io/><img class=avatar-user src=/images/avatar.jpg width=32 height=32></a></div><div class="d-flex flex-column"><h1 class="break-word f3 text-normal mb-md-0 mb-1"><span class=author><a href=https://stephenc.github.io/>Stephen Connolly</a>
</span><span class=path-divider>/</span>
<strong class="css-truncate css-truncate-target mr-1" style=max-width:410px><a href=https://stephenc.github.io/post/2008-04-01-writing-a-hudson-plugin-part-6-parsing-the-results/>Writing a Hudson plugin (Part 6 - Parsing the results)</a></strong></h1><div class="note m-0">Created <relative-time datetime="Tue, 01 Apr 2008 00:00:00 +0000" class=no-wrap>Tue, 01 Apr 2008 00:00:00 +0000</relative-time>
<span class=file-info-divider></span>
Modified <relative-time datetime="Tue, 01 Apr 2008 00:00:00 +0000" class=no-wrap>Tue, 01 Apr 2008 00:00:00 +0000</relative-time></div></div></div></div></div></div></div><div class="container-lg px-3 new-discussion-timeline"><div class="repository-content gist-content"><div><div class="js-gist-file-update-container js-task-list-container file-box"><div id=file-pytest class="file my-2"><div id=post-header class="file-header d-flex flex-md-items-center flex-items-start sticky-header" style=z-index:2><div class="file-info d-flex flex-md-items-center flex-items-start flex-order-1 flex-auto"><div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0"><summary id=toc-toggle onclick=clickToc() class="btn btn-octicon m-0 mr-2 p-2"><svg aria-hidden="true" viewBox="0 0 16 16" height="16" width="16" class="octicon octicon-list-unordered"><path fill-rule="evenodd" d="M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zm0 5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zm0 5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zM3 8A1 1 0 111 8a1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z"/></svg></summary><details-menu class=SelectMenu id=toc-details style="display: none;"><div class="SelectMenu-modal rounded-3 mt-1" style=max-height:340px><div class="SelectMenu-list SelectMenu-list--borderless p-2" style=overscroll-behavior:contain id=toc-list></div></div></details-menu>2388 Words</div><div class="file-actions flex-order-2 pt-0"><a class="muted-link mr-3" href=/tags/jenkins><svg class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M2.5 7.775V2.75a.25.25.0 01.25-.25h5.025a.25.25.0 01.177.073l6.25 6.25a.25.25.0 010 .354l-5.025 5.025a.25.25.0 01-.354.0l-6.25-6.25A.25.25.0 012.5 7.775zm-1.5.0V2.75C1 1.784 1.784 1 2.75 1h5.025c.464.0.91.184 1.238.513l6.25 6.25a1.75 1.75.0 010 2.474l-5.026 5.026a1.75 1.75.0 01-2.474.0l-6.25-6.25A1.75 1.75.0 011 7.775zM6 5a1 1 0 100 2 1 1 0 000-2z"/></svg>
Jenkins</a></div></div></div><div class="Box-body px-5 pb-5" style=z-index:1><article class="markdown-body entry-content container-lg"><p>In some ways parsing the JavaNCSS results is the least interesting part of developing a Hudson plugin, as once I have implemented the parser, it is available for everyone. For that reason I will focus more on:best practice techniques for parsing resultscommon gotchasdesigning for extensionGetting startedFirst off, we need to analyse the results file format. In the case of JavaNCSS there are multiple ways that the results file can be generated: from the JavaNCSS program directly, from ANT or from Maven. This leads us onto gotcha #1Gotcha #1:Never assume that a build tool generates the same format of output when run from the command line, ANT or Maven.A case in point for Gotcha #1 is Findbugs which generates one XML format from the command line and ANT, and generates a different format that appears similar at first glance when run from Maven (mail thread). In this case it turns out that Maven 1 used the different format output, and it is feared that some people came to depend on this Maven 1 format, so when the plugin for Maven 2 was developed, they kept the Maven 1 format. In any case, the moral is don’t assume, check!So we use the sample projects from Part 1 and generate an ANT and a Maven 2 XML report. First off, here is the report from ANT:2008-04-1211:22:30 com.onedash.common 1 3 10 3 &lt;javadoc_lines>12&lt;/javadoc_lines> &lt;single_comment_lines>0&lt;/single_comment_lines> &lt;multi_comment_lines>0&lt;/multi_comment_lines> &mldr; &mldr; 5 8 46 9 &lt;javadoc_lines>37&lt;/javadoc_lines> &lt;single_comment_lines>0&lt;/single_comment_lines> &lt;multi_comment_lines>0&lt;/multi_comment_lines> PackagesClassesFunctionsNCSSJavadocsper 4.005.008.0046.009.00Project 1.252.0011.502.25Package 1.609.201.80Class 5.751.13Function com.onedash.common.Factory 7 3 0 3 &mldr; &mldr; 6.60 1.60 0.00 1.80 46.00 com.onedash.common.Factory.Factory() 1 1 1 &mldr; &mldr; 46.00OK, first off, for those following the tutorial exactly, I have cheated a little. I added some more source files into the project to make sure that I have multiple classes is different packages. You can see the source code I built from here. Additionally, I have trimmed the output somewhat to highlight the interesting bits, removing the duplicate entries.From this report file we can see a basic XML structure:The root element is and has child elements: , , , , and The and elements are the timestamp when the report was generated with the date in YYYY-MM-DD format and the time in HH:MM:SS formatThe element has child elements: , , and . There are multiple ; elements, but only one and element.The elements have child elements: , , , , , &lt;javadoc_lines>, &lt;single_comment_lines> and &lt;multi_comment_lines>. The element contains the name of the package as a String and the other elements contain totals as Integers.The element has child elements: , , , , &lt;javadoc_lines>, &lt;single_comment_lines> and &lt;multi_comment_lines>. These elements are the sum of all the corresponding children inside the parentThe element seems to be a HTML table.The element has child elements: , and . There are multiple elements, the element contains the average results for all the elements and the element providing some form of total or average.The element has child elements: and . Again there are multiple elements with the element providing some form of total or average (interestingly the result appears to be the same as from ).Now, let’s take a look at what Maven 2 gives us:2008-04-1211:43:06 com.onedash.common 1 3 10 3 &lt;javadoc_lines>12&lt;/javadoc_lines> &lt;single_comment_lines>0&lt;/single_comment_lines> &lt;multi_comment_lines>0&lt;/multi_comment_lines> &mldr; &mldr; 5 8 46 10 &lt;javadoc_lines>42&lt;/javadoc_lines> &lt;single_comment_lines>3&lt;/single_comment_lines> &lt;multi_comment_lines>3&lt;/multi_comment_lines> PackagesClassesFunctionsNCSSJava 4.005.008.0046.0010.00P 1.252.0011.502.50Packag 1.609.202.00Class&lt; 5.751.25Function&lt;/ com.onedash.common.api.Namer 2 1 0 1 &mldr; &mldr; 6.60 1.60 0.00 2.00 46.00 com.onedash.common.api.Namer.newName() 1 1 0 &mldr; 46.00Thankfully, this is the same format as for ANT. You will also be relieved to know that this is the format generated by the JavaNCSS program directly. Thus we only have to write one parser, and we do not have to detect what format we are parsing. But before I forget:Best Practice #1:When there are multiple formats of a report generated by different tools, make sure that your Hudson plugin can detect the different formats and can handle them appropriately (by either delegating to a different parser implementation, or by handling the differences on the fly).One of the goals of Hudson is to minimise configuration. So when a plugin can detect an configuration option automatically, it should detect it automatically (possibly providing an “Advanced” option button to let users override the detection if Hudson gets it wrong)Start smallLooking at the JavaNCSS output, I see that there is a lot of information&mldr; and I only have one more Part left in this series! So I am not going to parse everything. I am sure that in the future I will extend the Hudson plugin to parse all of the file, but for now I am just going to concentrate on the element. This gives users something useful and it’s better than nothing.But what happens when I do get around to parsing the and elements? People may have lots of old builds and they will want to see the trends of the and results. I have two choices:Tell them “Sorry, out of luck”Save the results with the build, and then the newer parser can extract the results when people want the trend.Choosing between these two options can be difficult. My preference is to go with option two, as long as the results are not a really big file.Best Practice #2:If you are not parsing everything in the results file, and the results file is not too big, and it can be parsed without reference to the source code, copy the results file to Hudson so that future versions of your plugin can read the information you are not currently parsing.Don’t over parseThe results that we parse are going to be placed into an Action object. This Action object will be serialized. When Hudson starts up, it reads all the results of all the builds. If we place too much information in our Action object, this can have a detrimental effect on Hudson’s performance. When users have 50+ projects each with a couple of hundred builds, they will thank you for keeping your Action objects small.Gotcha #2:Don’t store too much in your Action objects.Don’t under parseOK, so I have just given out about storing too much in your Action objects. There is a second problem&mldr; not storing enough! Most reporting plugins try to present a trend graph to show progress over a number of builds. If we don’t store the information required to generate this trend graph inside our Action objects, then displaying the trend graph will require parsing all the result files for all builds of a project. This can have a detrimental effect on Hudson’s performance. When users have projects with a couple of hundred builds, they will thank you for keeping the information to generate the main trend graph inside your Action objects.Gotcha #3:Store the information for generating the Project level trend graph in your Action objects.A case in point for Gotach #3 is the cobertura plugin, which at the time of writing, does not store the information for the main trend graph in the Action object. I fully intend to fix this situation once I have finished this series!How to parseMost of the result files that you will encounter are XML based. We are writing our plugins in Java, so that gives us a range of parsers to choose from, e.g.SAXDOMStAXRoll your ownEtc.Given that report files can end up very big for very big projects, we need to be careful how we parse the results:Gotcha #4:Don’t parse XML results using DOM, as this will require reading the entire report file into memory.I am going to stick my neck out and make a recommendation:Best Practice #3:Use an XML pull parser to parse XML report files.They are generally faster, use less memory, and are better suited to a “hit-and-run” style of result extraction.Be able to aggregate parsing resultsYou may think that there will only ever be one result file that you need to parse. Maven 2 usually throws a spanner into that model, and everyone has their own ANT build script, so:Gotcha #5:Don’t assume you only have to parse one report file for each project.This gotcha arrives from the code coverage plugins (emma, clover, cobertura). Initially, you would think that people are only interested in one code coverage result, i.e. the coverage for the project&mldr; so they will only have one result file that we need to parse, right? Wrong! Some tools/build scripts generate a report for each module but only generate a summary report in non-conforming HTML. Some tools / build scripts generate a report for unit tests and integration tests separately. It’s a mess, and don’t get me started on using different tools for different test types&mldr;The parsing engineOk, so here is the parsing engine:package hudson.plugins.javancss.parser;import hudson.model.AbstractBuild;import hudson.util.IOException2;import org.xmlpull.v1.XmlPullParser;import org.xmlpull.v1.XmlPullParserException;import org.xmlpull.v1.XmlPullParserFactory;import java.io.<em>;import java.util.</em>;public class Statistic implements Serializable { private AbstractBuild owner; private String name; private long classes; private long functions; private long ncss; private long javadocs; private long javadocLines; private long singleCommentLines; private long multiCommentLines; public static Collection parse(File inFile) throws IOException, XmlPullParserException { Collection results = new ArrayList(); FileInputStream fis = null; BufferedInputStream bis = null; try { fis = new FileInputStream(inFile); bis = new BufferedInputStream(fis); XmlPullParserFactory factory = XmlPullParserFactory.newInstance(); factory.setNamespaceAware(true); factory.setValidating(false); XmlPullParser parser = factory.newPullParser(); parser.setInput(bis, null); // check that the first tag is expectNextTag(parser, &ldquo;javancss&rdquo;); // skip until we get to the tag while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;packages&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() > 0 && (parser.getEventType() != XmlPullParser.START_TAG || !&ldquo;package&rdquo;.equals(parser.getName()))) { parser.next(); } while (parser.getDepth() >= 2 && parser.getEventType() == XmlPullParser.START_TAG && &ldquo;package&rdquo;.equals(parser.getName())) { Map&lt;String, String> data = new HashMap&lt;String, String>(); String lastTag = null; String lastText = null; int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); switch (parser.getEventType()) { case XmlPullParser.START_TAG: lastTag = parser.getName(); break; case XmlPullParser.TEXT: lastText = parser.getText(); break; case XmlPullParser.END_TAG: if (parser.getDepth() == 4 && lastTag != null && lastText != null) { data.put(lastTag, lastText); } lastTag = null; lastText = null; break; } } if (data.containsKey(&ldquo;name&rdquo;)) { Statistic s = new Statistic(data.get(&ldquo;name&rdquo;)); s.setClasses(Long.valueOf(data.get(&ldquo;classes&rdquo;))); s.setFunctions(Long.valueOf(data.get(&ldquo;functions&rdquo;))); s.setNcss(Long.valueOf(data.get(&ldquo;ncss&rdquo;))); s.setJavadocs(Long.valueOf(data.get(&ldquo;javadocs&rdquo;))); s.setJavadocLines(Long.valueOf(data.get(&ldquo;javadoc_lines&rdquo;))); s.setSingleCommentLines(Long.valueOf(data.get(&ldquo;single_comment_lines&rdquo;))); s.setMultiCommentLines(Long.valueOf(data.get(&ldquo;multi_comment_lines&rdquo;))); results.add(s); } parser.next(); } } catch (XmlPullParserException e) { throw new IOException2(e); } finally { if (bis != null) { bis.close(); } if (fis != null) { fis.close(); } } return results; } private static void skipTag(XmlPullParser parser) throws IOException, XmlPullParserException { parser.next(); endElement(parser); } private static void expectNextTag(XmlPullParser parser, String tag) throws IOException, XmlPullParserException { while (true) { if (parser.getEventType() != XmlPullParser.START_TAG) { parser.next(); continue; } if (parser.getName().equals(tag)) { return; } throw new IOException(&ldquo;Expecting tag " + tag); } } private static void endElement(XmlPullParser parser) throws IOException, XmlPullParserException { int depth = parser.getDepth(); while (parser.getDepth() >= depth) { parser.next(); } } public Statistic(String name) { this.name = name; } &mldr; // Simple getters and setters for all the private fields &mldr; // equals based on all private fields, hashCode based on // name and owner. &mldr; // toString &mldr;}Essentially the main work is done in the static parse method. It takes a File and tries to parse it. We get an XML Pull Parser for the stream and ensure that it is neither namespace aware nor validating as the file format does not use namespaces and we will be forgiving on the XML format.The first tag should be and after that we skip until we get a tag. Once we have found the tag we skip until we hit the first tag.We are reverse engineering the JavaNCSS file format, so we will not make any assumptions about the order of the child elements in the element. We put all the child elements into a Map keyed by the element name, and then when we reach the end of the element we pull out the information we were after from the Map and put it into a Statistic object and add that to the collection of results that we will return.As soon as we hit the end of the element, we stop parsing.Supporting aggregationIn order to support aggregation of multiple results, we&rsquo;ll add some utility methods to the Statistic class, first we need methods that allow us to calculate totals:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Statistic total(Collection&mldr; results) { Collection merged = merge(results); Statistic total = new Statistic(&rdquo;"); for (Statistic individual : merged) { total.add(individual); } return total; } public void add(Statistic r) { classes += r.classes; functions += r.functions; ncss += r.ncss; javadocs += r.javadocs; javadocLines += r.javadocLines; singleCommentLines += r.singleCommentLines; multiCommentLines += r.multiCommentLines; } &mldr;}The total method just calculates the total of all the statistics in a collection of statistics. We will also need to be able to merge different result sets. This should aggregate totals for each package separately and return a collection with one total statistic for each package:package hudson.plugins.javancss.parser;&mldr;public class Statistic implements Serializable { &mldr; public static Collection merge( Collection&mldr; results) { if (results.length == 0) { return Collections.emptySet(); } else if (results.length == 1) { return results[0]; } else { Map&lt;String, Statistic> merged = new HashMap&lt;String, Statistic>(); for (Collection result : results) { for (Statistic individual : result) { if (!merged.containsKey(individual.name)) { merged.put(individual.name, new Statistic(individual.name)); } merged.get(individual.name).add(individual); } } return merged.values(); } } &mldr;}That is pretty much it for the parser engine.The GhostwriterNow we need to hook the engine into our publisher. We will need to configure the UI elements and the Actions&mldr; all tasks for the final part, but for now, we&rsquo;ll just hook it up. We want to run the parsing on the slave side so we implement Ghostwriter.SlaveGhostwriter.package hudson.plugins.javancss;import hudson.FilePath;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.plugins.helpers.BuildProxy;import hudson.plugins.helpers.Ghostwriter;import hudson.plugins.javancss.parser.Statistic;import org.xmlpull.v1.XmlPullParserException;import java.io.File;import java.io.IOException;import java.util.Collection;import java.util.HashSet;import java.util.Set;public class JavaNCSSGhostwriter implements Ghostwriter, Ghostwriter.SlaveGhostwriter { private final String reportFilenamePattern; public JavaNCSSGhostwriter(String reportFilenamePattern) { this.reportFilenamePattern = reportFilenamePattern; } public boolean performFromSlave( BuildProxy build, BuildListener listener) throws InterruptedException, IOException { FilePath[] paths = build.getExecutionRootDir() .list(reportFilenamePattern); Collection results = null; Set parsedFiles = new HashSet(); for (FilePath path : paths) { final String pathStr = path.getRemote(); if (!parsedFiles.contains(pathStr)) { parsedFiles.add(pathStr); try { Collection result = Statistic.parse(new File(pathStr)); if (results == null) { results = result; } else { results = Statistic.merge(results, result); } // TODO copy the parsed file to the master } catch (XmlPullParserException e) { e.printStackTrace(listener.getLogger()); } } } // TODO add the results into an Action an attach it to the // build. return true; }}Basically, we search the supplied wildcard-path for report files and merge all the results together into a collection of results. In the final part of this series we will create our Action to hold the results and wire everything together.</p></article></div></div></div></div></div></div></main></div><script type=application/javascript src=https://stephenc.github.io/js/toc.js></script><link rel=stylesheet href=https://stephenc.github.io/css/toc.css></div><div class="footer container-xl width-full p-responsive"><div class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between flex-sm-items-center pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light"><a aria-label=Homepage title=GitHub class="footer-octicon d-none d-lg-block mr-lg-4" href=https://stephenc.github.io/><svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a><ul class="list-style-none d-flex flex-wrap col-12 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0"><li class="mr-3 mr-lg-0">Theme by <a href=https://github.com/MeiK2333/github-style>github-style</a></li><li class="mr-3 mr-lg-0">GitHub and the Invertocat logo are trademarks of <a href=https://github.com/>GitHub, Inc.</a></li></ul></div><div class="d-flex flex-justify-center pb-6"><span class="f6 text-gray-light"></span></div></div><div id=cookie-consent-banner style="display:none;position:fixed;bottom:0;left:0;right:0;background:#333;color:#fff;padding:15px;text-align:center;z-index:9999;box-shadow:0 -2px 10px rgba(0,0,0,.3)"><div style="max-width:1200px;margin:0 auto"><p style="margin:0 0 10px;font-size:14px">This website uses Google Analytics to help analyze how visitors use this site. By continuing to browse this site, you agree to this use.
<a href=# style=color:#4caf50;text-decoration:underline onclick="return showCookieDetails(),!1">Learn more</a></p><div><button onclick=acceptCookies() style="background:#4caf50;color:#fff;border:none;padding:8px 16px;margin:0 5px;cursor:pointer;border-radius:4px">Accept</button>
<button onclick=declineCookies() style="background:#f44336;color:#fff;border:none;padding:8px 16px;margin:0 5px;cursor:pointer;border-radius:4px">Decline</button></div></div></div><div id=cookie-details-modal style=display:none;position:fixed;top:0;left:0;right:0;bottom:0;background:rgba(0,0,0,.5);z-index:10000><div style=position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);background:#fff;padding:20px;border-radius:8px;max-width:500px;width:90%><h3 style=margin-top:0>Cookie Information</h3><p>This website uses Google Analytics, which uses cookies to collect anonymous information about how visitors use this site. This information is used to improve the website experience.</p><p><strong>What data is collected:</strong></p><ul><li>Pages visited and time spent on pages</li><li>How you arrived at the site</li><li>General location (country/city level)</li><li>Device and browser information</li></ul><p>No personally identifiable information is collected. You can opt out at any time by declining cookies.</p><button onclick=hideCookieDetails() style="background:#2196f3;color:#fff;border:none;padding:8px 16px;cursor:pointer;border-radius:4px">Close</button></div></div><script>function getCookieConsent(){return localStorage.getItem("cookieConsent")}function setCookieConsent(e){localStorage.setItem("cookieConsent",e)}function loadGoogleAnalytics(){var t,e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-CEQZZXVE7Q",document.head.appendChild(e),t=document.createElement("script"),t.innerHTML=`
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-CEQZZXVE7Q', {
        anonymize_ip: true,
        cookie_flags: 'SameSite=None;Secure'
      });
    `,document.head.appendChild(t)}function acceptCookies(){setCookieConsent("accepted"),document.getElementById("cookie-consent-banner").style.display="none",loadGoogleAnalytics()}function declineCookies(){setCookieConsent("declined"),document.getElementById("cookie-consent-banner").style.display="none"}function showCookieDetails(){document.getElementById("cookie-details-modal").style.display="block"}function hideCookieDetails(){document.getElementById("cookie-details-modal").style.display="none"}document.addEventListener("DOMContentLoaded",function(){var e=getCookieConsent();e==="accepted"?loadGoogleAnalytics():e==="declined"||(document.getElementById("cookie-consent-banner").style.display="block")})</script></body><script type=application/javascript src=https://stephenc.github.io/js/github-style.js></script><script src=https://cdn.jsdelivr.net/npm/fuse.js/dist/fuse.min.js></script><script type=application/javascript src=https://stephenc.github.io/js/search.js></script></html>